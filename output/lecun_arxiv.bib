@misc{Balestriero2025_LeJEPA_,
    title = {LeJEPA: Provable and Scalable Self-Supervised Learning Without the Heuristics},
    author = {Randall Balestriero and Yann LeCun},
    year = {2025},
    eprint = {2511.08544},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2511.08544v3},
    abstract = {Learning manipulable representations of the world and its dynamics is central to AI. Joint-Embedding Predictive Architectures (JEPAs) offer a promising blueprint, but lack of practical guidance and theory has led to ad-hoc R\&D. We present a comprehensive theory of JEPAs and instantiate it in \{\bf LeJEPA\}, a lean, scalable, and theoretically grounded training objective. First, we identify the isotropic Gaussian as the optimal distribution that JEPAs' embeddings should follow to minimize downstrea...}
}

@misc{Yang2025_Cambrian_S_,
    title = {Cambrian-S: Towards Spatial Supersensing in Video},
    author = {Shusheng Yang and Jihan Yang and Pinzhi Huang and Ellis Brown and Zihao Yang and Yue Yu and Shengbang Tong and Zihan Zheng and Yifan Xu and Muhan Wang and Daohan Lu and Rob Fergus and Yann LeCun and Li Fei-Fei and Saining Xie},
    year = {2025},
    eprint = {2511.04670},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2511.04670v1},
    abstract = {We argue that progress in true multimodal intelligence calls for a shift from reactive, task-driven systems and brute-force long context towards a broader paradigm of supersensing. We frame spatial supersensing as four stages beyond linguistic-only understanding: semantic perception (naming what is seen), streaming event cognition (maintaining memory across continuous experiences), implicit 3D spatial cognition (inferring the world behind pixels), and predictive world modeling (creating internal...}
}

@misc{Queipo_de_Llano2025_Attention,
    title = {Attention Sinks and Compression Valleys in LLMs are Two Sides of the Same Coin},
    author = {Enrique Queipo-de-Llano and Álvaro Arroyo and Federico Barbero and Xiaowen Dong and Michael Bronstein and Yann LeCun and Ravid Shwartz-Ziv},
    year = {2025},
    eprint = {2510.06477},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2510.06477v1},
    abstract = {Attention sinks and compression valleys have attracted significant attention as two puzzling phenomena in large language models, but have been studied in isolation. In this work, we present a surprising connection between attention sinks and compression valleys, tracing both to the formation of massive activations in the residual stream. We prove theoretically that massive activations necessarily produce representational compression and establish bounds on the resulting entropy reduction. Throug...}
}

@misc{Balestriero2025_Gaussian,
    title = {Gaussian Embeddings: How JEPAs Secretly Learn Your Data Density},
    author = {Randall Balestriero and Nicolas Ballas and Mike Rabbat and Yann LeCun},
    year = {2025},
    eprint = {2510.05949},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2510.05949v1},
    abstract = {Joint Embedding Predictive Architectures (JEPAs) learn representations able to solve numerous downstream tasks out-of-the-box. JEPAs combine two objectives: (i) a latent-space prediction term, i.e., the representation of a slightly perturbed sample must be predictable from the original sample's representation, and (ii) an anti-collapse term, i.e., not all samples should have the same representation. While (ii) is often considered as an obvious remedy to representation collapse, we uncover that J...}
}

@misc{Huang2025_LLM_JEPA_,
    title = {LLM-JEPA: Large Language Models Meet Joint Embedding Predictive Architectures},
    author = {Hai Huang and Yann LeCun and Randall Balestriero},
    year = {2025},
    eprint = {2509.14252},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL},
    url = {https://arxiv.org/abs/2509.14252v2},
    abstract = {Large Language Model (LLM) pretraining, finetuning, and evaluation rely on input-space reconstruction and generative capabilities. Yet, it has been observed in vision that embedding-space training objectives, e.g., with Joint Embedding Predictive Architectures (JEPAs), are far superior to their input-space counterpart. That mismatch in how training is achieved between language and vision opens up a natural question: \{\em can language training methods learn a few tricks from the vision ones?\} The...}
}

@misc{Baldassarre2025_Back,
    title = {Back to the Features: DINO as a Foundation for Video World Models},
    author = {Federico Baldassarre and Marc Szafraniec and Basile Terver and Vasil Khalidov and Francisco Massa and Yann LeCun and Patrick Labatut and Maximilian Seitzer and Piotr Bojanowski},
    year = {2025},
    eprint = {2507.19468},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2507.19468v1},
    abstract = {We present DINO-world, a powerful generalist video world model trained to predict future frames in the latent space of DINOv2. By leveraging a pre-trained image encoder and training a future predictor on a large-scale uncurated video dataset, DINO-world learns the temporal dynamics of diverse scenes, from driving and indoor scenes to simulated environments. We show that DINO-world outperforms previous models on a variety of video prediction benchmarks, e.g. segmentation and depth forecasting, an...}
}

@misc{Bai2025_Whole_Body,
    title = {Whole-Body Conditioned Egocentric Video Prediction},
    author = {Yutong Bai and Danny Tran and Amir Bar and Yann LeCun and Trevor Darrell and Jitendra Malik},
    year = {2025},
    eprint = {2506.21552},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2506.21552v1},
    abstract = {We train models to Predict Ego-centric Video from human Actions (PEVA), given the past video and an action represented by the relative 3D body pose. By conditioning on kinematic pose trajectories, structured by the joint hierarchy of the body, our model learns to simulate how physical human actions shape the environment from a first-person point of view. We train an auto-regressive conditional diffusion transformer on Nymeria, a large-scale dataset of real-world egocentric video and body pose ca...}
}

@misc{Assran2025_V_JEPA,
    title = {V-JEPA 2: Self-Supervised Video Models Enable Understanding, Prediction and Planning},
    author = {Mido Assran and Adrien Bardes and David Fan and Quentin Garrido and Russell Howes and Mojtaba and Komeili and Matthew Muckley and Ammar Rizvi and Claire Roberts and Koustuv Sinha and Artem Zholus and Sergio Arnaud and Abha Gejji and Ada Martin and Francois Robert Hogan and Daniel Dugas and Piotr Bojanowski and Vasil Khalidov and Patrick Labatut and Francisco Massa and Marc Szafraniec and Kapil Krishnakumar and Yong Li and Xiaodong Ma and Sarath Chandar and Franziska Meier and Yann LeCun and Michael Rabbat and Nicolas Ballas},
    year = {2025},
    eprint = {2506.09985},
    archivePrefix = {arXiv},
    primaryClass = {cs.AI},
    url = {https://arxiv.org/abs/2506.09985v1},
    abstract = {A major challenge for modern AI is to learn to understand the world and learn to act largely by observation. This paper explores a self-supervised approach that combines internet-scale video data with a small amount of interaction data (robot trajectories), to develop models capable of understanding, predicting, and planning in the physical world. We first pre-train an action-free joint-embedding-predictive architecture, V-JEPA 2, on a video and image dataset comprising over 1 million hours of i...}
}

@misc{Goswami2025_OSVI_WM_,
    title = {OSVI-WM: One-Shot Visual Imitation for Unseen Tasks using World-Model-Guided Trajectory Generation},
    author = {Raktim Gautam Goswami and Prashanth Krishnamurthy and Yann LeCun and Farshad Khorrami},
    year = {2025},
    eprint = {2505.20425},
    archivePrefix = {arXiv},
    primaryClass = {cs.RO},
    url = {https://arxiv.org/abs/2505.20425v1},
    abstract = {Visual imitation learning enables robotic agents to acquire skills by observing expert demonstration videos. In the one-shot setting, the agent generates a policy after observing a single expert demonstration without additional fine-tuning. Existing approaches typically train and evaluate on the same set of tasks, varying only object configurations, and struggle to generalize to unseen tasks with different semantic or structural requirements. While some recent methods attempt to address this, th...}
}

@misc{Shani2025_From,
    title = {From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning},
    author = {Chen Shani and Liron Soffer and Dan Jurafsky and Yann LeCun and Ravid Shwartz-Ziv},
    year = {2025},
    eprint = {2505.17117},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL},
    url = {https://arxiv.org/abs/2505.17117v5},
    abstract = {Humans organize knowledge into compact categories that balance compression with semantic meaning preservation. Large Language Models (LLMs) demonstrate striking linguistic abilities, yet whether they achieve this same balance remains unclear. We apply the Information Bottleneck principle to quantitatively compare how LLMs and humans navigate this compression-meaning trade-off. Analyzing embeddings from 40+ LLMs against classic human categorization benchmarks, we uncover three key findings. First...}
}

@misc{Fan2025_Scaling,
    title = {Scaling Language-Free Visual Representation Learning},
    author = {David Fan and Shengbang Tong and Jiachen Zhu and Koustuv Sinha and Zhuang Liu and Xinlei Chen and Michael Rabbat and Nicolas Ballas and Yann LeCun and Amir Bar and Saining Xie},
    year = {2025},
    eprint = {2504.01017},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2504.01017v1},
    abstract = {Visual Self-Supervised Learning (SSL) currently underperforms Contrastive Language-Image Pretraining (CLIP) in multimodal settings such as Visual Question Answering (VQA). This multimodal gap is often attributed to the semantics introduced by language supervision, even though visual SSL and CLIP models are often trained on different data. In this work, we ask the question: "Do visual self-supervised approaches lag behind CLIP due to the lack of language supervision, or differences in the trainin...}
}

@misc{Zhu2025_Transformers,
    title = {Transformers without Normalization},
    author = {Jiachen Zhu and Xinlei Chen and Kaiming He and Yann LeCun and Zhuang Liu},
    year = {2025},
    eprint = {2503.10622},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2503.10622v2},
    abstract = {Normalization layers are ubiquitous in modern neural networks and have long been considered essential. This work demonstrates that Transformers without normalization can achieve the same or better performance using a remarkably simple technique. We introduce Dynamic Tanh (DyT), an element-wise operation \$DyT(\$x\$) = \tanh(α\$x\$)\$, as a drop-in replacement for normalization layers in Transformers. DyT is inspired by the observation that layer normalization in Transformers often produces tanh-like, ...}
}

@misc{Rudman2025_Forgotten,
    title = {Forgotten Polygons: Multimodal Large Language Models are Shape-Blind},
    author = {William Rudman and Michal Golovanevsky and Amir Bar and Vedant Palit and Yann LeCun and Carsten Eickhoff and Ritambhara Singh},
    year = {2025},
    eprint = {2502.15969},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2502.15969v4},
    abstract = {Despite strong performance on vision-language tasks, Multimodal Large Language Models (MLLMs) struggle with mathematical problem-solving, with both open-source and state-of-the-art models falling short of human performance on visual-math benchmarks. To systematically examine visual-mathematical reasoning in MLLMs, we (1) evaluate their understanding of geometric primitives, (2) test multi-step reasoning, and (3) explore a potential solution to improve visual reasoning capabilities. Our findings ...}
}

@misc{Sobal2025_Learning,
    title = {Learning from Reward-Free Offline Data: A Case for Planning with Latent Dynamics Models},
    author = {Vlad Sobal and Wancong Zhang and Kyunghyun Cho and Randall Balestriero and Tim G. J. Rudner and Yann LeCun},
    year = {2025},
    eprint = {2502.14819},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2502.14819v4},
    abstract = {A long-standing goal in AI is to develop agents capable of solving diverse tasks across a range of environments, including those never seen during training. Two dominant paradigms address this challenge: (i) reinforcement learning (RL), which learns policies via trial and error, and (ii) optimal control, which plans actions using a known or learned dynamics model. However, their comparative strengths in the offline setting - where agents must learn from reward-free trajectories - remain underexp...}
}

@misc{Garrido2025_Intuitive,
    title = {Intuitive physics understanding emerges from self-supervised pretraining on natural videos},
    author = {Quentin Garrido and Nicolas Ballas and Mahmoud Assran and Adrien Bardes and Laurent Najman and Michael Rabbat and Emmanuel Dupoux and Yann LeCun},
    year = {2025},
    eprint = {2502.11831},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2502.11831v1},
    abstract = {We investigate the emergence of intuitive physics understanding in general-purpose deep neural network models trained to predict masked regions in natural videos. Leveraging the violation-of-expectation framework, we find that video prediction models trained to predict outcomes in a learned representation space demonstrate an understanding of various intuitive physics properties, such as object permanence and shape consistency. In contrast, video prediction in pixel space and multimodal large la...}
}

@misc{Skean2025_Layer,
    title = {Layer by Layer: Uncovering Hidden Representations in Language Models},
    author = {Oscar Skean and Md Rifat Arefin and Dan Zhao and Niket Patel and Jalal Naghiyev and Yann LeCun and Ravid Shwartz-Ziv},
    year = {2025},
    eprint = {2502.02013},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2502.02013v2},
    abstract = {From extracting features to generating text, the outputs of large language models (LLMs) typically rely on the final layers, following the conventional wisdom that earlier layers capture only low-level cues. However, our analysis shows that intermediate layers can encode even richer representations, often improving performance on a range of downstream tasks. To explain and quantify these hidden-layer properties, we propose a unified framework of representation quality metrics based on informatio...}
}

@misc{Tong2024_MetaMorph_,
    title = {MetaMorph: Multimodal Understanding and Generation via Instruction Tuning},
    author = {Shengbang Tong and David Fan and Jiachen Zhu and Yunyang Xiong and Xinlei Chen and Koustuv Sinha and Michael Rabbat and Yann LeCun and Saining Xie and Zhuang Liu},
    year = {2024},
    eprint = {2412.14164},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2412.14164v1},
    abstract = {In this work, we propose Visual-Predictive Instruction Tuning (VPiT) - a simple and effective extension to visual instruction tuning that enables a pretrained LLM to quickly morph into an unified autoregressive model capable of generating both text and visual tokens. VPiT teaches an LLM to predict discrete text tokens and continuous visual tokens from any input sequence of image and text data curated in an instruction-following format. Our empirical investigation reveals several intriguing prope...}
}

@misc{Drozdov2024_Video,
    title = {Video Representation Learning with Joint-Embedding Predictive Architectures},
    author = {Katrina Drozdov and Ravid Shwartz-Ziv and Yann LeCun},
    year = {2024},
    eprint = {2412.10925},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2412.10925v1},
    abstract = {Video representation learning is an increasingly important topic in machine learning research. We present Video JEPA with Variance-Covariance Regularization (VJ-VCR): a joint-embedding predictive architecture for self-supervised video representation learning that employs variance and covariance regularization to avoid representation collapse. We show that hidden representations from our VJ-VCR contain abstract, high-level information about the input data. Specifically, they outperform representa...}
}

@misc{Skean2024_Does,
    title = {Does Representation Matter? Exploring Intermediate Layers in Large Language Models},
    author = {Oscar Skean and Md Rifat Arefin and Yann LeCun and Ravid Shwartz-Ziv},
    year = {2024},
    eprint = {2412.09563},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2412.09563v1},
    abstract = {Understanding what defines a good representation in large language models (LLMs) is fundamental to both theoretical understanding and practical applications. In this paper, we investigate the quality of intermediate representations in various LLM architectures, including Transformers and State Space Models (SSMs). We find that intermediate layers often yield more informative representations for downstream tasks than the final layers. To measure the representation quality, we adapt and apply a su...}
}

@misc{Zeevi2024_Rate_In_,
    title = {Rate-In: Information-Driven Adaptive Dropout Rates for Improved Inference-Time Uncertainty Estimation},
    author = {Tal Zeevi and Ravid Shwartz-Ziv and Yann LeCun and Lawrence H. Staib and John A. Onofrey},
    year = {2024},
    eprint = {2412.07169},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2412.07169v4},
    abstract = {Accurate uncertainty estimation is crucial for deploying neural networks in risk-sensitive applications such as medical diagnosis. Monte Carlo Dropout is a widely used technique for approximating predictive uncertainty by performing stochastic forward passes with dropout during inference. However, using static dropout rates across all layers and inputs can lead to suboptimal uncertainty estimates, as it fails to adapt to the varying characteristics of individual inputs and network layers. Existi...}
}

@misc{Bar2024_Navigation,
    title = {Navigation World Models},
    author = {Amir Bar and Gaoyue Zhou and Danny Tran and Trevor Darrell and Yann LeCun},
    year = {2024},
    eprint = {2412.03572},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2412.03572v2},
    abstract = {Navigation is a fundamental skill of agents with visual-motor capabilities. We introduce a Navigation World Model (NWM), a controllable video generation model that predicts future visual observations based on past observations and navigation actions. To capture complex environment dynamics, NWM employs a Conditional Diffusion Transformer (CDiT), trained on a diverse collection of egocentric videos of both human and robotic agents, and scaled up to 1 billion parameters. In familiar environments, ...}
}

@misc{Goswami2024_RoboPEPP_,
    title = {RoboPEPP: Vision-Based Robot Pose and Joint Angle Estimation through Embedding Predictive Pre-Training},
    author = {Raktim Gautam Goswami and Prashanth Krishnamurthy and Yann LeCun and Farshad Khorrami},
    year = {2024},
    eprint = {2411.17662},
    archivePrefix = {arXiv},
    primaryClass = {cs.RO},
    url = {https://arxiv.org/abs/2411.17662v2},
    abstract = {Vision-based pose estimation of articulated robots with unknown joint angles has applications in collaborative robotics and human-robot interaction tasks. Current frameworks use neural network encoders to extract image features and downstream layers to predict joint angles and robot pose. While images of robots inherently contain rich information about the robot's physical structures, existing methods often fail to leverage it fully; therefore, limiting performance under occlusions and truncatio...}
}

@misc{Chakraborty2024_Improving,
    title = {Improving Pre-trained Self-Supervised Embeddings Through Effective Entropy Maximization},
    author = {Deep Chakraborty and Yann LeCun and Tim G. J. Rudner and Erik Learned-Miller},
    year = {2024},
    eprint = {2411.15931},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2411.15931v2},
    abstract = {A number of different architectures and loss functions have been applied to the problem of self-supervised learning (SSL), with the goal of developing embeddings that provide the best possible pre-training for as-yet-unknown, lightly supervised downstream tasks. One of these SSL criteria is to maximize the entropy of a set of embeddings in some compact space. But the goal of maximizing the embedding entropy often depends -- whether explicitly or implicitly -- upon high dimensional entropy estima...}
}

@misc{Zhou2024_DINO_WM_,
    title = {DINO-WM: World Models on Pre-trained Visual Features enable Zero-shot Planning},
    author = {Gaoyue Zhou and Hengkai Pan and Yann LeCun and Lerrel Pinto},
    year = {2024},
    eprint = {2411.04983},
    archivePrefix = {arXiv},
    primaryClass = {cs.RO},
    url = {https://arxiv.org/abs/2411.04983v2},
    abstract = {The ability to predict future outcomes given control actions is fundamental for physical reasoning. However, such predictive models, often called world models, remains challenging to learn and are typically developed for task-specific solutions with online policy learning. To unlock world models' true potential, we argue that they should 1) be trainable on offline, pre-collected trajectories, 2) support test-time behavior optimization, and 3) facilitate task-agnostic reasoning. To this end, we p...}
}

@misc{Arefin2024_Seq_VCR_,
    title = {Seq-VCR: Preventing Collapse in Intermediate Transformer Representations for Enhanced Reasoning},
    author = {Md Rifat Arefin and Gopeshh Subbaraj and Nicolas Gontier and Yann LeCun and Irina Rish and Ravid Shwartz-Ziv and Christopher Pal},
    year = {2024},
    eprint = {2411.02344},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2411.02344v2},
    abstract = {Decoder-only Transformers often struggle with complex reasoning tasks, particularly arithmetic reasoning requiring multiple sequential operations. In this work, we identify representation collapse in the model's intermediate layers as a key factor limiting their reasoning capabilities. To address this, we propose Sequential Variance-Covariance Regularization (Seq-VCR), which enhances the entropy of intermediate representations and prevents collapse. Combined with dummy pause tokens as substitute...}
}

@misc{Witowski2024_Multi_modal,
    title = {Multi-modal AI for comprehensive breast cancer prognostication},
    author = {Jan Witowski and Ken G. Zeng and Joseph Cappadona and Jailan Elayoubi and Khalil Choucair and Elena Diana Chiru and Nancy Chan and Young-Joon Kang and Frederick Howard and Irina Ostrovnaya and Carlos Fernandez-Granda and Freya Schnabel and Zoe Steinsnyder and Ugur Ozerdem and Kangning Liu and Waleed Abdulsattar and Yu Zong and Lina Daoud and Rafic Beydoun and Anas Saad and Nitya Thakore and Mohammad Sadic and Frank Yeung and Elisa Liu and Theodore Hill and Benjamin Swett and Danielle Rigau and Andrew Clayburn and Valerie Speirs and Marcus Vetter and Lina Sojak and Simone Soysal and Daniel Baumhoer and Jia-Wern Pan and Haslina Makmur and Soo-Hwang Teo and Linda Ma Pak and Victor Angel and Dovile Zilenaite-Petrulaitiene and Arvydas Laurinavicius and Natalie Klar and Brian D. Piening and Carlo Bifulco and Sun-Young Jun and Jae Pak Yi and Su Hyun Lim and Adam Brufsky and Francisco J. Esteva and Lajos Pusztai and Yann LeCun and Krzysztof J. Geras},
    year = {2024},
    eprint = {2410.21256},
    archivePrefix = {arXiv},
    primaryClass = {cs.AI},
    url = {https://arxiv.org/abs/2410.21256v2},
    abstract = {Treatment selection in breast cancer is guided by molecular subtypes and clinical characteristics. However, current tools including genomic assays lack the accuracy required for optimal clinical decision-making. We developed a novel artificial intelligence (AI)-based approach that integrates digital pathology images with clinical data, providing a more robust and effective method for predicting the risk of cancer recurrence in breast cancer patients. Specifically, we utilized a vision transforme...}
}

@misc{Wang2024_PooDLe_,
    title = {PooDLe: Pooled and dense self-supervised learning from naturalistic videos},
    author = {Alex N. Wang and Christopher Hoang and Yuwen Xiong and Yann LeCun and Mengye Ren},
    year = {2024},
    eprint = {2408.11208},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2408.11208v3},
    abstract = {Self-supervised learning has driven significant progress in learning from single-subject, iconic images. However, there are still unanswered questions about the use of minimally-curated, naturalistic video data, which contain dense scenes with many independent objects, imbalanced class distributions, and varying object sizes. In this paper, we propose PooDLe, a self-supervised learning method that combines an invariance-based objective on pooled representations with a dense SSL objective that en...}
}

@misc{Sobal2024___mathbb_X___Sample,
    title = {\$\mathbb\{X\}\$-Sample Contrastive Loss: Improving Contrastive Learning with Sample Similarity Graphs},
    author = {Vlad Sobal and Mark Ibrahim and Randall Balestriero and Vivien Cabannes and Diane Bouchacourt and Pietro Astolfi and Kyunghyun Cho and Yann LeCun},
    year = {2024},
    eprint = {2407.18134},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2407.18134v2},
    abstract = {Learning good representations involves capturing the diverse ways in which data samples relate. Contrastive loss - an objective matching related samples - underlies methods from self-supervised to multimodal learning. Contrastive losses, however, can be viewed more broadly as modifying a similarity graph to indicate how samples should relate in the embedding space. This view reveals a shortcoming in contrastive learning: the similarity graph is binary, as only one sample is the related positive ...}
}

@misc{White2024_LiveBench_,
    title = {LiveBench: A Challenging, Contamination-Limited LLM Benchmark},
    author = {Colin White and Samuel Dooley and Manley Roberts and Arka Pal and Ben Feuer and Siddhartha Jain and Ravid Shwartz-Ziv and Neel Jain and Khalid Saifullah and Sreemanti Dey and Shubh-Agrawal and Sandeep Singh Sandha and Siddartha Naidu and Chinmay Hegde and Yann LeCun and Tom Goldstein and Willie Neiswanger and Micah Goldblum},
    year = {2024},
    eprint = {2406.19314},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL},
    url = {https://arxiv.org/abs/2406.19314v2},
    abstract = {Test set contamination, wherein test data from a benchmark ends up in a newer model's training set, is a well-documented obstacle for fair LLM evaluation and can quickly render benchmarks obsolete. To mitigate this, many recent benchmarks crowdsource new prompts and evaluations from human or LLM judges; however, these can introduce significant biases, and break down when scoring hard questions. In this work, we introduce a new benchmark for LLMs designed to be resistant to both test set contamin...}
}

@misc{Tong2024_Cambrian_1_,
    title = {Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs},
    author = {Shengbang Tong and Ellis Brown and Penghao Wu and Sanghyun Woo and Manoj Middepogu and Sai Charitha Akula and Jihan Yang and Shusheng Yang and Adithya Iyer and Xichen Pan and Ziteng Wang and Rob Fergus and Yann LeCun and Saining Xie},
    year = {2024},
    eprint = {2406.16860},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2406.16860v2},
    abstract = {We introduce Cambrian-1, a family of multimodal LLMs (MLLMs) designed with a vision-centric approach. While stronger language models can enhance multimodal capabilities, the design choices for vision components are often insufficiently explored and disconnected from visual representation learning research. This gap hinders accurate sensory grounding in real-world scenarios. Our study uses LLMs and visual instruction tuning as an interface to evaluate various visual representations, offering new ...}
}

@misc{Shwartz_Ziv2024_Just,
    title = {Just How Flexible are Neural Networks in Practice?},
    author = {Ravid Shwartz-Ziv and Micah Goldblum and Arpit Bansal and C. Bayan Bruss and Yann LeCun and Andrew Gordon Wilson},
    year = {2024},
    eprint = {2406.11463},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2406.11463v1},
    abstract = {It is widely believed that a neural network can fit a training set containing at least as many samples as it has parameters, underpinning notions of overparameterized and underparameterized models. In practice, however, we only find solutions accessible via our training procedure, including the optimizer and regularizers, limiting flexibility. Moreover, the exact parameterization of the function class, built into an architecture, shapes its loss surface and impacts the minima we find. In this wo...}
}

@misc{Schaeffer2024_Towards,
    title = {Towards an Improved Understanding and Utilization of Maximum Manifold Capacity Representations},
    author = {Rylan Schaeffer and Victor Lecomte and Dhruv Bhandarkar Pai and Andres Carranza and Berivan Isik and Alyssa Unell and Mikail Khona and Thomas Yerxa and Yann LeCun and SueYeon Chung and Andrey Gromov and Ravid Shwartz-Ziv and Sanmi Koyejo},
    year = {2024},
    eprint = {2406.09366},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2406.09366v1},
    abstract = {Maximum Manifold Capacity Representations (MMCR) is a recent multi-view self-supervised learning (MVSSL) method that matches or surpasses other leading MVSSL methods. MMCR is intriguing because it does not fit neatly into any of the commonplace MVSSL lineages, instead originating from a statistical mechanical perspective on the linear separability of data manifolds. In this paper, we seek to improve our understanding and our utilization of MMCR. To better understand MMCR, we leverage tools from ...}
}

@misc{Hansen2024_Hierarchical,
    title = {Hierarchical World Models as Visual Whole-Body Humanoid Controllers},
    author = {Nicklas Hansen and Jyothir S and Vlad Sobal and Yann LeCun and Xiaolong Wang and Hao Su},
    year = {2024},
    eprint = {2405.18418},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2405.18418v3},
    abstract = {Whole-body control for humanoids is challenging due to the high-dimensional nature of the problem, coupled with the inherent instability of a bipedal morphology. Learning from visual observations further exacerbates this difficulty. In this work, we explore highly data-driven approaches to visual whole-body humanoid control based on reinforcement learning, without any simplifying assumptions, reward design, or skill primitives. Specifically, we propose a hierarchical world model in which a high-...}
}

@misc{Basdevant2024_Towards,
    title = {Towards a Framework for Openness in Foundation Models: Proceedings from the Columbia Convening on Openness in Artificial Intelligence},
    author = {Adrien Basdevant and Camille François and Victor Storchan and Kevin Bankston and Ayah Bdeir and Brian Behlendorf and Merouane Debbah and Sayash Kapoor and Yann LeCun and Mark Surman and Helen King-Turvey and Nathan Lambert and Stefano Maffulli and Nik Marda and Govind Shivkumar and Justine Tunney},
    year = {2024},
    eprint = {2405.15802},
    archivePrefix = {arXiv},
    primaryClass = {cs.SE},
    url = {https://arxiv.org/abs/2405.15802v1},
    abstract = {Over the past year, there has been a robust debate about the benefits and risks of open sourcing foundation models. However, this discussion has often taken place at a high level of generality or with a narrow focus on specific technical attributes. In part, this is because defining open source for foundation models has proven tricky, given its significant differences from traditional software development. In order to inform more practical and nuanced decisions about opening AI systems, includin...}
}

@misc{Zhai2024_Fine_Tuning,
    title = {Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning},
    author = {Yuexiang Zhai and Hao Bai and Zipeng Lin and Jiayi Pan and Shengbang Tong and Yifei Zhou and Alane Suhr and Saining Xie and Yann LeCun and Yi Ma and Sergey Levine},
    year = {2024},
    eprint = {2405.10292},
    archivePrefix = {arXiv},
    primaryClass = {cs.AI},
    url = {https://arxiv.org/abs/2405.10292v3},
    abstract = {Large vision-language models (VLMs) fine-tuned on specialized visual instruction-following data have exhibited impressive language reasoning capabilities across various scenarios. However, this fine-tuning paradigm may not be able to efficiently learn optimal decision-making agents in multi-step goal-directed tasks from interactive environments. To address this challenge, we propose an algorithmic framework that fine-tunes VLMs with reinforcement learning (RL). Specifically, our framework provid...}
}

@misc{Press2024_The,
    title = {The Entropy Enigma: Success and Failure of Entropy Minimization},
    author = {Ori Press and Ravid Shwartz-Ziv and Yann LeCun and Matthias Bethge},
    year = {2024},
    eprint = {2405.05012},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2405.05012v2},
    abstract = {Entropy minimization (EM) is frequently used to increase the accuracy of classification models when they're faced with new data at test time. EM is a self-supervised learning method that optimizes classifiers to assign even higher probabilities to their top predicted classes. In this paper, we analyze why EM works when adapting a model for a few steps and why it eventually fails after adapting for many steps. We show that, at first, EM causes the model to embed test images close to training imag...}
}

@misc{Moutakanni2024_Advancing,
    title = {Advancing human-centric AI for robust X-ray analysis through holistic self-supervised learning},
    author = {Théo Moutakanni and Piotr Bojanowski and Guillaume Chassagnon and Céline Hudelot and Armand Joulin and Yann LeCun and Matthew Muckley and Maxime Oquab and Marie-Pierre Revel and Maria Vakalopoulou},
    year = {2024},
    eprint = {2405.01469},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2405.01469v1},
    abstract = {AI Foundation models are gaining traction in various applications, including medical fields like radiology. However, medical foundation models are often tested on limited tasks, leaving their generalisability and biases unexplored. We present RayDINO, a large visual encoder trained by self-supervision on 873k chest X-rays. We compare RayDINO to previous state-of-the-art models across nine radiology tasks, from classification and dense segmentation to text generation, and provide an in depth anal...}
}

@misc{Bar2024_EgoPet_,
    title = {EgoPet: Egomotion and Interaction Data from an Animal's Perspective},
    author = {Amir Bar and Arya Bakhtiar and Danny Tran and Antonio Loquercio and Jathushan Rajasegaran and Yann LeCun and Amir Globerson and Trevor Darrell},
    year = {2024},
    eprint = {2404.09991},
    archivePrefix = {arXiv},
    primaryClass = {cs.RO},
    url = {https://arxiv.org/abs/2404.09991v1},
    abstract = {Animals perceive the world to plan their actions and interact with other agents to accomplish complex tasks, demonstrating capabilities that are still unmatched by AI systems. To advance our understanding and reduce the gap between the capabilities of animals and AI systems, we introduce a dataset of pet egomotion imagery with diverse examples of simultaneous egomotion and multi-agent interaction. Current video datasets separately contain egomotion and interaction examples, but rarely both at th...}
}

@misc{Garrido2024_Learning,
    title = {Learning and Leveraging World Models in Visual Representation Learning},
    author = {Quentin Garrido and Mahmoud Assran and Nicolas Ballas and Adrien Bardes and Laurent Najman and Yann LeCun},
    year = {2024},
    eprint = {2403.00504},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2403.00504v1},
    abstract = {Joint-Embedding Predictive Architecture (JEPA) has emerged as a promising self-supervised approach that learns by leveraging a world model. While previously limited to predicting missing parts of an input, we explore how to generalize the JEPA prediction task to a broader set of corruptions. We introduce Image World Models, an approach that goes beyond masked image modeling and learns to predict the effect of global photometric transformations in latent space. We study the recipe of learning per...}
}

@misc{Balestriero2024_Learning,
    title = {Learning by Reconstruction Produces Uninformative Features For Perception},
    author = {Randall Balestriero and Yann LeCun},
    year = {2024},
    eprint = {2402.11337},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2402.11337v1},
    abstract = {Input space reconstruction is an attractive representation learning paradigm. Despite interpretability of the reconstruction and generation, we identify a misalignment between learning by reconstruction, and learning for perception. We show that the former allocates a model's capacity towards a subspace of the data explaining the observed variance--a subspace with uninformative features for the latter. For example, the supervised TinyImagenet task with images projected onto the top subspace expl...}
}

@misc{Bardes2024_Revisiting,
    title = {Revisiting Feature Prediction for Learning Visual Representations from Video},
    author = {Adrien Bardes and Quentin Garrido and Jean Ponce and Xinlei Chen and Michael Rabbat and Yann LeCun and Mahmoud Assran and Nicolas Ballas},
    year = {2024},
    eprint = {2404.08471},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2404.08471v1},
    abstract = {This paper explores feature prediction as a stand-alone objective for unsupervised learning from video and introduces V-JEPA, a collection of vision models trained solely using a feature prediction objective, without the use of pretrained image encoders, text, negative examples, reconstruction, or other sources of supervision. The models are trained on 2 million videos collected from public datasets and are evaluated on downstream image and video tasks. Our results show that learning by predicti...}
}

@misc{He2024_G_Retriever_,
    title = {G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering},
    author = {Xiaoxin He and Yijun Tian and Yifei Sun and Nitesh V. Chawla and Thomas Laurent and Yann LeCun and Xavier Bresson and Bryan Hooi},
    year = {2024},
    eprint = {2402.07630},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2402.07630v3},
    abstract = {Given a graph with textual attributes, we enable users to `chat with their graph': that is, to ask questions about the graph using a conversational interface. In response to a user's questions, our method provides textual replies and highlights the relevant parts of the graph. While existing works integrate large language models (LLMs) and graph neural networks (GNNs) in various ways, they mostly focus on either conventional graph tasks (such as node, edge, and graph classification), or on answe...}
}

@misc{Balestriero2024_Fast,
    title = {Fast and Exact Enumeration of Deep Networks Partitions Regions},
    author = {Randall Balestriero and Yann LeCun},
    year = {2024},
    eprint = {2401.11188},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2401.11188v1},
    abstract = {One fruitful formulation of Deep Networks (DNs) enabling their theoretical study and providing practical guidelines to practitioners relies on Piecewise Affine Splines. In that realm, a DN's input-mapping is expressed as per-region affine mapping where those regions are implicitly determined by the model's architecture and form a partition of their input space. That partition -- which is involved in all the results spanned from this line of research -- has so far only been computed on \$2/3\$-dime...}
}

@misc{Tong2024_Eyes,
    title = {Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs},
    author = {Shengbang Tong and Zhuang Liu and Yuexiang Zhai and Yi Ma and Yann LeCun and Saining Xie},
    year = {2024},
    eprint = {2401.06209},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2401.06209v2},
    abstract = {Is vision good enough for language? Recent advancements in multimodal models primarily stem from the powerful reasoning abilities of large language models (LLMs). However, the visual component typically depends only on the instance-level contrastive language-image pre-training (CLIP). Our research reveals that the visual capabilities in recent multimodal LLMs (MLLMs) still exhibit systematic shortcomings. To understand the roots of these errors, we explore the gap between the visual embedding sp...}
}

@misc{S2023_Gradient_based,
    title = {Gradient-based Planning with World Models},
    author = {Jyothir S and Siddhartha Jalagam and Yann LeCun and Vlad Sobal},
    year = {2023},
    eprint = {2312.17227},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2312.17227v1},
    abstract = {The enduring challenge in the field of artificial intelligence has been the control of systems to achieve desired behaviours. While for systems governed by straightforward dynamics equations, methods like Linear Quadratic Regulation (LQR) have historically proven highly effective, most real-world tasks, which require a general problem-solver, demand world models with dynamics that cannot be easily described by simple equations. Consequently, these models must be learned from data using neural ne...}
}

@misc{Mialon2023_GAIA_,
    title = {GAIA: a benchmark for General AI Assistants},
    author = {Grégoire Mialon and Clémentine Fourrier and Craig Swift and Thomas Wolf and Yann LeCun and Thomas Scialom},
    year = {2023},
    eprint = {2311.12983},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL},
    url = {https://arxiv.org/abs/2311.12983v1},
    abstract = {We introduce GAIA, a benchmark for General AI Assistants that, if solved, would represent a milestone in AI research. GAIA proposes real-world questions that require a set of fundamental abilities such as reasoning, multi-modality handling, web browsing, and generally tool-use proficiency. GAIA questions are conceptually simple for humans yet challenging for most advanced AIs: we show that human respondents obtain 92\\% vs. 15\\% for GPT-4 equipped with plugins. This notable performance disparity ...}
}

@misc{Yun2023_URLOST_,
    title = {URLOST: Unsupervised Representation Learning without Stationarity or Topology},
    author = {Zeyu Yun and Juexiao Zhang and Yann LeCun and Yubei Chen},
    year = {2023},
    eprint = {2310.04496},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2310.04496v2},
    abstract = {Unsupervised representation learning has seen tremendous progress. However, it is constrained by its reliance on domain specific stationarity and topology, a limitation not found in biological intelligence systems. For instance, unlike computer vision, human vision can process visual signals sampled from highly irregular and non-stationary sensors. We introduce a novel framework that learns from high-dimensional data without prior knowledge of stationarity and topology. Our model, abbreviated as...}
}

@misc{Bar2023_Stochastic,
    title = {Stochastic positional embeddings improve masked image modeling},
    author = {Amir Bar and Florian Bordes and Assaf Shocher and Mahmoud Assran and Pascal Vincent and Nicolas Ballas and Trevor Darrell and Amir Globerson and Yann LeCun},
    year = {2023},
    eprint = {2308.00566},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2308.00566v2},
    abstract = {Masked Image Modeling (MIM) is a promising self-supervised learning approach that enables learning from unlabeled images. Despite its recent success, learning good representations through MIM remains challenging because it requires predicting the right semantic content in accurate locations. For example, given an incomplete picture of a dog, we can guess that there is a tail, but we cannot determine its exact location. In this work, we propose to incorporate location uncertainty into MIM by usin...}
}

@misc{Bardes2023_MC_JEPA_,
    title = {MC-JEPA: A Joint-Embedding Predictive Architecture for Self-Supervised Learning of Motion and Content Features},
    author = {Adrien Bardes and Jean Ponce and Yann LeCun},
    year = {2023},
    eprint = {2307.12698},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2307.12698v1},
    abstract = {Self-supervised learning of visual representations has been focusing on learning content features, which do not capture object motion or location, and focus on identifying and differentiating objects in images and videos. On the other hand, optical flow estimation is a task that does not involve understanding the content of the images on which it is estimated. We unify the two approaches and introduce MC-JEPA, a joint-embedding predictive architecture and self-supervised learning approach to joi...}
}

@misc{Mialon2023_Self_Supervised,
    title = {Self-Supervised Learning with Lie Symmetries for Partial Differential Equations},
    author = {Grégoire Mialon and Quentin Garrido and Hannah Lawrence and Danyal Rehman and Yann LeCun and Bobak T. Kiani},
    year = {2023},
    eprint = {2307.05432},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2307.05432v2},
    abstract = {Machine learning for differential equations paves the way for computationally efficient alternatives to numerical solvers, with potentially broad impacts in science and engineering. Though current algorithms typically require simulated training data tailored to a given setting, one may instead wish to learn useful information from heterogeneous sources, or from real dynamical systems observations that are messy or incomplete. In this work, we learn general-purpose representations of PDEs from he...}
}

@misc{Zhu2023_Variance_Covariance,
    title = {Variance-Covariance Regularization Improves Representation Learning},
    author = {Jiachen Zhu and Katrina Evtimova and Yubei Chen and Ravid Shwartz-Ziv and Yann LeCun},
    year = {2023},
    eprint = {2306.13292},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2306.13292v2},
    abstract = {Transfer learning plays a key role in advancing machine learning models, yet conventional supervised pretraining often undermines feature transferability by prioritizing features that minimize the pretraining loss. In this work, we adapt a self-supervised learning regularization technique from the VICReg method to supervised learning contexts, introducing Variance-Covariance Regularization (VCReg). This adaptation encourages the network to learn high-variance, low-covariance representations, pro...}
}

@misc{Dawid2023_Introduction,
    title = {Introduction to Latent Variable Energy-Based Models: A Path Towards Autonomous Machine Intelligence},
    author = {Anna Dawid and Yann LeCun},
    year = {2023},
    doi = {10.1088/1742-5468/ad292b},
    eprint = {2306.02572},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2306.02572v1},
    abstract = {Current automated systems have crucial limitations that need to be addressed before artificial intelligence can reach human-like levels and bring new technological revolutions. Among others, our societies still lack Level 5 self-driving cars, domestic robots, and virtual assistants that learn reliable world models, reason, and plan complex action sequences. In these notes, we summarize the main ideas behind the architecture of autonomous intelligence of the future proposed by Yann LeCun. In part...}
}

@misc{He2023_Harnessing,
    title = {Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning},
    author = {Xiaoxin He and Xavier Bresson and Thomas Laurent and Adam Perold and Yann LeCun and Bryan Hooi},
    year = {2023},
    eprint = {2305.19523},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2305.19523v5},
    abstract = {Representation learning on text-attributed graphs (TAGs) has become a critical research problem in recent years. A typical example of a TAG is a paper citation graph, where the text of each paper serves as node attributes. Initial graph neural network (GNN) pipelines handled these text attributes by transforming them into shallow or hand-crafted features, such as skip-gram or bag-of-words features. Recent efforts have focused on enhancing these pipelines with language models (LMs), which typical...}
}

@misc{Ben_Shaul2023_Reverse,
    title = {Reverse Engineering Self-Supervised Learning},
    author = {Ido Ben-Shaul and Ravid Shwartz-Ziv and Tomer Galanti and Shai Dekel and Yann LeCun},
    year = {2023},
    eprint = {2305.15614},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2305.15614v2},
    abstract = {Self-supervised learning (SSL) is a powerful tool in machine learning, but understanding the learned representations and their underlying mechanisms remains a challenge. This paper presents an in-depth empirical analysis of SSL-trained representations, encompassing diverse models, architectures, and hyperparameters. Our study reveals an intriguing aspect of the SSL training process: it inherently facilitates the clustering of samples with respect to semantic labels, which is surprisingly driven ...}
}

@misc{Balestriero2023_A,
    title = {A Cookbook of Self-Supervised Learning},
    author = {Randall Balestriero and Mark Ibrahim and Vlad Sobal and Ari Morcos and Shashank Shekhar and Tom Goldstein and Florian Bordes and Adrien Bardes and Gregoire Mialon and Yuandong Tian and Avi Schwarzschild and Andrew Gordon Wilson and Jonas Geiping and Quentin Garrido and Pierre Fernandez and Amir Bar and Hamed Pirsiavash and Yann LeCun and Micah Goldblum},
    year = {2023},
    eprint = {2304.12210},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2304.12210v2},
    abstract = {Self-supervised learning, dubbed the dark matter of intelligence, is a promising path to advance machine learning. Yet, much like cooking, training SSL methods is a delicate art with a high barrier to entry. While many components are familiar, successfully training a SSL method involves a dizzying set of choices from the pretext tasks to training hyper-parameters. Our goal is to lower the barrier to entry into SSL research by laying the foundations and latest SSL recipes in the style of a cookbo...}
}

@misc{Shwartz_Ziv2023_To,
    title = {To Compress or Not to Compress- Self-Supervised Learning and Information Theory: A Review},
    author = {Ravid Shwartz-Ziv and Yann LeCun},
    year = {2023},
    eprint = {2304.09355},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2304.09355v5},
    abstract = {Deep neural networks excel in supervised learning tasks but are constrained by the need for extensive labeled data. Self-supervised learning emerges as a promising alternative, allowing models to learn without explicit labels. Information theory, and notably the information bottleneck principle, has been pivotal in shaping deep neural networks. This principle focuses on optimizing the trade-off between compression and preserving relevant information, providing a foundation for efficient network ...}
}

@misc{Tong2023_EMP_SSL_,
    title = {EMP-SSL: Towards Self-Supervised Learning in One Training Epoch},
    author = {Shengbang Tong and Yubei Chen and Yi Ma and Yann Lecun},
    year = {2023},
    eprint = {2304.03977},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2304.03977v1},
    abstract = {Recently, self-supervised learning (SSL) has achieved tremendous success in learning image representation. Despite the empirical success, most self-supervised learning methods are rather "inefficient" learners, typically taking hundreds of training epochs to fully converge. In this work, we show that the key towards efficient self-supervised learning is to increase the number of crops from each image instance. Leveraging one of the state-of-the-art SSL method, we introduce a simplistic form of s...}
}

@misc{Cabannes2023_Active,
    title = {Active Self-Supervised Learning: A Few Low-Cost Relationships Are All You Need},
    author = {Vivien Cabannes and Leon Bottou and Yann Lecun and Randall Balestriero},
    year = {2023},
    eprint = {2303.15256},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2303.15256v2},
    abstract = {Self-Supervised Learning (SSL) has emerged as the solution of choice to learn transferable representations from unlabeled data. However, SSL requires to build samples that are known to be semantically akin, i.e. positive views. Requiring such knowledge is the main limitation of SSL and is often tackled by ad-hoc strategies e.g. applying known data-augmentations to the same input. In this work, we formalize and generalize this principle through Positive Active Learning (PAL) where an oracle queri...}
}

@misc{Shwartz_Ziv2023_An,
    title = {An Information-Theoretic Perspective on Variance-Invariance-Covariance Regularization},
    author = {Ravid Shwartz-Ziv and Randall Balestriero and Kenji Kawaguchi and Tim G. J. Rudner and Yann LeCun},
    year = {2023},
    eprint = {2303.00633},
    archivePrefix = {arXiv},
    primaryClass = {cs.IT},
    url = {https://arxiv.org/abs/2303.00633v4},
    abstract = {Variance-Invariance-Covariance Regularization (VICReg) is a self-supervised learning (SSL) method that has shown promising results on a variety of tasks. However, the fundamental mechanisms underlying VICReg remain unexplored. In this paper, we present an information-theoretic perspective on the VICReg objective. We begin by deriving information-theoretic quantities for deterministic networks as an alternative to unrealistic stochastic network assumptions. We then relate the optimization of the ...}
}

@misc{Mialon2023_Augmented,
    title = {Augmented Language Models: a Survey},
    author = {Grégoire Mialon and Roberto Dessì and Maria Lomeli and Christoforos Nalmpantis and Ram Pasunuru and Roberta Raileanu and Baptiste Rozière and Timo Schick and Jane Dwivedi-Yu and Asli Celikyilmaz and Edouard Grave and Yann LeCun and Thomas Scialom},
    year = {2023},
    eprint = {2302.07842},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL},
    url = {https://arxiv.org/abs/2302.07842v1},
    abstract = {This survey reviews works in which language models (LMs) are augmented with reasoning skills and the ability to use tools. The former is defined as decomposing a potentially complex task into simpler subtasks while the latter consists in calling external modules such as a code interpreter. LMs can leverage these augmentations separately or in combination via heuristics, or learn to do so from demonstrations. While adhering to a standard missing tokens prediction objective, such augmented LMs can...}
}

@misc{Garrido2023_Self_supervised,
    title = {Self-supervised learning of Split Invariant Equivariant representations},
    author = {Quentin Garrido and Laurent Najman and Yann Lecun},
    year = {2023},
    eprint = {2302.10283},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2302.10283v2},
    abstract = {Recent progress has been made towards learning invariant or equivariant representations with self-supervised learning. While invariant methods are evaluated on large scale datasets, equivariant ones are evaluated in smaller, more controlled, settings. We aim at bridging the gap between the two in order to learn more diverse representations that are suitable for a wide range of tasks. We start by introducing a dataset called 3DIEBench, consisting of renderings from 3D models over  55 classes and ...}
}

@misc{Cabannes2023_The,
    title = {The SSL Interplay: Augmentations, Inductive Bias, and Generalization},
    author = {Vivien Cabannes and Bobak T. Kiani and Randall Balestriero and Yann LeCun and Alberto Bietti},
    year = {2023},
    eprint = {2302.02774},
    archivePrefix = {arXiv},
    primaryClass = {stat.ML},
    url = {https://arxiv.org/abs/2302.02774v2},
    abstract = {Self-supervised learning (SSL) has emerged as a powerful framework to learn representations from raw data without supervision. Yet in practice, engineers face issues such as instability in tuning optimizers and collapse of representations during training. Such challenges motivate the need for a theory to shed light on the complex interplay between the choice of data augmentation, network architecture, and training algorithm. We study such an interplay with a precise analysis of generalization pe...}
}

@misc{Siddiqui2023_Blockwise,
    title = {Blockwise Self-Supervised Learning at Scale},
    author = {Shoaib Ahmed Siddiqui and David Krueger and Yann LeCun and Stéphane Deny},
    year = {2023},
    eprint = {2302.01647},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2302.01647v2},
    abstract = {Current state-of-the-art deep networks are all powered by backpropagation. In this paper, we explore alternatives to full backpropagation in the form of blockwise learning rules, leveraging the latest developments in self-supervised learning. We show that a blockwise pretraining procedure consisting of training independently the 4 main blocks of layers of a ResNet-50 with Barlow Twins' loss function at each block performs almost as well as end-to-end backpropagation on ImageNet: a linear probe t...}
}

@misc{Assran2023_Self_Supervised,
    title = {Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture},
    author = {Mahmoud Assran and Quentin Duval and Ishan Misra and Piotr Bojanowski and Pascal Vincent and Michael Rabbat and Yann LeCun and Nicolas Ballas},
    year = {2023},
    eprint = {2301.08243},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2301.08243v3},
    abstract = {This paper demonstrates an approach for learning highly semantic image representations without relying on hand-crafted data-augmentations. We introduce the Image-based Joint-Embedding Predictive Architecture (I-JEPA), a non-generative approach for self-supervised learning from images. The idea behind I-JEPA is simple: from a single context block, predict the representations of various target blocks in the same image. A core design choice to guide I-JEPA towards producing semantic representations...}
}

@misc{He2022_A,
    title = {A Generalization of ViT/MLP-Mixer to Graphs},
    author = {Xiaoxin He and Bryan Hooi and Thomas Laurent and Adam Perold and Yann LeCun and Xavier Bresson},
    year = {2022},
    eprint = {2212.13350},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2212.13350v2},
    abstract = {Graph Neural Networks (GNNs) have shown great potential in the field of graph representation learning. Standard GNNs define a local message-passing mechanism which propagates information over the whole graph domain by stacking multiple layers. This paradigm suffers from two major limitations, over-squashing and poor long-range dependencies, that can be solved using global attention but significantly increases the computational cost to quadratic complexity. In this work, we propose an alternative...}
}

@misc{Sobal2022_Joint,
    title = {Joint Embedding Predictive Architectures Focus on Slow Features},
    author = {Vlad Sobal and Jyothir S and Siddhartha Jalagam and Nicolas Carion and Kyunghyun Cho and Yann LeCun},
    year = {2022},
    eprint = {2211.10831},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2211.10831v1},
    abstract = {Many common methods for learning a world model for pixel-based environments use generative architectures trained with pixel-level reconstruction objectives. Recently proposed Joint Embedding Predictive Architectures (JEPA) offer a reconstruction-free alternative. In this work, we analyze performance of JEPA trained with VICReg and SimCLR objectives in the fully offline setting without access to rewards, and compare the results to the performance of the generative architecture. We test the method...}
}

@misc{Balestriero2022_POLICE_,
    title = {POLICE: Provably Optimal Linear Constraint Enforcement for Deep Neural Networks},
    author = {Randall Balestriero and Yann LeCun},
    year = {2022},
    eprint = {2211.01340},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2211.01340v3},
    abstract = {Deep Neural Networks (DNNs) outshine alternative function approximators in many settings thanks to their modularity in composing any desired differentiable operator. The formed parametrized functional is then tuned to solve a task at hand from simple gradient descent. This modularity comes at the cost of making strict enforcement of constraints on DNNs, e.g. from a priori knowledge of the task, or from desired physical properties, an open challenge. In this paper we propose the first provable af...}
}

@misc{Tong2022_Unsupervised,
    title = {Unsupervised Learning of Structured Representations via Closed-Loop Transcription},
    author = {Shengbang Tong and Xili Dai and Yubei Chen and Mingyang Li and Zengyi Li and Brent Yi and Yann LeCun and Yi Ma},
    year = {2022},
    eprint = {2210.16782},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2210.16782v1},
    abstract = {This paper proposes an unsupervised method for learning a unified representation that serves both discriminative and generative purposes. While most existing unsupervised learning approaches focus on a representation for only one of these two goals, we show that a unified representation can enjoy the mutual benefits of having both. Such a representation is attainable by generalizing the recently proposed \textit\{closed-loop transcription\} framework, known as CTRL, to the unsupervised setting. Th...}
}

@misc{Zador2022_Toward,
    title = {Toward Next-Generation Artificial Intelligence: Catalyzing the NeuroAI Revolution},
    author = {Anthony Zador and Sean Escola and Blake Richards and Bence Ölveczky and Yoshua Bengio and Kwabena Boahen and Matthew Botvinick and Dmitri Chklovskii and Anne Churchland and Claudia Clopath and James DiCarlo and Surya Ganguli and Jeff Hawkins and Konrad Koerding and Alexei Koulakov and Yann LeCun and Timothy Lillicrap and Adam Marblestone and Bruno Olshausen and Alexandre Pouget and Cristina Savin and Terrence Sejnowski and Eero Simoncelli and Sara Solla and David Sussillo and Andreas S. Tolias and Doris Tsao},
    year = {2022},
    eprint = {2210.08340},
    archivePrefix = {arXiv},
    primaryClass = {cs.AI},
    url = {https://arxiv.org/abs/2210.08340v3},
    abstract = {Neuroscience has long been an essential driver of progress in artificial intelligence (AI). We propose that to accelerate progress in AI, we must invest in fundamental research in NeuroAI. A core component of this is the embodied Turing test, which challenges AI animal models to interact with the sensorimotor world at skill levels akin to their living counterparts. The embodied Turing test shifts the focus from those capabilities like game playing and language that are especially well-developed ...}
}

@misc{Pramanick2022_VoLTA_,
    title = {VoLTA: Vision-Language Transformer with Weakly-Supervised Local-Feature Alignment},
    author = {Shraman Pramanick and Li Jing and Sayan Nag and Jiachen Zhu and Hardik Shah and Yann LeCun and Rama Chellappa},
    year = {2022},
    eprint = {2210.04135},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2210.04135v3},
    abstract = {Vision-language pre-training (VLP) has recently proven highly effective for various uni- and multi-modal downstream applications. However, most existing end-to-end VLP methods use high-resolution image-text box data to perform well on fine-grained region-level tasks, such as object detection, segmentation, and referring expression comprehension. Unfortunately, such high-resolution images with accurate bounding box annotations are expensive to collect and use for supervision at scale. In this wor...}
}

@misc{Garrido2022_RankMe_,
    title = {RankMe: Assessing the downstream performance of pretrained self-supervised representations by their rank},
    author = {Quentin Garrido and Randall Balestriero and Laurent Najman and Yann Lecun},
    year = {2022},
    eprint = {2210.02885},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2210.02885v3},
    abstract = {Joint-Embedding Self Supervised Learning (JE-SSL) has seen a rapid development, with the emergence of many method variations but only few principled guidelines that would help practitioners to successfully deploy them. The main reason for that pitfall comes from JE-SSL's core principle of not employing any input reconstruction therefore lacking visual cues of unsuccessful training. Adding non informative loss values to that, it becomes difficult to deploy SSL on a new dataset for which no labels...}
}

@misc{Bardes2022_VICRegL_,
    title = {VICRegL: Self-Supervised Learning of Local Visual Features},
    author = {Adrien Bardes and Jean Ponce and Yann LeCun},
    year = {2022},
    eprint = {2210.01571},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2210.01571v1},
    abstract = {Most recent self-supervised methods for learning image representations focus on either producing a global feature with invariance properties, or producing a set of local features. The former works best for classification tasks while the latter is best for detection and segmentation tasks. This paper explores the fundamental trade-off between learning local and global features. A new method called VICRegL is proposed that learns good global and local features simultaneously, yielding excellent pe...}
}

@misc{Chen2022_Minimalistic,
    title = {Minimalistic Unsupervised Learning with the Sparse Manifold Transform},
    author = {Yubei Chen and Zeyu Yun and Yi Ma and Bruno Olshausen and Yann LeCun},
    year = {2022},
    eprint = {2209.15261},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2209.15261v2},
    abstract = {We describe a minimalistic and interpretable method for unsupervised learning, without resorting to data augmentation, hyperparameter tuning, or other engineering designs, that achieves performance close to the SOTA SSL methods. Our approach leverages the sparse manifold transform, which unifies sparse coding, manifold learning, and slow feature analysis. With a one-layer deterministic sparse manifold transform, one can achieve 99.3\% KNN top-1 accuracy on MNIST, 81.1\% KNN top-1 accuracy on CIFAR...}
}

@misc{Mialon2022_Variance,
    title = {Variance Covariance Regularization Enforces Pairwise Independence in Self-Supervised Representations},
    author = {Grégoire Mialon and Randall Balestriero and Yann LeCun},
    year = {2022},
    eprint = {2209.14905},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2209.14905v2},
    abstract = {Self-Supervised Learning (SSL) methods such as VICReg, Barlow Twins or W-MSE avoid collapse of their joint embedding architectures by constraining or regularizing the covariance matrix of their projector's output. This study highlights important properties of such strategy, which we coin Variance-Covariance regularization (VCReg). More precisely, we show that \{\em VCReg combined to a MLP projector enforces pairwise independence between the features of the learned representation\}. This result eme...}
}

@misc{Kiani2022_Joint,
    title = {Joint Embedding Self-Supervised Learning in the Kernel Regime},
    author = {Bobak T. Kiani and Randall Balestriero and Yubei Chen and Seth Lloyd and Yann LeCun},
    year = {2022},
    eprint = {2209.14884},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2209.14884v1},
    abstract = {The fundamental goal of self-supervised learning (SSL) is to produce useful representations of data without access to any labels for classifying the data. Modern methods in SSL, which form representations based on known or constructed relationships between samples, have been particularly effective at this task. Here, we aim to extend this framework to incorporate algorithms based on kernel methods where embeddings are constructed by linear maps acting on the feature space of a kernel. In this ke...}
}

@misc{Zhang2022_Light_weight,
    title = {Light-weight probing of unsupervised representations for Reinforcement Learning},
    author = {Wancong Zhang and Anthony GX-Chen and Vlad Sobal and Yann LeCun and Nicolas Carion},
    year = {2022},
    eprint = {2208.12345},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2208.12345v2},
    abstract = {Unsupervised visual representation learning offers the opportunity to leverage large corpora of unlabeled trajectories to form useful visual representations, which can benefit the training of reinforcement learning (RL) algorithms. However, evaluating the fitness of such representations requires training RL algorithms which is computationally intensive and has high variance outcomes. Inspired by the vision community, we study whether linear probing can be a proxy evaluation task for the quality ...}
}

@misc{Shwartz_Ziv2022_What,
    title = {What Do We Maximize in Self-Supervised Learning?},
    author = {Ravid Shwartz-Ziv and Randall Balestriero and Yann LeCun},
    year = {2022},
    eprint = {2207.10081},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2207.10081v1},
    abstract = {In this paper, we examine self-supervised learning methods, particularly VICReg, to provide an information-theoretical understanding of their construction. As a first step, we demonstrate how information-theoretic quantities can be obtained for a deterministic network, offering a possible alternative to prior work that relies on stochastic models. This enables us to demonstrate how VICReg can be (re)discovered from first principles and its assumptions about data distribution. Furthermore, we emp...}
}

@misc{Zhu2022_TiCo_,
    title = {TiCo: Transformation Invariance and Covariance Contrast for Self-Supervised Visual Representation Learning},
    author = {Jiachen Zhu and Rafael M. Moraes and Serkan Karakulak and Vlad Sobol and Alfredo Canziani and Yann LeCun},
    year = {2022},
    eprint = {2206.10698},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2206.10698v2},
    abstract = {We present Transformation Invariance and Covariance Contrast (TiCo) for self-supervised visual representation learning. Similar to other recent self-supervised learning methods, our method is based on maximizing the agreement among embeddings of different distorted versions of the same image, which pushes the encoder to produce transformation invariant representations. To avoid the trivial solution where the encoder generates constant vectors, we regularize the covariance matrix of the embedding...}
}

@misc{Chen2022_Bag,
    title = {Bag of Image Patch Embedding Behind the Success of Self-Supervised Learning},
    author = {Yubei Chen and Adrien Bardes and Zengyi Li and Yann LeCun},
    year = {2022},
    eprint = {2206.08954},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2206.08954v2},
    abstract = {Self-supervised learning (SSL) has recently achieved tremendous empirical advancements in learning image representation. However, our understanding of the principle behind learning such a representation is still limited. This work shows that joint-embedding SSL approaches primarily learn a representation of image patches, which reflects their co-occurrence. Such a connection to co-occurrence modeling can be established formally, and it supplements the prevailing invariance perspective. We empiri...}
}

@misc{Jing2022_Masked,
    title = {Masked Siamese ConvNets},
    author = {Li Jing and Jiachen Zhu and Yann LeCun},
    year = {2022},
    eprint = {2206.07700},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2206.07700v1},
    abstract = {Self-supervised learning has shown superior performances over supervised methods on various vision benchmarks. The siamese network, which encourages embeddings to be invariant to distortions, is one of the most successful self-supervised visual representation learning approaches. Among all the augmentation methods, masking is the most general and straightforward method that has the potential to be applied to all kinds of input and requires the least amount of domain knowledge. However, masked si...}
}

@misc{Dou2022_Coarse_to_Fine,
    title = {Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone},
    author = {Zi-Yi Dou and Aishwarya Kamath and Zhe Gan and Pengchuan Zhang and Jianfeng Wang and Linjie Li and Zicheng Liu and Ce Liu and Yann LeCun and Nanyun Peng and Jianfeng Gao and Lijuan Wang},
    year = {2022},
    eprint = {2206.07643},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2206.07643v2},
    abstract = {Vision-language (VL) pre-training has recently received considerable attention. However, most existing end-to-end pre-training approaches either only aim to tackle VL tasks such as image-text retrieval, visual question answering (VQA) and image captioning that test high-level understanding of images, or only target region-level understanding for tasks such as phrase grounding and object detection. We present FIBER (Fusion-In-the-Backbone-based transformER), a new VL model architecture that can s...}
}

@misc{Garrido2022_On,
    title = {On the duality between contrastive and non-contrastive self-supervised learning},
    author = {Quentin Garrido and Yubei Chen and Adrien Bardes and Laurent Najman and Yann Lecun},
    year = {2022},
    doi = {10.48550/arXiv.2206.02574},
    eprint = {2206.02574},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2206.02574v3},
    abstract = {Recent approaches in self-supervised learning of image representations can be categorized into different families of methods and, in particular, can be divided into contrastive and non-contrastive approaches. While differences between the two families have been thoroughly discussed to motivate new approaches, we focus more on the theoretical similarities between them. By designing contrastive and covariance based non-contrastive criteria that can be related algebraically and shown to be equivale...}
}

@misc{Balestriero2022_Contrastive,
    title = {Contrastive and Non-Contrastive Self-Supervised Learning Recover Global and Local Spectral Embedding Methods},
    author = {Randall Balestriero and Yann LeCun},
    year = {2022},
    eprint = {2205.11508},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2205.11508v3},
    abstract = {Self-Supervised Learning (SSL) surmises that inputs and pairwise positive relationships are enough to learn meaningful representations. Although SSL has recently reached a milestone: outperforming supervised methods in many modalities\dots the theoretical foundations are limited, method-specific, and fail to provide principled design guidelines to practitioners. In this paper, we propose a unifying framework under the helm of spectral manifold learning to address those limitations. Through the c...}
}

@misc{Shwartz_Ziv2022_Pre_Train,
    title = {Pre-Train Your Loss: Easy Bayesian Transfer Learning with Informative Priors},
    author = {Ravid Shwartz-Ziv and Micah Goldblum and Hossein Souri and Sanyam Kapoor and Chen Zhu and Yann LeCun and Andrew Gordon Wilson},
    year = {2022},
    eprint = {2205.10279},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2205.10279v1},
    abstract = {Deep learning is increasingly moving towards a transfer learning paradigm whereby large foundation models are fine-tuned on downstream tasks, starting from an initialization learned on the source task. But an initialization contains relatively little information about the source task. Instead, we show that we can learn highly informative posteriors from the source task, through supervised or self-supervised approaches, which then serve as the basis for priors that modify the whole loss surface o...}
}

@misc{Sobal2022_Separating,
    title = {Separating the World and Ego Models for Self-Driving},
    author = {Vlad Sobal and Alfredo Canziani and Nicolas Carion and Kyunghyun Cho and Yann LeCun},
    year = {2022},
    eprint = {2204.07184},
    archivePrefix = {arXiv},
    primaryClass = {cs.RO},
    url = {https://arxiv.org/abs/2204.07184v1},
    abstract = {Training self-driving systems to be robust to the long-tail of driving scenarios is a critical problem. Model-based approaches leverage simulation to emulate a wide range of scenarios without putting users at risk in the real world. One promising path to faithful simulation is to train a forward model of the world to predict the future states of both the environment and the ego-vehicle given past states and a sequence of actions. In this paper, we argue that it is beneficial to model the state o...}
}

@misc{Balestriero2022_The,
    title = {The Effects of Regularization and Data Augmentation are Class Dependent},
    author = {Randall Balestriero and Leon Bottou and Yann LeCun},
    year = {2022},
    eprint = {2204.03632},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2204.03632v2},
    abstract = {Regularization is a fundamental technique to prevent over-fitting and to improve generalization performances by constraining a model's complexity. Current Deep Networks heavily rely on regularizers such as Data-Augmentation (DA) or weight-decay, and employ structural risk minimization, i.e. cross-validation, to select the optimal regularization hyper-parameters. In this study, we demonstrate that techniques such as DA or weight decay produce a model with a reduced complexity that is unfair acros...}
}

@misc{Kiani2022_projUNN_,
    title = {projUNN: efficient method for training deep networks with unitary matrices},
    author = {Bobak Kiani and Randall Balestriero and Yann LeCun and Seth Lloyd},
    year = {2022},
    eprint = {2203.05483},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2203.05483v3},
    abstract = {In learning with recurrent or very deep feed-forward networks, employing unitary matrices in each layer can be very effective at maintaining long-range stability. However, restricting network parameters to be unitary typically comes at the cost of expensive parameterizations or increased training runtime. We propose instead an efficient method based on rank-\$k\$ updates -- or their rank-\$k\$ approximation -- that maintains performance at a nearly optimal training runtime. We introduce two variants...}
}

@misc{Balestriero2022_A,
    title = {A Data-Augmentation Is Worth A Thousand Samples: Exact Quantification From Analytical Augmented Sample Moments},
    author = {Randall Balestriero and Ishan Misra and Yann LeCun},
    year = {2022},
    eprint = {2202.08325},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2202.08325v1},
    abstract = {Data-Augmentation (DA) is known to improve performance across tasks and datasets. We propose a method to theoretically analyze the effect of DA and study questions such as: how many augmented samples are needed to correctly estimate the information encoded by that DA? How does the augmentation policy impact the final parameters of a model? We derive several quantities in close-form, such as the expectation and variance of an image, loss, and model's output under a given DA distribution. Those de...}
}

@misc{Li2022_Neural,
    title = {Neural Manifold Clustering and Embedding},
    author = {Zengyi Li and Yubei Chen and Yann LeCun and Friedrich T. Sommer},
    year = {2022},
    eprint = {2201.10000},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2201.10000v1},
    abstract = {Given a union of non-linear manifolds, non-linear subspace clustering or manifold clustering aims to cluster data points based on manifold structures and also learn to parameterize each manifold as a linear subspace in a feature space. Deep neural networks have the potential to achieve this goal under highly non-linear settings given their large capacity and flexibility. We argue that achieving manifold clustering with neural networks requires two essential ingredients: a domain-specific constra...}
}

@misc{Evtimova2021_Sparse,
    title = {Sparse Coding with Multi-Layer Decoders using Variance Regularization},
    author = {Katrina Evtimova and Yann LeCun},
    year = {2021},
    eprint = {2112.09214},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2112.09214v2},
    abstract = {Sparse representations of images are useful in many computer vision applications. Sparse coding with an \$l\_1\$ penalty and a learned linear dictionary requires regularization of the dictionary to prevent a collapse in the \$l\_1\$ norms of the codes. Typically, this regularization entails bounding the Euclidean norms of the dictionary's elements. In this work, we propose a novel sparse coding protocol which prevents a collapse in the codes without the need to regularize the decoder. Our method regul...}
}

@misc{Balestriero2021_Learning,
    title = {Learning in High Dimension Always Amounts to Extrapolation},
    author = {Randall Balestriero and Jerome Pesenti and Yann LeCun},
    year = {2021},
    eprint = {2110.09485},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2110.09485v2},
    abstract = {The notion of interpolation and extrapolation is fundamental in various fields from deep learning to function approximation. Interpolation occurs for a sample \$x\$ whenever this sample falls inside or on the boundary of the given dataset's convex hull. Extrapolation occurs when \$x\$ falls outside of that convex hull. One fundamental (mis)conception is that state-of-the-art algorithms work so well because of their ability to correctly interpolate training data. A second (mis)conception is that inte...}
}

@misc{Jing2021_Understanding,
    title = {Understanding Dimensional Collapse in Contrastive Self-supervised Learning},
    author = {Li Jing and Pascal Vincent and Yann LeCun and Yuandong Tian},
    year = {2021},
    eprint = {2110.09348},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2110.09348v3},
    abstract = {Self-supervised visual representation learning aims to learn useful representations without relying on human annotations. Joint embedding approach bases on maximizing the agreement between embedding vectors from different views of the same image. Various methods have been proposed to solve the collapsing problem where all embedding vectors collapse to a trivial constant solution. Among these methods, contrastive learning prevents collapse via negative sample pairs. It has been shown that non-con...}
}

@misc{Yeh2021_Decoupled,
    title = {Decoupled Contrastive Learning},
    author = {Chun-Hsiao Yeh and Cheng-Yao Hong and Yen-Chi Hsu and Tyng-Luh Liu and Yubei Chen and Yann LeCun},
    year = {2021},
    eprint = {2110.06848},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2110.06848v3},
    abstract = {Contrastive learning (CL) is one of the most successful paradigms for self-supervised learning (SSL). In a principled way, it considers two augmented "views" of the same image as positive to be pulled closer, and all other images as negative to be pushed further apart. However, behind the impressive success of CL-based techniques, their formulation often relies on heavy-computation settings, including large sample batches, extensive training epochs, etc. We are thus motivated to tackle these iss...}
}

@misc{Wang2021_Compact,
    title = {Compact and Optimal Deep Learning with Recurrent Parameter Generators},
    author = {Jiayun Wang and Yubei Chen and Stella X. Yu and Brian Cheung and Yann LeCun},
    year = {2021},
    eprint = {2107.07110},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2107.07110v3},
    abstract = {Deep learning has achieved tremendous success by training increasingly large models, which are then compressed for practical deployment. We propose a drastically different approach to compact and optimal deep learning: We decouple the Degrees of freedom (DoF) and the actual number of parameters of a model, optimize a small DoF with predefined random linear constraints for a large model of arbitrary architecture, in one-stage end-to-end learning. Specifically, we create a recurrent parameter gene...}
}

@misc{Bardes2021_VICReg_,
    title = {VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning},
    author = {Adrien Bardes and Jean Ponce and Yann LeCun},
    year = {2021},
    eprint = {2105.04906},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2105.04906v3},
    abstract = {Recent self-supervised methods for image representation learning are based on maximizing the agreement between embedding vectors from different views of the same image. A trivial solution is obtained when the encoder outputs constant vectors. This collapse problem is often avoided through implicit biases in the learning architecture, that often lack a clear justification or interpretation. In this paper, we introduce VICReg (Variance-Invariance-Covariance Regularization), a method that explicitl...}
}

@misc{Kamath2021_MDETR,
    title = {MDETR -- Modulated Detection for End-to-End Multi-Modal Understanding},
    author = {Aishwarya Kamath and Mannat Singh and Yann LeCun and Gabriel Synnaeve and Ishan Misra and Nicolas Carion},
    year = {2021},
    eprint = {2104.12763},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2104.12763v2},
    abstract = {Multi-modal reasoning systems rely on a pre-trained object detector to extract regions of interest from the image. However, this crucial module is typically used as a black box, trained independently of the downstream task and on a fixed vocabulary of objects and attributes. This makes it challenging for such systems to capture the long tail of visual concepts expressed in free form text. In this paper we propose MDETR, an end-to-end modulated detector that detects objects in an image conditione...}
}

@misc{Yun2021_Transformer,
    title = {Transformer visualization via dictionary learning: contextualized embedding as a linear superposition of transformer factors},
    author = {Zeyu Yun and Yubei Chen and Bruno A Olshausen and Yann LeCun},
    year = {2021},
    eprint = {2103.15949},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL},
    url = {https://arxiv.org/abs/2103.15949v2},
    abstract = {Transformer networks have revolutionized NLP representation learning since they were introduced. Though a great effort has been made to explain the representation in transformers, it is widely recognized that our understanding is not sufficient. One important reason is that there lack enough visualization tools for detailed analysis. In this paper, we propose to use dictionary learning to open up these "black boxes" as linear superpositions of transformer factors. Through visualization, we demon...}
}

@misc{Zbontar2021_Barlow,
    title = {Barlow Twins: Self-Supervised Learning via Redundancy Reduction},
    author = {Jure Zbontar and Li Jing and Ishan Misra and Yann LeCun and Stéphane Deny},
    year = {2021},
    eprint = {2103.03230},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/2103.03230v3},
    abstract = {Self-supervised learning (SSL) is rapidly closing the gap with supervised methods on large computer vision benchmarks. A successful approach to SSL is to learn embeddings which are invariant to distortions of the input sample. However, a recurring issue with this approach is the existence of trivial constant solutions. Most current methods avoid such solutions by careful implementation details. We propose an objective function that naturally avoids collapse by measuring the cross-correlation mat...}
}

@misc{Jing2020_Implicit,
    title = {Implicit Rank-Minimizing Autoencoder},
    author = {Li Jing and Jure Zbontar and Yann LeCun},
    year = {2020},
    eprint = {2010.00679},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2010.00679v2},
    abstract = {An important component of autoencoders is the method by which the information capacity of the latent representation is minimized or limited. In this work, the rank of the covariance matrix of the codes is implicitly minimized by relying on the fact that gradient descent learning in multi-layer linear networks leads to minimum-rank solutions. By inserting a number of extra linear layers between the encoder and the decoder, the system spontaneously learns representations with a low effective dimen...}
}

@misc{Rozière2019_Inspirational,
    title = {Inspirational Adversarial Image Generation},
    author = {Baptiste Rozière and Morgane Riviere and Olivier Teytaud and Jérémy Rapin and Yann LeCun and Camille Couprie},
    year = {2019},
    eprint = {1906.11661},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1906.11661v2},
    abstract = {The task of image generation started to receive some attention from artists and designers to inspire them in new creations. However, exploiting the results of deep generative models such as Generative Adversarial Networks can be long and tedious given the lack of existing tools. In this work, we propose a simple strategy to inspire creators with new generations learned from a dataset of their choice, while providing some control on them. We design a simple optimization method to find the optimal...}
}

@misc{Vo2019_Unsupervised,
    title = {Unsupervised Image Matching and Object Discovery as Optimization},
    author = {Huy V. Vo and Francis Bach and Minsu Cho and Kai Han and Yann LeCun and Patrick Perez and Jean Ponce},
    year = {2019},
    eprint = {1904.03148},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1904.03148v1},
    abstract = {Learning with complete or partial supervision is powerful but relies on ever-growing human annotation efforts. As a way to mitigate this serious problem, as well as to serve specific applications, unsupervised learning has emerged as an important field of research. In computer vision, unsupervised learning comes in various guises. We focus here on the unsupervised discovery and matching of object categories among images in a collection, following the work of Cho et al. 2015. We show that the ori...}
}

@misc{Belghazi2019_Learning,
    title = {Learning about an exponential amount of conditional distributions},
    author = {Mohamed Ishmael Belghazi and Maxime Oquab and Yann LeCun and David Lopez-Paz},
    year = {2019},
    eprint = {1902.08401},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1902.08401v1},
    abstract = {We introduce the Neural Conditioner (NC), a self-supervised machine able to learn about all the conditional distributions of a random vector \$X\$. The NC is a function \$NC(x \cdot a, a, r)\$ that leverages adversarial training to match each conditional distribution \$P(X\_r|X\_a=x\_a)\$. After training, the NC generalizes to sample from conditional distributions never seen, including the joint distribution. The NC is also able to auto-encode examples, providing data representations useful for downstrea...}
}

@misc{Henaff2019_Model_Predictive,
    title = {Model-Predictive Policy Learning with Uncertainty Regularization for Driving in Dense Traffic},
    author = {Mikael Henaff and Alfredo Canziani and Yann LeCun},
    year = {2019},
    eprint = {1901.02705},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1901.02705v1},
    abstract = {Learning a policy using only observational data is challenging because the distribution of states it induces at execution time may differ from the distribution observed during training. We propose to train a policy by unrolling a learned model of the environment dynamics over multiple time steps while explicitly penalizing two costs: the original cost the policy seeks to optimize, and an uncertainty cost which represents its divergence from the states it is trained on. We measure this second cos...}
}

@misc{Ramesh2018_A,
    title = {A Spectral Regularizer for Unsupervised Disentanglement},
    author = {Aditya Ramesh and Youngduck Choi and Yann LeCun},
    year = {2018},
    eprint = {1812.01161},
    archivePrefix = {arXiv},
    primaryClass = {stat.ML},
    url = {https://arxiv.org/abs/1812.01161v2},
    abstract = {A generative model with a disentangled representation allows for independent control over different aspects of the output. Learning disentangled representations has been a recent topic of great interest, but it remains poorly understood. We show that even for GANs that do not possess disentangled representations, one can find curved trajectories in latent space over which local disentanglement occurs. These trajectories are found by iteratively following the leading right-singular vectors of the...}
}

@misc{Zhang2018_Adversarially_Trained,
    title = {Adversarially-Trained Normalized Noisy-Feature Auto-Encoder for Text Generation},
    author = {Xiang Zhang and Yann LeCun},
    year = {2018},
    eprint = {1811.04201},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL},
    url = {https://arxiv.org/abs/1811.04201v1},
    abstract = {This article proposes Adversarially-Trained Normalized Noisy-Feature Auto-Encoder (ATNNFAE) for byte-level text generation. An ATNNFAE consists of an auto-encoder where the internal code is normalized on the unit sphere and corrupted by additive noise. Simultaneously, a replica of the decoder (sharing the same parameters as the AE decoder) is used as the generator and fed with random latent vectors. An adversarial discriminator is trained to distinguish training samples reconstructed from the AE...}
}

@misc{Yang2018_GLoMo_,
    title = {GLoMo: Unsupervisedly Learned Relational Graphs as Transferable Representations},
    author = {Zhilin Yang and Jake Zhao and Bhuwan Dhingra and Kaiming He and William W. Cohen and Ruslan Salakhutdinov and Yann LeCun},
    year = {2018},
    eprint = {1806.05662},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1806.05662v3},
    abstract = {Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words...}
}

@misc{Ramesh2018_Backpropagation,
    title = {Backpropagation for Implicit Spectral Densities},
    author = {Aditya Ramesh and Yann LeCun},
    year = {2018},
    eprint = {1806.00499},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1806.00499v1},
    abstract = {Most successful machine intelligence systems rely on gradient-based learning, which is made possible by backpropagation. Some systems are designed to aid us in interpreting data when explicit goals cannot be provided. These unsupervised systems are commonly trained by backpropagating through a likelihood function. We introduce a tool that allows us to do this even when the likelihood is not explicitly set, by instead using the implicit likelihood of the model. Explicitly defining the likelihood ...}
}

@misc{Neyshabur2018_Towards,
    title = {Towards Understanding the Role of Over-Parametrization in Generalization of Neural Networks},
    author = {Behnam Neyshabur and Zhiyuan Li and Srinadh Bhojanapalli and Yann LeCun and Nathan Srebro},
    year = {2018},
    eprint = {1805.12076},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1805.12076v1},
    abstract = {Despite existing work on ensuring generalization of neural networks in terms of scale sensitive complexity measures, such as norms, margin and sharpness, these complexity measures do not offer an explanation of why neural networks generalize better with over-parametrization. In this work we suggest a novel complexity measure based on unit-wise capacities resulting in a tighter generalization bound for two layer ReLU networks. Our capacity bound correlates with the behavior of test error with inc...}
}

@misc{Sbai2018_DeSIGN_,
    title = {DeSIGN: Design Inspiration from Generative Networks},
    author = {Othman Sbai and Mohamed Elhoseiny and Antoine Bordes and Yann LeCun and Camille Couprie},
    year = {2018},
    eprint = {1804.00921},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1804.00921v2},
    abstract = {Can an algorithm create original and compelling fashion designs to serve as an inspirational assistant? To help answer this question, we design and investigate different image generation models associated with different loss functions to boost creativity in fashion generation. The dimensions of our explorations include: (i) different Generative Adversarial Networks architectures that start from noise vectors to generate fashion items, (ii) novel loss functions that encourage novelty, inspired fr...}
}

@misc{Luc2018_Predicting,
    title = {Predicting Future Instance Segmentation by Forecasting Convolutional Features},
    author = {Pauline Luc and Camille Couprie and Yann LeCun and Jakob Verbeek},
    year = {2018},
    eprint = {1803.11496},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1803.11496v2},
    abstract = {Anticipating future events is an important prerequisite towards intelligent behavior. Video forecasting has been studied as a proxy task towards this goal. Recent work has shown that to predict semantic segmentation of future frames, forecasting at the semantic level is more effective than forecasting RGB frames and then segmenting these. In this paper we consider the more challenging problem of future instance segmentation, which additionally segments out individual objects. To deal with a vary...}
}

@misc{Zhang2018_Byte_Level,
    title = {Byte-Level Recursive Convolutional Auto-Encoder for Text},
    author = {Xiang Zhang and Yann LeCun},
    year = {2018},
    eprint = {1802.01817},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL},
    url = {https://arxiv.org/abs/1802.01817v1},
    abstract = {This article proposes to auto-encode text at byte-level using convolutional networks with a recursive architecture. The motivation is to explore whether it is possible to have scalable and homogeneous text generation at byte-level in a non-sequential fashion through the simple task of auto-encoding. We show that non-sequential text generation from a fixed-length representation is not only possible, but also achieved much better auto-encoding results than recurrent networks. The proposed model is...}
}

@misc{Tran2017_A,
    title = {A Closer Look at Spatiotemporal Convolutions for Action Recognition},
    author = {Du Tran and Heng Wang and Lorenzo Torresani and Jamie Ray and Yann LeCun and Manohar Paluri},
    year = {2017},
    eprint = {1711.11248},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1711.11248v3},
    abstract = {In this paper we discuss several forms of spatiotemporal convolutions for video analysis and study their effects on action recognition. Our motivation stems from the observation that 2D CNNs applied to individual frames of the video have remained solid performers in action recognition. In this work we empirically demonstrate the accuracy advantages of 3D CNNs over 2D CNNs within the framework of residual learning. Furthermore, we show that factorizing the 3D convolutional filters into separate s...}
}

@misc{Henaff2017_Prediction,
    title = {Prediction Under Uncertainty with Error-Encoding Networks},
    author = {Mikael Henaff and Junbo Zhao and Yann LeCun},
    year = {2017},
    eprint = {1711.04994},
    archivePrefix = {arXiv},
    primaryClass = {cs.AI},
    url = {https://arxiv.org/abs/1711.04994v3},
    abstract = {In this work we introduce a new framework for performing temporal predictions in the presence of uncertainty. It is based on a simple idea of disentangling components of the future state which are predictable from those which are inherently unpredictable, and encoding the unpredictable components into a low-dimensional latent variable which is fed into a forward model. Our method uses a supervised training objective which is fast and easy to train. We evaluate it in the context of video predicti...}
}

@misc{Wu2017_A,
    title = {A hierarchical loss and its problems when classifying non-hierarchically},
    author = {Cinna Wu and Mark Tygert and Yann LeCun},
    year = {2017},
    eprint = {1709.01062},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1709.01062v2},
    abstract = {Failing to distinguish between a sheepdog and a skyscraper should be worse and penalized more than failing to distinguish between a sheepdog and a poodle; after all, sheepdogs and poodles are both breeds of dogs. However, existing metrics of failure (so-called "loss" or "win") used in textual or visual classification/recognition via neural networks seldom leverage a-priori information, such as a sheepdog being more similar to a poodle than to a skyscraper. We define a metric that, inter alia, ca...}
}

@misc{Zhang2017_Which,
    title = {Which Encoding is the Best for Text Classification in Chinese, English, Japanese and Korean?},
    author = {Xiang Zhang and Yann LeCun},
    year = {2017},
    eprint = {1708.02657},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL},
    url = {https://arxiv.org/abs/1708.02657v2},
    abstract = {This article offers an empirical study on the different ways of encoding Chinese, Japanese, Korean (CJK) and English languages for text classification. Different encoding levels are studied, including UTF-8 bytes, characters, words, romanized characters and romanized words. For all encoding levels, whenever applicable, we provide comparisons with linear models, fastText and convolutional networks. For convolutional networks, we compare between encoding mechanisms using character glyph images, on...}
}

@misc{Zhao2017_Adversarially,
    title = {Adversarially Regularized Autoencoders},
    author = {Jake Zhao and Yoon Kim and Kelly Zhang and Alexander M. Rush and Yann LeCun},
    year = {2017},
    eprint = {1706.04223},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1706.04223v3},
    abstract = {Deep latent variable models, trained using variational autoencoders or generative adversarial networks, are now a key technique for representation learning of continuous structures. However, applying similar methods to discrete structures, such as text sequences or discretized images, has proven to be more challenging. In this work, we propose a flexible method for training deep latent variable models of discrete structures. Our approach is based on the recently-proposed Wasserstein autoencoder ...}
}

@misc{Henaff2017_Model_Based,
    title = {Model-Based Planning with Discrete and Continuous Actions},
    author = {Mikael Henaff and William F. Whitney and Yann LeCun},
    year = {2017},
    eprint = {1705.07177},
    archivePrefix = {arXiv},
    primaryClass = {cs.AI},
    url = {https://arxiv.org/abs/1705.07177v2},
    abstract = {Action planning using learned and differentiable forward models of the world is a general approach which has a number of desirable properties, including improved sample complexity over model-free RL methods, reuse of learned models across different tasks, and the ability to perform efficient gradient-based optimization in continuous action spaces. However, this approach does not apply straightforwardly when the action space is discrete. In this work, we show that it is in fact possible to effect...}
}

@misc{Luc2017_Predicting,
    title = {Predicting Deeper into the Future of Semantic Segmentation},
    author = {Pauline Luc and Natalia Neverova and Camille Couprie and Jakob Verbeek and Yann LeCun},
    year = {2017},
    eprint = {1703.07684},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1703.07684v3},
    abstract = {The ability to predict and therefore to anticipate the future is an important attribute of intelligence. It is also of utmost importance in real-time systems, e.g. in robotics or autonomous driving, which depend on visual scene understanding for decision making. While prediction of the raw RGB pixel values in future video frames has been studied in previous work, here we introduce the novel task of predicting semantic segmentations of future frames. Given a sequence of video frames, our goal is ...}
}

@misc{Jing2016_Tunable,
    title = {Tunable Efficient Unitary Neural Networks (EUNN) and their application to RNNs},
    author = {Li Jing and Yichen Shen and Tena Dubček and John Peurifoy and Scott Skirlo and Yann LeCun and Max Tegmark and Marin Soljačić},
    year = {2016},
    eprint = {1612.05231},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1612.05231v3},
    abstract = {Using unitary (instead of general) matrices in artificial neural networks (ANNs) is a promising way to solve the gradient explosion/vanishing problem, as well as to enable ANNs to learn long-term correlations in the data. This approach appears particularly promising for Recurrent Neural Networks (RNNs). In this work, we present a new architecture for implementing an Efficient Unitary Neural Network (EUNNs); its main advantages can be summarized as follows. Firstly, the representation capacity of...}
}

@misc{Henaff2016_Tracking,
    title = {Tracking the World State with Recurrent Entity Networks},
    author = {Mikael Henaff and Jason Weston and Arthur Szlam and Antoine Bordes and Yann LeCun},
    year = {2016},
    eprint = {1612.03969},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL},
    url = {https://arxiv.org/abs/1612.03969v3},
    abstract = {We introduce a new model, the Recurrent Entity Network (EntNet). It is equipped with a dynamic long-term memory which allows it to maintain and update a representation of the state of the world as it receives new data. For language understanding tasks, it can reason on-the-fly as it reads text, not just when it is required to answer a question or respond as is the case for a Memory Network (Sukhbaatar et al., 2015). Like a Neural Turing Machine or Differentiable Neural Computer (Graves et al., 2...}
}

@misc{Bronstein2016_Geometric,
    title = {Geometric deep learning: going beyond Euclidean data},
    author = {Michael M. Bronstein and Joan Bruna and Yann LeCun and Arthur Szlam and Pierre Vandergheynst},
    year = {2016},
    doi = {10.1109/MSP.2017.2693418},
    eprint = {1611.08097},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1611.08097v2},
    abstract = {Many scientific fields study data with an underlying structure that is a non-Euclidean space. Some examples include social networks in computational social sciences, sensor networks in communications, functional networks in brain imaging, regulatory networks in genetics, and meshed surfaces in computer graphics. In many applications, such geometric data are large and complex (in the case of social networks, on the scale of billions), and are natural targets for machine learning techniques. In pa...}
}

@misc{Sagun2016_Eigenvalues,
    title = {Eigenvalues of the Hessian in Deep Learning: Singularity and Beyond},
    author = {Levent Sagun and Leon Bottou and Yann LeCun},
    year = {2016},
    eprint = {1611.07476},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1611.07476v2},
    abstract = {We look at the eigenvalues of the Hessian of a loss function before and after training. The eigenvalue distribution is seen to be composed of two parts, the bulk which is concentrated around zero, and the edges which are scattered away from zero. We present empirical evidence for the bulk indicating how over-parametrized the system is, and for the edges that depend on the input data.}
}

@misc{Mathieu2016_Disentangling,
    title = {Disentangling factors of variation in deep representations using adversarial training},
    author = {Michael Mathieu and Junbo Zhao and Pablo Sprechmann and Aditya Ramesh and Yann LeCun},
    year = {2016},
    eprint = {1611.03383},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1611.03383v1},
    abstract = {We introduce a conditional generative model for learning to disentangle the hidden factors of variation within a set of labeled observations, and separate them into complementary codes. One code summarizes the specified factors of variation associated with the labels. The other summarizes the remaining unspecified variability. During training, the only available source of supervision comes from our ability to distinguish among different observations belonging to the same class. Examples of such ...}
}

@misc{Chaudhari2016_Entropy_SGD_,
    title = {Entropy-SGD: Biasing Gradient Descent Into Wide Valleys},
    author = {Pratik Chaudhari and Anna Choromanska and Stefano Soatto and Yann LeCun and Carlo Baldassi and Christian Borgs and Jennifer Chayes and Levent Sagun and Riccardo Zecchina},
    year = {2016},
    eprint = {1611.01838},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1611.01838v5},
    abstract = {This paper proposes a new optimization algorithm called Entropy-SGD for training deep neural networks that is motivated by the local geometry of the energy landscape. Local extrema with low generalization error have a large proportion of almost-zero eigenvalues in the Hessian with very few positive or negative eigenvalues. We leverage upon this observation to construct a local-entropy-based objective function that favors well-generalizable solutions lying in large flat regions of the energy land...}
}

@misc{Zhao2016_Energy_based,
    title = {Energy-based Generative Adversarial Network},
    author = {Junbo Zhao and Michael Mathieu and Yann LeCun},
    year = {2016},
    eprint = {1609.03126},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1609.03126v4},
    abstract = {We introduce the "Energy-based Generative Adversarial Network" model (EBGAN) which views the discriminator as an energy function that attributes low energies to the regions near the data manifold and higher energies to other regions. Similar to the probabilistic GANs, a generator is seen as being trained to produce contrastive samples with minimal energies, while the discriminator is trained to assign high energies to these generated samples. Viewing the discriminator as an energy function allow...}
}

@misc{Provodin2016_Fast,
    title = {Fast Incremental Learning for Off-Road Robot Navigation},
    author = {Artem Provodin and Liila Torabi and Beat Flepp and Yann LeCun and Michael Sergio and L. D. Jackel and Urs Muller and Jure Zbontar},
    year = {2016},
    eprint = {1606.08057},
    archivePrefix = {arXiv},
    primaryClass = {cs.RO},
    url = {https://arxiv.org/abs/1606.08057v1},
    abstract = {A promising approach to autonomous driving is machine learning. In such systems, training datasets are created that capture the sensory input to a vehicle as well as the desired response. A disadvantage of using a learned navigation system is that the learning process itself may require a huge number of training examples and a large amount of computing. To avoid the need to collect a large training set of driving examples, we describe a system that takes advantage of the huge number of training ...}
}

@misc{Conneau2016_Very,
    title = {Very Deep Convolutional Networks for Text Classification},
    author = {Alexis Conneau and Holger Schwenk and Loïc Barrault and Yann Lecun},
    year = {2016},
    eprint = {1606.01781},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL},
    url = {https://arxiv.org/abs/1606.01781v2},
    abstract = {The dominant approach for many NLP tasks are recurrent neural networks, in particular LSTMs, and convolutional neural networks. However, these architectures are rather shallow in comparison to the deep convolutional networks which have pushed the state-of-the-art in computer vision. We present a new architecture (VDCNN) for text processing which operates directly at the character level and uses only small convolutions and pooling operations. We are able to show that the performance of this model...}
}

@misc{Jarrett2016_What,
    title = {What is the Best Feature Learning Procedure in Hierarchical Recognition Architectures?},
    author = {Kevin Jarrett and Koray Kvukcuoglu and Karol Gregor and Yann LeCun},
    year = {2016},
    eprint = {1606.01535},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1606.01535v1},
    abstract = {(This paper was written in November 2011 and never published. It is posted on arXiv.org in its original form in June 2016). Many recent object recognition systems have proposed using a two phase training procedure to learn sparse convolutional feature hierarchies: unsupervised pre-training followed by supervised fine-tuning. Recent results suggest that these methods provide little improvement over purely supervised systems when the appropriate nonlinearities are included. This paper presents an ...}
}

@misc{Dugan2016_Phase,
    title = {Phase 3: DCL System Using Deep Learning Approaches for Land-based or Ship-based Real-Time Recognition and Localization of Marine Mammals - Bioacoustic Applicaitons},
    author = {Peter J. Dugan and Christopher W. Clark and Yann André LeCun and Sofie M. Van Parijs},
    year = {2016},
    eprint = {1605.00983},
    archivePrefix = {arXiv},
    primaryClass = {cs.DC},
    url = {https://arxiv.org/abs/1605.00983v2},
    abstract = {Goals of this research phase is to investigate advanced detection and classification pardims useful for data-mining passive large passive acoustic archives. Technical objectives are to develop and refine a High Performance Computing, Acoustic Data Accelerator (HPC-ADA) along with MATLAB based software based on time series acoustic signal Detection cLassification using Machine learning Algorithms, called DeLMA. Data scientists and biologists integrate to use the HPC-ADA and DeLMA technologies to ...}
}

@misc{Dugan2016_Phase,
    title = {Phase 4: DCL System Using Deep Learning Approaches for Land-Based or Ship-Based Real-Time Recognition and Localization of Marine Mammals - Distributed Processing and Big Data Applications},
    author = {Peter J. Dugan and Christopher W. Clark and Yann André LeCun and Sofie M. Van Parijs},
    year = {2016},
    eprint = {1605.00982},
    archivePrefix = {arXiv},
    primaryClass = {cs.DC},
    url = {https://arxiv.org/abs/1605.00982v2},
    abstract = {While the animal bioacoustics community at large is collecting huge amounts of acoustic data at an unprecedented pace, processing these data is problematic. Currently in bioacoustics, there is no effective way to achieve high performance computing using commericial off the shelf (COTS) or government off the shelf (GOTS) tools. Although several advances have been made in the open source and commercial software community, these offerings either support specific applications that do not integrate w...}
}

@misc{Dugan2016_Phase,
    title = {Phase 2: DCL System Using Deep Learning Approaches for Land-based or Ship-based Real-Time Recognition and Localization of Marine Mammals - Machine Learning Detection Algorithms},
    author = {Peter J. Dugan and Christopher W. Clark and Yann André LeCun and Sofie M. Van Parijs},
    year = {2016},
    eprint = {1605.00972},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1605.00972v2},
    abstract = {Overarching goals for this work aim to advance the state of the art for detection, classification and localization (DCL) in the field of bioacoustics. This goal is primarily achieved by building a generic framework for detection-classification (DC) using a fast, efficient and scalable architecture, demonstrating the capabilities of this system using on a variety of low-frequency mid-frequency cetacean sounds. Two primary goals are to develop transferable technologies for detection and classifica...}
}

@misc{Dugan2016_Phase,
    title = {Phase 1: DCL System Research Using Advanced Approaches for Land-based or Ship-based Real-Time Recognition and Localization of Marine Mammals - HPC System Implementation},
    author = {Peter J. Dugan and Christopher W. Clark and Yann André LeCun and Sofie M. Van Parijs},
    year = {2016},
    eprint = {1605.00971},
    archivePrefix = {arXiv},
    primaryClass = {cs.DC},
    url = {https://arxiv.org/abs/1605.00971v2},
    abstract = {We aim to investigate advancing the state of the art of detection, classification and localization (DCL) in the field of bioacoustics. The two primary goals are to develop transferable technologies for detection and classification in: (1) the area of advanced algorithms, such as deep learning and other methods; and (2) advanced systems, capable of real-time and archival and processing. This project will focus on long-term, continuous datasets to provide automatic recognition, minimizing human ti...}
}

@misc{Henaff2016_Recurrent,
    title = {Recurrent Orthogonal Networks and Long-Memory Tasks},
    author = {Mikael Henaff and Arthur Szlam and Yann LeCun},
    year = {2016},
    eprint = {1602.06662},
    archivePrefix = {arXiv},
    primaryClass = {cs.NE},
    url = {https://arxiv.org/abs/1602.06662v2},
    abstract = {Although RNNs have been shown to be powerful tools for processing sequential data, finding architectures or optimization strategies that allow them to model very long term dependencies is still an active area of research. In this work, we carefully analyze two synthetic datasets originally outlined in (Hochreiter and Schmidhuber, 1997) which are used to evaluate the ability of RNNs to store information over many time steps. We explicitly construct RNN solutions to these problems, and using these...}
}

@misc{Sagun2015_Universal,
    title = {Universal halting times in optimization and machine learning},
    author = {Levent Sagun and Thomas Trogdon and Yann LeCun},
    year = {2015},
    doi = {10.1090/qam/1483},
    eprint = {1511.06444},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1511.06444v3},
    abstract = {The authors present empirical distributions for the halting time (measured by the number of iterations to reach a given accuracy) of optimization algorithms applied to two random systems: spin glasses and deep learning. Given an algorithm, which we take to be both the optimization routine and the form of the random landscape, the fluctuations of the halting time follow a distribution that, after centering and scaling, remains unchanged even when the distribution on the landscape is changed. We o...}
}

@misc{Bruna2015_Super_Resolution,
    title = {Super-Resolution with Deep Convolutional Sufficient Statistics},
    author = {Joan Bruna and Pablo Sprechmann and Yann LeCun},
    year = {2015},
    eprint = {1511.05666},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1511.05666v4},
    abstract = {Inverse problems in image and audio, and super-resolution in particular, can be seen as high-dimensional structured prediction problems, where the goal is to characterize the conditional distribution of a high-resolution output given its low-resolution corrupted observation. When the scaling ratio is small, point estimates achieve impressive performance, but soon they suffer from the regression-to-the-mean problem, result of their inability to capture the multi-modality of this conditional distr...}
}

@misc{Mathieu2015_Deep,
    title = {Deep multi-scale video prediction beyond mean square error},
    author = {Michael Mathieu and Camille Couprie and Yann LeCun},
    year = {2015},
    eprint = {1511.05440},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1511.05440v6},
    abstract = {Learning to predict future images from a video sequence involves the construction of an internal representation that models the image evolution accurately, and therefore, to some degree, its content and dynamics. This is why pixel-space video prediction may be viewed as a promising avenue for unsupervised feature learning. In addition, while optical flow has been a very studied problem in computer vision for a long time, future frame prediction is rarely approached. Still, many vision applicatio...}
}

@misc{Choromanska2015_Binary,
    title = {Binary embeddings with structured hashed projections},
    author = {Anna Choromanska and Krzysztof Choromanski and Mariusz Bojarski and Tony Jebara and Sanjiv Kumar and Yann LeCun},
    year = {2015},
    eprint = {1511.05212},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1511.05212v5},
    abstract = {We consider the hashing mechanism for constructing binary embeddings, that involves pseudo-random projections followed by nonlinear (sign function) mappings. The pseudo-random projection is described by a matrix, where not all entries are independent random variables but instead a fixed "budget of randomness" is distributed across the matrix. Such matrices can be efficiently stored in sub-quadratic or even linear space, provide reduction in randomness usage (i.e. number of required random values...}
}

@misc{Zhang2015_Universum,
    title = {Universum Prescription: Regularization using Unlabeled Data},
    author = {Xiang Zhang and Yann LeCun},
    year = {2015},
    eprint = {1511.03719},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1511.03719v7},
    abstract = {This paper shows that simply prescribing "none of the above" labels to unlabeled data has a beneficial regularization effect to supervised learning. We call it universum prescription by the fact that the prescribed labels cannot be one of the supervised labels. In spite of its simplicity, universum prescription obtained competitive results in training deep convolutional networks for CIFAR-10, CIFAR-100, STL-10 and ImageNet datasets. A qualitative justification of these approaches using Rademache...}
}

@misc{Žbontar2015_Stereo,
    title = {Stereo Matching by Training a Convolutional Neural Network to Compare Image Patches},
    author = {Jure Žbontar and Yann LeCun},
    year = {2015},
    eprint = {1510.05970},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1510.05970v2},
    abstract = {We present a method for extracting depth information from a rectified image pair. Our approach focuses on the first stage of many stereo algorithms: the matching cost computation. We approach the problem by learning a similarity measure on small image patches using a convolutional neural network. Training is carried out in a supervised manner by constructing a binary classification data set with examples of similar and dissimilar pairs of patches. We examine two network architectures for this ta...}
}

@misc{Sercu2015_Very,
    title = {Very Deep Multilingual Convolutional Neural Networks for LVCSR},
    author = {Tom Sercu and Christian Puhrsch and Brian Kingsbury and Yann LeCun},
    year = {2015},
    eprint = {1509.08967},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL},
    url = {https://arxiv.org/abs/1509.08967v2},
    abstract = {Convolutional neural networks (CNNs) are a standard component of many current state-of-the-art Large Vocabulary Continuous Speech Recognition (LVCSR) systems. However, CNNs in LVCSR have not kept pace with recent advances in other domains where deeper neural networks provide superior performance. In this paper we propose a number of architectural advances in CNNs for LVCSR. First, we introduce a very deep convolutional network architecture with up to 14 weight layers. There are multiple convolut...}
}

@misc{Dugan2015_High,
    title = {High Performance Computer Acoustic Data Accelerator: A New System for Exploring Marine Mammal Acoustics for Big Data Applications},
    author = {Peter Dugan and John Zollweg and Marian Popescu and Denise Risch and Herve Glotin and Yann LeCun and and Christopher Clark},
    year = {2015},
    eprint = {1509.03591},
    archivePrefix = {arXiv},
    primaryClass = {cs.DC},
    url = {https://arxiv.org/abs/1509.03591v1},
    abstract = {This paper presents a new software model designed for distributed sonic signal detection runtime using machine learning algorithms called DeLMA. A new algorithm--Acoustic Data-mining Accelerator (ADA)--is also presented. ADA is a robust yet scalable solution for efficiently processing big sound archives using distributing computing technologies. Together, DeLMA and the ADA algorithm provide a powerful tool currently being used by the Bioacoustics Research Program (BRP) at the Cornell Lab of Orni...}
}

@misc{Zhang2015_Character_level,
    title = {Character-level Convolutional Networks for Text Classification},
    author = {Xiang Zhang and Junbo Zhao and Yann LeCun},
    year = {2015},
    eprint = {1509.01626},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1509.01626v3},
    abstract = {This article offers an empirical exploration on the use of character-level convolutional networks (ConvNets) for text classification. We constructed several large-scale datasets to show that character-level convolutional networks could achieve state-of-the-art or competitive results. Comparisons are offered against traditional models such as bag of words, n-grams and their TFIDF variants, and deep learning models such as word-based ConvNets and recurrent neural networks.}
}

@misc{Henaff2015_Deep,
    title = {Deep Convolutional Networks on Graph-Structured Data},
    author = {Mikael Henaff and Joan Bruna and Yann LeCun},
    year = {2015},
    eprint = {1506.05163},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1506.05163v1},
    abstract = {Deep Learning's recent successes have mostly relied on Convolutional Networks, which exploit fundamental statistical properties of images, sounds and video data: the local stationarity and multi-scale compositional structure, that allows expressing long range interactions in terms of shorter, localized interactions. However, there exist other important examples, such as text documents or bioinformatic data, that may lack some or all of these strong statistical regularities.   In this paper we co...}
}

@misc{Goroshin2015_Learning,
    title = {Learning to Linearize Under Uncertainty},
    author = {Ross Goroshin and Michael Mathieu and Yann LeCun},
    year = {2015},
    eprint = {1506.03011},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1506.03011v2},
    abstract = {Training deep feature hierarchies to solve supervised learning tasks has achieved state of the art performance on many problems in computer vision. However, a principled way in which to train such hierarchies in the unsupervised setting has remained elusive. In this work we suggest a new architecture and loss for training deep feature hierarchies that linearize the transformations observed in unlabeled natural video sequences. This is done by training a generative model to predict video frames. ...}
}

@misc{Zhao2015_Stacked,
    title = {Stacked What-Where Auto-encoders},
    author = {Junbo Zhao and Michael Mathieu and Ross Goroshin and Yann LeCun},
    year = {2015},
    eprint = {1506.02351},
    archivePrefix = {arXiv},
    primaryClass = {stat.ML},
    url = {https://arxiv.org/abs/1506.02351v8},
    abstract = {We present a novel architecture, the "stacked what-where auto-encoders" (SWWAE), which integrates discriminative and generative pathways and provides a unified approach to supervised, semi-supervised and unsupervised learning without relying on sampling during training. An instantiation of SWWAE uses a convolutional net (Convnet) (LeCun et al. (1998)) to encode the input, and employs a deconvolutional net (Deconvnet) (Zeiler et al. (2010)) to produce the reconstruction. The objective function in...}
}

@misc{Goroshin2015_Unsupervised,
    title = {Unsupervised Feature Learning from Temporal Data},
    author = {Ross Goroshin and Joan Bruna and Jonathan Tompson and David Eigen and Yann LeCun},
    year = {2015},
    eprint = {1504.02518},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1504.02518v2},
    abstract = {Current state-of-the-art classification and detection algorithms rely on supervised training. In this work we study unsupervised feature learning in the context of temporally coherent video data. We focus on feature learning from unlabeled video data, using the assumption that adjacent video frames contain semantically similar information. This assumption is exploited to train a convolutional pooling auto-encoder regularized by slowness and sparsity. We establish a connection between slow featur...}
}

@misc{Bruna2015_A,
    title = {A mathematical motivation for complex-valued convolutional networks},
    author = {Joan Bruna and Soumith Chintala and Yann LeCun and Serkan Piantino and Arthur Szlam and Mark Tygert},
    year = {2015},
    eprint = {1503.03438},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1503.03438v3},
    abstract = {A complex-valued convolutional network (convnet) implements the repeated application of the following composition of three operations, recursively applying the composition to an input vector of nonnegative real numbers: (1) convolution with complex-valued vectors followed by (2) taking the absolute value of every entry of the resulting vectors followed by (3) local averaging. For processing real-valued random vectors, complex-valued convnets can be viewed as "data-driven multiscale windowed powe...}
}

@misc{Zhang2015_Text,
    title = {Text Understanding from Scratch},
    author = {Xiang Zhang and Yann LeCun},
    year = {2015},
    eprint = {1502.01710},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1502.01710v5},
    abstract = {This article demontrates that we can apply deep learning to text understanding from character-level inputs all the way up to abstract text concepts, using temporal convolutional networks (ConvNets). We apply ConvNets to various large-scale datasets, including ontology classification, sentiment analysis, and text categorization. We show that temporal ConvNets can achieve astonishing performance without the knowledge of words, phrases, sentences and any other syntactic or semantic structures with ...}
}

@misc{Vasilache2014_Fast,
    title = {Fast Convolutional Nets With fbfft: A GPU Performance Evaluation},
    author = {Nicolas Vasilache and Jeff Johnson and Michael Mathieu and Soumith Chintala and Serkan Piantino and Yann LeCun},
    year = {2014},
    eprint = {1412.7580},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1412.7580v3},
    abstract = {We examine the performance profile of Convolutional Neural Network training on the current generation of NVIDIA Graphics Processing Units. We introduce two new Fast Fourier Transform convolution implementations: one based on NVIDIA's cuFFT library, and another based on a Facebook authored FFT implementation, fbfft, that provides significant speedups over cuFFT (over 1.5x) for whole CNNs. Both of these convolution implementations are available in open source, and are faster than NVIDIA's cuDNN im...}
}

@misc{Sprechmann2014_Audio,
    title = {Audio Source Separation with Discriminative Scattering Networks},
    author = {Pablo Sprechmann and Joan Bruna and Yann LeCun},
    year = {2014},
    eprint = {1412.7022},
    archivePrefix = {arXiv},
    primaryClass = {cs.SD},
    url = {https://arxiv.org/abs/1412.7022v3},
    abstract = {In this report we describe an ongoing line of research for solving single-channel source separation problems. Many monaural signal decomposition techniques proposed in the literature operate on a feature space consisting of a time-frequency representation of the input data. A challenge faced by these approaches is to effectively exploit the temporal dependencies of the signals at scales larger than the duration of a time-frame. In this work we propose to tackle this problem by modeling the signa...}
}

@misc{Zhang2014_Deep,
    title = {Deep learning with Elastic Averaging SGD},
    author = {Sixin Zhang and Anna Choromanska and Yann LeCun},
    year = {2014},
    eprint = {1412.6651},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1412.6651v8},
    abstract = {We study the problem of stochastic optimization for deep learning in the parallel computing environment under communication constraints. A new algorithm is proposed in this setting where the communication and coordination of work among concurrent processes (local workers), is based on an elastic force which links the parameters they compute with a center variable stored by the parameter server (master). The algorithm enables the local workers to perform more exploration, i.e. the algorithm allow...}
}

@misc{Sagun2014_Explorations,
    title = {Explorations on high dimensional landscapes},
    author = {Levent Sagun and V. Ugur Guney and Gerard Ben Arous and Yann LeCun},
    year = {2014},
    eprint = {1412.6615},
    archivePrefix = {arXiv},
    primaryClass = {stat.ML},
    url = {https://arxiv.org/abs/1412.6615v4},
    abstract = {Finding minima of a real valued non-convex function over a high dimensional space is a major challenge in science. We provide evidence that some such functions that are defined on high dimensional domains have a narrow band of values whose pre-image contains the bulk of its critical points. This is in contrast with the low dimensional picture in which this band is wide. Our simulations agree with the previous theoretical work on spin glasses that proves the existence of such a band when the dime...}
}

@misc{Goroshin2014_Unsupervised,
    title = {Unsupervised Learning of Spatiotemporally Coherent Metrics},
    author = {Ross Goroshin and Joan Bruna and Jonathan Tompson and David Eigen and Yann LeCun},
    year = {2014},
    eprint = {1412.6056},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1412.6056v6},
    abstract = {Current state-of-the-art classification and detection algorithms rely on supervised training. In this work we study unsupervised feature learning in the context of temporally coherent video data. We focus on feature learning from unlabeled video data, using the assumption that adjacent video frames contain semantically similar information. This assumption is exploited to train a convolutional pooling auto-encoder regularized by slowness and sparsity. We establish a connection between slow featur...}
}

@misc{Choromanska2014_The,
    title = {The Loss Surfaces of Multilayer Networks},
    author = {Anna Choromanska and Mikael Henaff and Michael Mathieu and Gérard Ben Arous and Yann LeCun},
    year = {2014},
    eprint = {1412.0233},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1412.0233v3},
    abstract = {We study the connection between the highly non-convex loss function of a simple model of the fully-connected feed-forward neural network and the Hamiltonian of the spherical spin-glass model under the assumptions of: i) variable independence, ii) redundancy in network parametrization, and iii) uniformity. These assumptions enable us to explain the complexity of the fully decoupled neural network through the prism of the results from random matrix theory. We show that for large-size decoupled net...}
}

@misc{Tompson2014_Efficient,
    title = {Efficient Object Localization Using Convolutional Networks},
    author = {Jonathan Tompson and Ross Goroshin and Arjun Jain and Yann LeCun and Christopher Bregler},
    year = {2014},
    eprint = {1411.4280},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1411.4280v3},
    abstract = {Recent state-of-the-art performance on human-body pose estimation has been achieved with Deep Convolutional Networks (ConvNets). Traditional ConvNet architectures include pooling and sub-sampling layers which reduce computational requirements, introduce invariance and prevent over-training. These benefits of pooling come at the cost of reduced localization accuracy. We introduce a novel architecture which includes an efficient `position refinement' model that is trained to estimate the joint off...}
}

@misc{Bojarski2014_Differentially_,
    title = {Differentially- and non-differentially-private random decision trees},
    author = {Mariusz Bojarski and Anna Choromanska and Krzysztof Choromanski and Yann LeCun},
    year = {2014},
    eprint = {1410.6973},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1410.6973v2},
    abstract = {We consider supervised learning with random decision trees, where the tree construction is completely random. The method is popularly used and works well in practice despite the simplicity of the setting, but its statistical mechanism is not yet well-understood. In this paper we provide strong theoretical guarantees regarding learning with random decision trees. We analyze and compare three different variants of the algorithm that have minimal memory requirements: majority voting, threshold aver...}
}

@misc{Jain2014_MoDeep_,
    title = {MoDeep: A Deep Learning Framework Using Motion Features for Human Pose Estimation},
    author = {Arjun Jain and Jonathan Tompson and Yann LeCun and Christoph Bregler},
    year = {2014},
    eprint = {1409.7963},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1409.7963v1},
    abstract = {In this work, we propose a novel and efficient method for articulated human pose estimation in videos using a convolutional network architecture, which incorporates both color and motion features. We propose a new human body pose dataset, FLIC-motion, that extends the FLIC dataset with additional motion features. We apply our architecture to this dataset and report significantly better performance than current state-of-the-art pose detection systems.}
}

@misc{Žbontar2014_Computing,
    title = {Computing the Stereo Matching Cost with a Convolutional Neural Network},
    author = {Jure Žbontar and Yann LeCun},
    year = {2014},
    doi = {10.1109/CVPR.2015.7298767},
    eprint = {1409.4326},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1409.4326v2},
    abstract = {We present a method for extracting depth information from a rectified image pair. We train a convolutional neural network to predict how well two image patches match and use it to compute the stereo matching cost. The cost is refined by cross-based cost aggregation and semiglobal matching, followed by a left-right consistency check to eliminate errors in the occluded regions. Our stereo method achieves an error rate of 2.61 \% on the KITTI stereo dataset and is currently (August 2014) the top per...}
}

@misc{Tompson2014_Joint,
    title = {Joint Training of a Convolutional Network and a Graphical Model for Human Pose Estimation},
    author = {Jonathan Tompson and Arjun Jain and Yann LeCun and Christoph Bregler},
    year = {2014},
    eprint = {1406.2984},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1406.2984v2},
    abstract = {This paper proposes a new hybrid architecture that consists of a deep Convolutional Network and a Markov Random Field. We show how this architecture is successfully applied to the challenging problem of articulated human pose estimation in monocular images. The architecture can exploit structural domain constraints such as geometric relationships between body joint locations. We show that joint training of these two model paradigms improves performance and allows us to significantly outperform e...}
}

@misc{Mathieu2014_Fast,
    title = {Fast Approximation of Rotations and Hessians matrices},
    author = {Michael Mathieu and Yann LeCun},
    year = {2014},
    eprint = {1404.7195},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1404.7195v1},
    abstract = {A new method to represent and approximate rotation matrices is introduced. The method represents approximations of a rotation matrix \$Q\$ with linearithmic complexity, i.e. with \$\frac\{1\}\{2\}n\lg(n)\$ rotations over pairs of coordinates, arranged in an FFT-like fashion. The approximation is "learned" using gradient descent. It allows to represent symmetric matrices \$H\$ as \$QDQ\textasciicircum{}T\$ where \$D\$ is a diagonal matrix. It can be used to approximate covariance matrix of Gaussian models in order to speed up ...}
}

@misc{Denton2014_Exploiting,
    title = {Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation},
    author = {Remi Denton and Wojciech Zaremba and Joan Bruna and Yann LeCun and Rob Fergus},
    year = {2014},
    eprint = {1404.0736},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1404.0736v2},
    abstract = {We present techniques for speeding up the test-time evaluation of large convolutional networks, designed for object recognition tasks. These models deliver impressive accuracy but each image evaluation requires millions of floating point operations, making their deployment on smartphones and Internet-scale clusters problematic. The computation is dominated by the convolution operations in the lower layers of the model. We exploit the linear structure present within the convolutional filters to d...}
}

@misc{Sermanet2013_OverFeat_,
    title = {OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks},
    author = {Pierre Sermanet and David Eigen and Xiang Zhang and Michael Mathieu and Rob Fergus and Yann LeCun},
    year = {2013},
    eprint = {1312.6229},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1312.6229v4},
    abstract = {We present an integrated framework for using Convolutional Networks for classification, localization and detection. We show how a multiscale and sliding window approach can be efficiently implemented within a ConvNet. We also introduce a novel deep learning approach to localization by learning to predict object boundaries. Bounding boxes are then accumulated rather than suppressed in order to increase detection confidence. We show that different tasks can be learned simultaneously using a single...}
}

@misc{Bruna2013_Spectral,
    title = {Spectral Networks and Locally Connected Networks on Graphs},
    author = {Joan Bruna and Wojciech Zaremba and Arthur Szlam and Yann LeCun},
    year = {2013},
    eprint = {1312.6203},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1312.6203v3},
    abstract = {Convolutional Neural Networks are extremely efficient architectures in image and audio recognition tasks, thanks to their ability to exploit the local translational invariance of signal classes over their domain. In this paper we consider possible generalizations of CNNs to signals defined on more general domains without the action of a translation group. In particular, we propose two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the ...}
}

@misc{Mathieu2013_Fast,
    title = {Fast Training of Convolutional Networks through FFTs},
    author = {Michael Mathieu and Mikael Henaff and Yann LeCun},
    year = {2013},
    eprint = {1312.5851},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1312.5851v5},
    abstract = {Convolutional networks are one of the most widely employed architectures in computer vision and machine learning. In order to leverage their ability to learn complex functions, large amounts of data are required for training. Training a large convolutional network to produce state-of-the-art results can take weeks, even when using modern GPUs. Producing labels using a trained network can also be costly when dealing with web-scale datasets. In this work, we present a simple algorithm which accele...}
}

@misc{Eigen2013_Understanding,
    title = {Understanding Deep Architectures using a Recursive Convolutional Network},
    author = {David Eigen and Jason Rolfe and Rob Fergus and Yann LeCun},
    year = {2013},
    eprint = {1312.1847},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1312.1847v2},
    abstract = {A key challenge in designing convolutional network models is sizing them appropriately. Many factors are involved in these decisions, including number of layers, feature maps, kernel sizes, etc. Complicating this further is the fact that each of these influence not only the numbers and dimensions of the activation units, but also the total number of parameters. In this paper we focus on assessing the independent contributions of three of these linked variables: The numbers of layers, feature map...}
}

@misc{Bruna2013_Signal,
    title = {Signal Recovery from Pooling Representations},
    author = {Joan Bruna and Arthur Szlam and Yann LeCun},
    year = {2013},
    eprint = {1311.4025},
    archivePrefix = {arXiv},
    primaryClass = {stat.ML},
    url = {https://arxiv.org/abs/1311.4025v3},
    abstract = {In this work we compute lower Lipschitz bounds of \$\ell\_p\$ pooling operators for \$p=1, 2, \infty\$ as well as \$\ell\_p\$ pooling operators preceded by half-rectification layers. These give sufficient conditions for the design of invertible neural network layers. Numerical experiments on MNIST and image patches confirm that pooling layers can be inverted with phase recovery algorithms. Moreover, the regularity of the inverse pooling, controlled by the lower Lipschitz constant, is empirically verifie...}
}

@misc{Rolfe2013_Discriminative,
    title = {Discriminative Recurrent Sparse Auto-Encoders},
    author = {Jason Tyler Rolfe and Yann LeCun},
    year = {2013},
    eprint = {1301.3775},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1301.3775v4},
    abstract = {We present the discriminative recurrent sparse auto-encoder model, comprising a recurrent encoder of rectified linear units, unrolled for a fixed number of iterations, and connected to two linear decoders that reconstruct the input and predict its supervised classification. Training via backpropagation-through-time initially minimizes an unsupervised sparse reconstruction error; the loss function is then augmented with a discriminative term on the supervised classification. The depth implicit in...}
}

@misc{Schaul2013_Adaptive,
    title = {Adaptive learning rates and parallelization for stochastic, sparse, non-smooth gradients},
    author = {Tom Schaul and Yann LeCun},
    year = {2013},
    eprint = {1301.3764},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1301.3764v2},
    abstract = {Recent work has established an empirically successful framework for adapting learning rates for stochastic gradient descent (SGD). This effectively removes all needs for tuning, while automatically reducing learning rates over time on stationary problems, and permitting learning rates to grow appropriately in non-stationary tasks. Here, we extend the idea in three directions, addressing proper minibatch parallelization, including reweighted updates for sparse or orthogonal gradients, improving r...}
}

@misc{Goroshin2013_Saturating,
    title = {Saturating Auto-Encoders},
    author = {Rostislav Goroshin and Yann LeCun},
    year = {2013},
    eprint = {1301.3577},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1301.3577v3},
    abstract = {We introduce a simple new regularizer for auto-encoders whose hidden-unit activation functions contain at least one zero-gradient (saturated) region. This regularizer explicitly encourages activations in the saturated region(s) of the corresponding activation function. We call these Saturating Auto-Encoders (SATAE). We show that the saturation regularizer explicitly limits the SATAE's ability to reconstruct inputs which are not near the data manifold. Furthermore, we show that a wide variety of ...}
}

@misc{Couprie2013_Indoor,
    title = {Indoor Semantic Segmentation using depth information},
    author = {Camille Couprie and Clément Farabet and Laurent Najman and Yann LeCun},
    year = {2013},
    eprint = {1301.3572},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1301.3572v2},
    abstract = {This work addresses multi-class segmentation of indoor scenes with RGB-D inputs. While this area of research has gained much attention recently, most works still rely on hand-crafted features. In contrast, we apply a multiscale convolutional network to learn features directly from the images and the depth information. We obtain state-of-the-art on the NYU-v2 depth dataset with an accuracy of 64.5\%. We illustrate the labeling of indoor scenes in videos sequences that could be processed in real-ti...}
}

@misc{Bruna2013_Learning,
    title = {Learning Stable Group Invariant Representations with Convolutional Networks},
    author = {Joan Bruna and Arthur Szlam and Yann LeCun},
    year = {2013},
    eprint = {1301.3537},
    archivePrefix = {arXiv},
    primaryClass = {cs.AI},
    url = {https://arxiv.org/abs/1301.3537v1},
    abstract = {Transformation groups, such as translations or rotations, effectively express part of the variability observed in many recognition problems. The group structure enables the construction of invariant signal representations with appealing mathematical properties, where convolutions, together with pooling operators, bring stability to additive and geometric perturbations of the input. Whereas physical transformation groups are ubiquitous in image and audio applications, they do not account for all ...}
}

@misc{Vatanen2013_Pushing,
    title = {Pushing Stochastic Gradient towards Second-Order Methods -- Backpropagation Learning with Transformations in Nonlinearities},
    author = {Tommi Vatanen and Tapani Raiko and Harri Valpola and Yann LeCun},
    year = {2013},
    eprint = {1301.3476},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/1301.3476v3},
    abstract = {Recently, we proposed to transform the outputs of each hidden neuron in a multi-layer perceptron network to have zero output and zero slope on average, and use separate shortcut connections to model the linear dependencies instead. We continue the work by firstly introducing a third transformation to normalize the scale of the outputs of each hidden neuron, and secondly by analyzing the connections to second order optimization methods. We show that the transformations make a simple stochastic gr...}
}

@misc{Couprie2013_Causal,
    title = {Causal graph-based video segmentation},
    author = {Camille Couprie and Clément Farabet and Yann LeCun},
    year = {2013},
    eprint = {1301.1671},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1301.1671v1},
    abstract = {Numerous approaches in image processing and computer vision are making use of super-pixels as a pre-processing step. Among the different methods producing such over-segmentation of an image, the graph-based approach of Felzenszwalb and Huttenlocher is broadly employed. One of its interesting properties is that the regions are computed in a greedy manner in quasi-linear time. The algorithm may be trivially extended to video segmentation by considering a video as a 3D volume, however, this can not...}
}

@misc{Sermanet2012_Pedestrian,
    title = {Pedestrian Detection with Unsupervised Multi-Stage Feature Learning},
    author = {Pierre Sermanet and Koray Kavukcuoglu and Soumith Chintala and Yann LeCun},
    year = {2012},
    eprint = {1212.0142},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1212.0142v2},
    abstract = {Pedestrian detection is a problem of considerable practical interest. Adding to the list of successful applications of deep learning methods to vision, we report state-of-the-art and competitive results on all major pedestrian datasets with a convolutional network model. The model uses a few new twists, such as multi-stage features, connections that skip layers to integrate global shape information with local distinctive motif information, and an unsupervised method based on convolutional sparse...}
}

@misc{Schaul2012_No,
    title = {No More Pesky Learning Rates},
    author = {Tom Schaul and Sixin Zhang and Yann LeCun},
    year = {2012},
    eprint = {1206.1106},
    archivePrefix = {arXiv},
    primaryClass = {stat.ML},
    url = {https://arxiv.org/abs/1206.1106v2},
    abstract = {The performance of stochastic gradient descent (SGD) depends critically on how learning rates are tuned and decreased over time. We propose a method to automatically adjust multiple learning rates so as to minimize the expected error at any one time. The method relies on local gradient variations across samples. In our approach, learning rates can increase as well as decrease, making it suitable for non-stationary problems. Using a number of convex and non-convex learning tasks, we show that the...}
}

@misc{Sermanet2012_Convolutional,
    title = {Convolutional Neural Networks Applied to House Numbers Digit Classification},
    author = {Pierre Sermanet and Soumith Chintala and Yann LeCun},
    year = {2012},
    eprint = {1204.3968},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1204.3968v1},
    abstract = {We classify digits of real-world house numbers using convolutional neural networks (ConvNets). ConvNets are hierarchical feature learning neural networks whose structure is biologically inspired. Unlike many popular vision approaches that are hand-designed, ConvNets can automatically learn a unique set of features optimized for a given task. We augmented the traditional ConvNet architecture by learning multi-stage features and by using Lp pooling and establish a new state-of-the-art of 94.85\% ac...}
}

@misc{Szlam2012_Fast,
    title = {Fast approximations to structured sparse coding and applications to object classification},
    author = {Arthur Szlam and Karol Gregor and Yann LeCun},
    year = {2012},
    eprint = {1202.6384},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1202.6384v1},
    abstract = {We describe a method for fast approximation of sparse coding. The input space is subdivided by a binary decision tree, and we simultaneously learn a dictionary and assignment of allowed dictionary elements for each leaf of the tree. We store a lookup table with the assignments and the pseudoinverses for each node, allowing for very fast inference. We give an algorithm for learning the tree, the dictionary and the dictionary element assignment, and In the process of describing this algorithm, we ...}
}

@misc{Farabet2012_Scene,
    title = {Scene Parsing with Multiscale Feature Learning, Purity Trees, and Optimal Covers},
    author = {Clément Farabet and Camille Couprie and Laurent Najman and Yann LeCun},
    year = {2012},
    eprint = {1202.2160},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1202.2160v2},
    abstract = {Scene parsing, or semantic segmentation, consists in labeling each pixel in an image with the category of the object it belongs to. It is a challenging task that involves the simultaneous detection, segmentation and recognition of all the objects in the image.   The scene parsing method proposed here starts by computing a tree of segments from a graph of pixel dissimilarities. Simultaneously, a set of dense feature vectors is computed which encodes regions of multiple sizes centered on each pixe...}
}

@misc{Gregor2011_Learning,
    title = {Learning Representations by Maximizing Compression},
    author = {Karol Gregor and Yann LeCun},
    year = {2011},
    eprint = {1108.1169},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1108.1169v1},
    abstract = {We give an algorithm that learns a representation of data through compression. The algorithm 1) predicts bits sequentially from those previously seen and 2) has a structure and a number of computations similar to an autoencoder. The likelihood under the model can be calculated exactly, and arithmetic coding can be used directly for compression. When training on digits the algorithm learns filters similar to those of restricted boltzman machines and denoising autoencoders. Independent samples can...}
}

@misc{Gregor2011_Efficient,
    title = {Efficient Learning of Sparse Invariant Representations},
    author = {Karol Gregor and Yann LeCun},
    year = {2011},
    eprint = {1105.5307},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1105.5307v1},
    abstract = {We propose a simple and efficient algorithm for learning sparse invariant representations from unlabeled data with fast inference. When trained on short movies sequences, the learned features are selective to a range of orientations and spatial frequencies, but robust to a wide range of positions, similar to complex cells in the primary visual cortex. We give a hierarchical version of the algorithm, and give guarantees of fast convergence under certain conditions.}
}

@misc{Kavukcuoglu2010_Fast,
    title = {Fast Inference in Sparse Coding Algorithms with Applications to Object Recognition},
    author = {Koray Kavukcuoglu and Marc'Aurelio Ranzato and Yann LeCun},
    year = {2010},
    eprint = {1010.3467},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1010.3467v1},
    abstract = {Adaptive sparse coding methods learn a possibly overcomplete set of basis functions, such that natural image patches can be reconstructed by linearly combining a small subset of these bases. The applicability of these methods to visual object recognition tasks has been limited because of the prohibitive cost of the optimization algorithms required to compute the sparse representation. In this work we propose a simple and efficient algorithm to learn basis functions. After training, this model al...}
}

@misc{Szlam2010_Convolutional,
    title = {Convolutional Matching Pursuit and Dictionary Training},
    author = {Arthur Szlam and Koray Kavukcuoglu and Yann LeCun},
    year = {2010},
    eprint = {1010.0422},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV},
    url = {https://arxiv.org/abs/1010.0422v1},
    abstract = {Matching pursuit and K-SVD is demonstrated in the translation invariant setting}
}

@misc{Gregor2010_Emergence,
    title = {Emergence of Complex-Like Cells in a Temporal Product Network with Local Receptive Fields},
    author = {Karo Gregor and Yann LeCun},
    year = {2010},
    eprint = {1006.0448},
    archivePrefix = {arXiv},
    primaryClass = {cs.NE},
    url = {https://arxiv.org/abs/1006.0448v1},
    abstract = {We introduce a new neural architecture and an unsupervised algorithm for learning invariant representations from temporal sequence of images. The system uses two groups of complex cells whose outputs are combined multiplicatively: one that represents the content of the image, constrained to be constant over several consecutive frames, and one that represents the precise location of features, which is allowed to vary over time but constrained to be sparse. The architecture uses an encoder to extr...}
}