{
  "0": {
    "input": {
      "id": 0,
      "name": "Yann LeCun",
      "scholar_id": "WLN3QrAAAAAJ",
      "semantic_scholar_id": null,
      "arxiv_name": "Yann LeCun"
    },
    "errors": {},
    "parsed_at": "2025-11-28T15:46:29.230382",
    "arxiv": {
      "name": "Yann LeCun",
      "source": "arxiv",
      "source_id": "Yann LeCun",
      "affiliation": null,
      "orcid": null,
      "homepage": null,
      "interests": [],
      "metrics": {
        "citations": 0,
        "citations_recent": 0,
        "h_index": 0,
        "h_index_recent": 0,
        "i10_index": 0,
        "publication_count": 183
      },
      "citations_per_year": {},
      "publications_per_year": {
        "2025": 16,
        "2024": 28,
        "2023": 20,
        "2022": 25,
        "2021": 9,
        "2020": 1,
        "2019": 4,
        "2018": 8,
        "2017": 7,
        "2016": 15,
        "2015": 15,
        "2014": 13,
        "2013": 12,
        "2012": 5,
        "2011": 2,
        "2010": 3
      },
      "first_publication_year": 2010,
      "last_publication_year": 2025,
      "years_active": 15,
      "publications": [
        {
          "title": "LeJEPA: Provable and Scalable Self-Supervised Learning Without the Heuristics",
          "year": 2025,
          "citations": 0,
          "abstract": "Learning manipulable representations of the world and its dynamics is central to AI. Joint-Embedding Predictive Architectures (JEPAs) offer a promising blueprint, but lack of practical guidance and theory has led to ad-hoc R&D. We present a comprehensive theory of JEPAs and instantiate it in {\\bf LeJEPA}, a lean, scalable, and theoretically grounded training objective. First, we identify the isotropic Gaussian as the optimal distribution that JEPAs' embeddings should follow to minimize downstream prediction risk. Second, we introduce a novel objective--{\\bf Sketched Isotropic Gaussian Regularization} (SIGReg)--to constrain embeddings to reach that ideal distribution. Combining the JEPA predictive loss with SIGReg yields LeJEPA with numerous theoretical and practical benefits: (i) single trade-off hyperparameter, (ii) linear time and memory complexity, (iii) stability across hyper-parameters, architectures (ResNets, ViTs, ConvNets) and domains, (iv) heuristics-free, e.g., no stop-gradient, no teacher-student, no hyper-parameter schedulers, and (v) distributed training-friendly implementation requiring only $\\approx$50 lines of code. Our empirical validation covers 10+ datasets, 60+ architectures, all with varying scales and domains. As an example, using imagenet-1k for pretraining and linear evaluation with frozen backbone, LeJEPA reaches 79\\% with a ViT-H/14. We hope that the simplicity and theory-friendly ecosystem offered by LeJEPA will reestablish self-supervised pre-training as a core pillar of AI research (\\href{https://github.com/rbalestr-lab/lejepa}{GitHub repo}).",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2511.08544v3",
          "authors": [
            "Randall Balestriero",
            "Yann LeCun"
          ]
        },
        {
          "title": "Cambrian-S: Towards Spatial Supersensing in Video",
          "year": 2025,
          "citations": 0,
          "abstract": "We argue that progress in true multimodal intelligence calls for a shift from reactive, task-driven systems and brute-force long context towards a broader paradigm of supersensing. We frame spatial supersensing as four stages beyond linguistic-only understanding: semantic perception (naming what is seen), streaming event cognition (maintaining memory across continuous experiences), implicit 3D spatial cognition (inferring the world behind pixels), and predictive world modeling (creating internal models that filter and organize information). Current benchmarks largely test only the early stages, offering narrow coverage of spatial cognition and rarely challenging models in ways that require true world modeling. To drive progress in spatial supersensing, we present VSI-SUPER, a two-part benchmark: VSR (long-horizon visual spatial recall) and VSC (continual visual spatial counting). These tasks require arbitrarily long video inputs yet are resistant to brute-force context expansion. We then test data scaling limits by curating VSI-590K and training Cambrian-S, achieving +30% absolute improvement on VSI-Bench without sacrificing general capabilities. Yet performance on VSI-SUPER remains limited, indicating that scale alone is insufficient for spatial supersensing. We propose predictive sensing as a path forward, presenting a proof-of-concept in which a self-supervised next-latent-frame predictor leverages surprise (prediction error) to drive memory and event segmentation. On VSI-SUPER, this approach substantially outperforms leading proprietary baselines, showing that spatial supersensing requires models that not only see but also anticipate, select, and organize experience.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2511.04670v1",
          "authors": [
            "Shusheng Yang",
            "Jihan Yang",
            "Pinzhi Huang",
            "Ellis Brown",
            "Zihao Yang",
            "Yue Yu",
            "Shengbang Tong",
            "Zihan Zheng",
            "Yifan Xu",
            "Muhan Wang",
            "Daohan Lu",
            "Rob Fergus",
            "Yann LeCun",
            "Li Fei-Fei",
            "Saining Xie"
          ]
        },
        {
          "title": "Attention Sinks and Compression Valleys in LLMs are Two Sides of the Same Coin",
          "year": 2025,
          "citations": 0,
          "abstract": "Attention sinks and compression valleys have attracted significant attention as two puzzling phenomena in large language models, but have been studied in isolation. In this work, we present a surprising connection between attention sinks and compression valleys, tracing both to the formation of massive activations in the residual stream. We prove theoretically that massive activations necessarily produce representational compression and establish bounds on the resulting entropy reduction. Through experiments across several models (410M-120B parameters), we confirm that when the beginning-of-sequence token develops extreme activation norms in the middle layers, both compression valleys and attention sinks emerge simultaneously. Targeted ablation studies validate our theoretical predictions. This unified view motivates us to propose the Mix-Compress-Refine theory of information flow, as an attempt to explain how LLMs organize their computation in depth by controlling attention and representational compression via massive activations. Specifically, we posit that Transformer-based LLMs process tokens in three distinct phases: (1) broad mixing in the early layers, (2) compressed computation with limited mixing in the middle layers, and (3) selective refinement in the late layers. Our framework helps explain why embedding tasks perform best at intermediate layers, whereas generation tasks benefit from full-depth processing, clarifying differences in task-dependent representations.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2510.06477v1",
          "authors": [
            "Enrique Queipo-de-Llano",
            "Álvaro Arroyo",
            "Federico Barbero",
            "Xiaowen Dong",
            "Michael Bronstein",
            "Yann LeCun",
            "Ravid Shwartz-Ziv"
          ]
        },
        {
          "title": "Gaussian Embeddings: How JEPAs Secretly Learn Your Data Density",
          "year": 2025,
          "citations": 0,
          "abstract": "Joint Embedding Predictive Architectures (JEPAs) learn representations able to solve numerous downstream tasks out-of-the-box. JEPAs combine two objectives: (i) a latent-space prediction term, i.e., the representation of a slightly perturbed sample must be predictable from the original sample's representation, and (ii) an anti-collapse term, i.e., not all samples should have the same representation. While (ii) is often considered as an obvious remedy to representation collapse, we uncover that JEPAs' anti-collapse term does much more--it provably estimates the data density. In short, any successfully trained JEPA can be used to get sample probabilities, e.g., for data curation, outlier detection, or simply for density estimation. Our theoretical finding is agnostic of the dataset and architecture used--in any case one can compute the learned probabilities of sample $x$ efficiently and in closed-form using the model's Jacobian matrix at $x$. Our findings are empirically validated across datasets (synthetic, controlled, and Imagenet) and across different Self Supervised Learning methods falling under the JEPA family (I-JEPA and DINOv2) and on multimodal models, such as MetaCLIP. We denote the method extracting the JEPA learned density as {\\bf JEPA-SCORE}.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2510.05949v1",
          "authors": [
            "Randall Balestriero",
            "Nicolas Ballas",
            "Mike Rabbat",
            "Yann LeCun"
          ]
        },
        {
          "title": "LLM-JEPA: Large Language Models Meet Joint Embedding Predictive Architectures",
          "year": 2025,
          "citations": 0,
          "abstract": "Large Language Model (LLM) pretraining, finetuning, and evaluation rely on input-space reconstruction and generative capabilities. Yet, it has been observed in vision that embedding-space training objectives, e.g., with Joint Embedding Predictive Architectures (JEPAs), are far superior to their input-space counterpart. That mismatch in how training is achieved between language and vision opens up a natural question: {\\em can language training methods learn a few tricks from the vision ones?} The lack of JEPA-style LLM is a testimony of the challenge in designing such objectives for language. In this work, we propose a first step in that direction where we develop LLM-JEPA, a JEPA based solution for LLMs applicable both to finetuning and pretraining. Thus far, LLM-JEPA is able to outperform the standard LLM training objectives by a significant margin across models, all while being robust to overfiting. Those findings are observed across numerous datasets (NL-RX, GSM8K, Spider, RottenTomatoes) and various models from the Llama3, OpenELM, Gemma2 and Olmo families. Code: https://github.com/rbalestr-lab/llm-jepa.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2509.14252v2",
          "authors": [
            "Hai Huang",
            "Yann LeCun",
            "Randall Balestriero"
          ]
        },
        {
          "title": "Back to the Features: DINO as a Foundation for Video World Models",
          "year": 2025,
          "citations": 0,
          "abstract": "We present DINO-world, a powerful generalist video world model trained to predict future frames in the latent space of DINOv2. By leveraging a pre-trained image encoder and training a future predictor on a large-scale uncurated video dataset, DINO-world learns the temporal dynamics of diverse scenes, from driving and indoor scenes to simulated environments. We show that DINO-world outperforms previous models on a variety of video prediction benchmarks, e.g. segmentation and depth forecasting, and demonstrates strong understanding of intuitive physics. Furthermore, we show that it is possible to fine-tune the predictor on observation-action trajectories. The resulting action-conditioned world model can be used for planning by simulating candidate trajectories in latent space.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2507.19468v1",
          "authors": [
            "Federico Baldassarre",
            "Marc Szafraniec",
            "Basile Terver",
            "Vasil Khalidov",
            "Francisco Massa",
            "Yann LeCun",
            "Patrick Labatut",
            "Maximilian Seitzer",
            "Piotr Bojanowski"
          ]
        },
        {
          "title": "Whole-Body Conditioned Egocentric Video Prediction",
          "year": 2025,
          "citations": 0,
          "abstract": "We train models to Predict Ego-centric Video from human Actions (PEVA), given the past video and an action represented by the relative 3D body pose. By conditioning on kinematic pose trajectories, structured by the joint hierarchy of the body, our model learns to simulate how physical human actions shape the environment from a first-person point of view. We train an auto-regressive conditional diffusion transformer on Nymeria, a large-scale dataset of real-world egocentric video and body pose capture. We further design a hierarchical evaluation protocol with increasingly challenging tasks, enabling a comprehensive analysis of the model's embodied prediction and control abilities. Our work represents an initial attempt to tackle the challenges of modeling complex real-world environments and embodied agent behaviors with video prediction from the perspective of a human.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2506.21552v1",
          "authors": [
            "Yutong Bai",
            "Danny Tran",
            "Amir Bar",
            "Yann LeCun",
            "Trevor Darrell",
            "Jitendra Malik"
          ]
        },
        {
          "title": "V-JEPA 2: Self-Supervised Video Models Enable Understanding, Prediction and Planning",
          "year": 2025,
          "citations": 0,
          "abstract": "A major challenge for modern AI is to learn to understand the world and learn to act largely by observation. This paper explores a self-supervised approach that combines internet-scale video data with a small amount of interaction data (robot trajectories), to develop models capable of understanding, predicting, and planning in the physical world. We first pre-train an action-free joint-embedding-predictive architecture, V-JEPA 2, on a video and image dataset comprising over 1 million hours of internet video. V-JEPA 2 achieves strong performance on motion understanding (77.3 top-1 accuracy on Something-Something v2) and state-of-the-art performance on human action anticipation (39.7 recall-at-5 on Epic-Kitchens-100) surpassing previous task-specific models. Additionally, after aligning V-JEPA 2 with a large language model, we demonstrate state-of-the-art performance on multiple video question-answering tasks at the 8 billion parameter scale (e.g., 84.0 on PerceptionTest, 76.9 on TempCompass). Finally, we show how self-supervised learning can be applied to robotic planning tasks by post-training a latent action-conditioned world model, V-JEPA 2-AC, using less than 62 hours of unlabeled robot videos from the Droid dataset. We deploy V-JEPA 2-AC zero-shot on Franka arms in two different labs and enable picking and placing of objects using planning with image goals. Notably, this is achieved without collecting any data from the robots in these environments, and without any task-specific training or reward. This work demonstrates how self-supervised learning from web-scale data and a small amount of robot interaction data can yield a world model capable of planning in the physical world.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2506.09985v1",
          "authors": [
            "Mido Assran",
            "Adrien Bardes",
            "David Fan",
            "Quentin Garrido",
            "Russell Howes",
            "Mojtaba",
            "Komeili",
            "Matthew Muckley",
            "Ammar Rizvi",
            "Claire Roberts",
            "Koustuv Sinha",
            "Artem Zholus",
            "Sergio Arnaud",
            "Abha Gejji",
            "Ada Martin",
            "Francois Robert Hogan",
            "Daniel Dugas",
            "Piotr Bojanowski",
            "Vasil Khalidov",
            "Patrick Labatut",
            "Francisco Massa",
            "Marc Szafraniec",
            "Kapil Krishnakumar",
            "Yong Li",
            "Xiaodong Ma",
            "Sarath Chandar",
            "Franziska Meier",
            "Yann LeCun",
            "Michael Rabbat",
            "Nicolas Ballas"
          ]
        },
        {
          "title": "OSVI-WM: One-Shot Visual Imitation for Unseen Tasks using World-Model-Guided Trajectory Generation",
          "year": 2025,
          "citations": 0,
          "abstract": "Visual imitation learning enables robotic agents to acquire skills by observing expert demonstration videos. In the one-shot setting, the agent generates a policy after observing a single expert demonstration without additional fine-tuning. Existing approaches typically train and evaluate on the same set of tasks, varying only object configurations, and struggle to generalize to unseen tasks with different semantic or structural requirements. While some recent methods attempt to address this, they exhibit low success rates on hard test tasks that, despite being visually similar to some training tasks, differ in context and require distinct responses. Additionally, most existing methods lack an explicit model of environment dynamics, limiting their ability to reason about future states. To address these limitations, we propose a novel framework for one-shot visual imitation learning via world-model-guided trajectory generation. Given an expert demonstration video and the agent's initial observation, our method leverages a learned world model to predict a sequence of latent states and actions. This latent trajectory is then decoded into physical waypoints that guide the agent's execution. Our method is evaluated on two simulated benchmarks and three real-world robotic platforms, where it consistently outperforms prior approaches, with over 30% improvement in some cases.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2505.20425v1",
          "authors": [
            "Raktim Gautam Goswami",
            "Prashanth Krishnamurthy",
            "Yann LeCun",
            "Farshad Khorrami"
          ]
        },
        {
          "title": "From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning",
          "year": 2025,
          "citations": 0,
          "abstract": "Humans organize knowledge into compact categories that balance compression with semantic meaning preservation. Large Language Models (LLMs) demonstrate striking linguistic abilities, yet whether they achieve this same balance remains unclear. We apply the Information Bottleneck principle to quantitatively compare how LLMs and humans navigate this compression-meaning trade-off. Analyzing embeddings from 40+ LLMs against classic human categorization benchmarks, we uncover three key findings. First, LLMs broadly align with human categories but miss fine-grained semantic distinctions crucial for human understanding. Second, LLMs demonstrate aggressive statistical compression, achieving ``optimal'' information-theoretic efficiency, while humans prioritize contextual richness and adaptive flexibility. Third, encoder models surprisingly outperform decoder models in human alignment, suggesting that generation and understanding rely on distinct mechanisms in current architectures. In addition, training dynamics analysis reveals that conceptual structure develops in distinct phases: rapid initial formation followed by architectural reorganization, with semantic processing migrating from deeper to mid-network layers as models discover more efficient encoding. These divergent strategies, where LLMs optimize for compression and humans for adaptive utility, reveal fundamental differences between artificial and biological intelligence, guiding development toward more human-aligned AI.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2505.17117v5",
          "authors": [
            "Chen Shani",
            "Liron Soffer",
            "Dan Jurafsky",
            "Yann LeCun",
            "Ravid Shwartz-Ziv"
          ]
        },
        {
          "title": "Scaling Language-Free Visual Representation Learning",
          "year": 2025,
          "citations": 0,
          "abstract": "Visual Self-Supervised Learning (SSL) currently underperforms Contrastive Language-Image Pretraining (CLIP) in multimodal settings such as Visual Question Answering (VQA). This multimodal gap is often attributed to the semantics introduced by language supervision, even though visual SSL and CLIP models are often trained on different data. In this work, we ask the question: \"Do visual self-supervised approaches lag behind CLIP due to the lack of language supervision, or differences in the training data?\" We study this question by training both visual SSL and CLIP models on the same MetaCLIP data, and leveraging VQA as a diverse testbed for vision encoders. In this controlled setup, visual SSL models scale better than CLIP models in terms of data and model capacity, and visual SSL performance does not saturate even after scaling up to 7B parameters. Consequently, we observe visual SSL methods achieve CLIP-level performance on a wide range of VQA and classic vision benchmarks. These findings demonstrate that pure visual SSL can match language-supervised visual pretraining at scale, opening new opportunities for vision-centric representation learning.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2504.01017v1",
          "authors": [
            "David Fan",
            "Shengbang Tong",
            "Jiachen Zhu",
            "Koustuv Sinha",
            "Zhuang Liu",
            "Xinlei Chen",
            "Michael Rabbat",
            "Nicolas Ballas",
            "Yann LeCun",
            "Amir Bar",
            "Saining Xie"
          ]
        },
        {
          "title": "Transformers without Normalization",
          "year": 2025,
          "citations": 0,
          "abstract": "Normalization layers are ubiquitous in modern neural networks and have long been considered essential. This work demonstrates that Transformers without normalization can achieve the same or better performance using a remarkably simple technique. We introduce Dynamic Tanh (DyT), an element-wise operation $DyT($x$) = \\tanh(α$x$)$, as a drop-in replacement for normalization layers in Transformers. DyT is inspired by the observation that layer normalization in Transformers often produces tanh-like, $S$-shaped input-output mappings. By incorporating DyT, Transformers without normalization can match or exceed the performance of their normalized counterparts, mostly without hyperparameter tuning. We validate the effectiveness of Transformers with DyT across diverse settings, ranging from recognition to generation, supervised to self-supervised learning, and computer vision to language models. These findings challenge the conventional understanding that normalization layers are indispensable in modern neural networks, and offer new insights into their role in deep networks.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2503.10622v2",
          "authors": [
            "Jiachen Zhu",
            "Xinlei Chen",
            "Kaiming He",
            "Yann LeCun",
            "Zhuang Liu"
          ]
        },
        {
          "title": "Forgotten Polygons: Multimodal Large Language Models are Shape-Blind",
          "year": 2025,
          "citations": 0,
          "abstract": "Despite strong performance on vision-language tasks, Multimodal Large Language Models (MLLMs) struggle with mathematical problem-solving, with both open-source and state-of-the-art models falling short of human performance on visual-math benchmarks. To systematically examine visual-mathematical reasoning in MLLMs, we (1) evaluate their understanding of geometric primitives, (2) test multi-step reasoning, and (3) explore a potential solution to improve visual reasoning capabilities. Our findings reveal fundamental shortcomings in shape recognition, with top models achieving under 50% accuracy in identifying regular polygons. We analyze these failures through the lens of dual-process theory and show that MLLMs rely on System 1 (intuitive, memorized associations) rather than System 2 (deliberate reasoning). Consequently, MLLMs fail to count the sides of both familiar and novel shapes, suggesting they have neither learned the concept of sides nor effectively process visual inputs. Finally, we propose Visually Cued Chain-of-Thought (VC-CoT) prompting, which enhances multi-step mathematical reasoning by explicitly referencing visual annotations in diagrams, boosting GPT-4o's accuracy on an irregular polygon side-counting task from 7% to 93%. Our findings suggest that System 2 reasoning in MLLMs remains an open problem, and visually-guided prompting is essential for successfully engaging visual reasoning. Code available at: https://github.com/rsinghlab/Shape-Blind.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2502.15969v4",
          "authors": [
            "William Rudman",
            "Michal Golovanevsky",
            "Amir Bar",
            "Vedant Palit",
            "Yann LeCun",
            "Carsten Eickhoff",
            "Ritambhara Singh"
          ]
        },
        {
          "title": "Learning from Reward-Free Offline Data: A Case for Planning with Latent Dynamics Models",
          "year": 2025,
          "citations": 0,
          "abstract": "A long-standing goal in AI is to develop agents capable of solving diverse tasks across a range of environments, including those never seen during training. Two dominant paradigms address this challenge: (i) reinforcement learning (RL), which learns policies via trial and error, and (ii) optimal control, which plans actions using a known or learned dynamics model. However, their comparative strengths in the offline setting - where agents must learn from reward-free trajectories - remain underexplored. In this work, we systematically evaluate RL and control-based methods on a suite of navigation tasks, using offline datasets of varying quality. On the RL side, we consider goal-conditioned and zero-shot methods. On the control side, we train a latent dynamics model using the Joint Embedding Predictive Architecture (JEPA) and employ it for planning. We investigate how factors such as data diversity, trajectory quality, and environment variability influence the performance of these approaches. Our results show that model-free RL benefits most from large amounts of high-quality data, whereas model-based planning generalizes better to unseen layouts and is more data-efficient, while achieving trajectory stitching performance comparable to leading model-free methods. Notably, planning with a latent dynamics model proves to be a strong approach for handling suboptimal offline data and adapting to diverse environments.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2502.14819v4",
          "authors": [
            "Vlad Sobal",
            "Wancong Zhang",
            "Kyunghyun Cho",
            "Randall Balestriero",
            "Tim G. J. Rudner",
            "Yann LeCun"
          ]
        },
        {
          "title": "Intuitive physics understanding emerges from self-supervised pretraining on natural videos",
          "year": 2025,
          "citations": 0,
          "abstract": "We investigate the emergence of intuitive physics understanding in general-purpose deep neural network models trained to predict masked regions in natural videos. Leveraging the violation-of-expectation framework, we find that video prediction models trained to predict outcomes in a learned representation space demonstrate an understanding of various intuitive physics properties, such as object permanence and shape consistency. In contrast, video prediction in pixel space and multimodal large language models, which reason through text, achieve performance closer to chance. Our comparisons of these architectures reveal that jointly learning an abstract representation space while predicting missing parts of sensory input, akin to predictive coding, is sufficient to acquire an understanding of intuitive physics, and that even models trained on one week of unique video achieve above chance performance. This challenges the idea that core knowledge -- a set of innate systems to help understand the world -- needs to be hardwired to develop an understanding of intuitive physics.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2502.11831v1",
          "authors": [
            "Quentin Garrido",
            "Nicolas Ballas",
            "Mahmoud Assran",
            "Adrien Bardes",
            "Laurent Najman",
            "Michael Rabbat",
            "Emmanuel Dupoux",
            "Yann LeCun"
          ]
        },
        {
          "title": "Layer by Layer: Uncovering Hidden Representations in Language Models",
          "year": 2025,
          "citations": 0,
          "abstract": "From extracting features to generating text, the outputs of large language models (LLMs) typically rely on the final layers, following the conventional wisdom that earlier layers capture only low-level cues. However, our analysis shows that intermediate layers can encode even richer representations, often improving performance on a range of downstream tasks. To explain and quantify these hidden-layer properties, we propose a unified framework of representation quality metrics based on information theory, geometry, and invariance to input perturbations. Our framework highlights how each layer balances information compression and signal preservation, revealing why mid-depth embeddings can exceed the last layer's performance. Through extensive experiments on 32 text-embedding tasks across various architectures (transformers, state-space models) and domains (language, vision), we demonstrate that intermediate layers consistently provide stronger features, challenging the standard view on final-layer embeddings and opening new directions on using mid-layer representations for more robust and accurate representations.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2502.02013v2",
          "authors": [
            "Oscar Skean",
            "Md Rifat Arefin",
            "Dan Zhao",
            "Niket Patel",
            "Jalal Naghiyev",
            "Yann LeCun",
            "Ravid Shwartz-Ziv"
          ]
        },
        {
          "title": "MetaMorph: Multimodal Understanding and Generation via Instruction Tuning",
          "year": 2024,
          "citations": 0,
          "abstract": "In this work, we propose Visual-Predictive Instruction Tuning (VPiT) - a simple and effective extension to visual instruction tuning that enables a pretrained LLM to quickly morph into an unified autoregressive model capable of generating both text and visual tokens. VPiT teaches an LLM to predict discrete text tokens and continuous visual tokens from any input sequence of image and text data curated in an instruction-following format. Our empirical investigation reveals several intriguing properties of VPiT: (1) visual generation ability emerges as a natural byproduct of improved visual understanding, and can be unlocked efficiently with a small amount of generation data; (2) while we find understanding and generation to be mutually beneficial, understanding data contributes to both capabilities more effectively than generation data. Building upon these findings, we train our MetaMorph model and achieve competitive performance on both visual understanding and generation. In visual generation, MetaMorph can leverage the world knowledge and reasoning abilities gained from LLM pretraining, and overcome common failure modes exhibited by other generation models. Our results suggest that LLMs may have strong \"prior\" vision capabilities that can be efficiently adapted to both visual understanding and generation with a relatively simple instruction tuning process.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2412.14164v1",
          "authors": [
            "Shengbang Tong",
            "David Fan",
            "Jiachen Zhu",
            "Yunyang Xiong",
            "Xinlei Chen",
            "Koustuv Sinha",
            "Michael Rabbat",
            "Yann LeCun",
            "Saining Xie",
            "Zhuang Liu"
          ]
        },
        {
          "title": "Video Representation Learning with Joint-Embedding Predictive Architectures",
          "year": 2024,
          "citations": 0,
          "abstract": "Video representation learning is an increasingly important topic in machine learning research. We present Video JEPA with Variance-Covariance Regularization (VJ-VCR): a joint-embedding predictive architecture for self-supervised video representation learning that employs variance and covariance regularization to avoid representation collapse. We show that hidden representations from our VJ-VCR contain abstract, high-level information about the input data. Specifically, they outperform representations obtained from a generative baseline on downstream tasks that require understanding of the underlying dynamics of moving objects in the videos. Additionally, we explore different ways to incorporate latent variables into the VJ-VCR framework that capture information about uncertainty in the future in non-deterministic settings.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2412.10925v1",
          "authors": [
            "Katrina Drozdov",
            "Ravid Shwartz-Ziv",
            "Yann LeCun"
          ]
        },
        {
          "title": "Does Representation Matter? Exploring Intermediate Layers in Large Language Models",
          "year": 2024,
          "citations": 0,
          "abstract": "Understanding what defines a good representation in large language models (LLMs) is fundamental to both theoretical understanding and practical applications. In this paper, we investigate the quality of intermediate representations in various LLM architectures, including Transformers and State Space Models (SSMs). We find that intermediate layers often yield more informative representations for downstream tasks than the final layers. To measure the representation quality, we adapt and apply a suite of metrics - such as prompt entropy, curvature, and augmentation-invariance - originally proposed in other contexts. Our empirical study reveals significant architectural differences, how representations evolve throughout training, and how factors like input randomness and prompt length affect each layer. Notably, we observe a bimodal pattern in the entropy of some intermediate layers and consider potential explanations tied to training data. Overall, our results illuminate the internal mechanics of LLMs and guide strategies for architectural optimization and training.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2412.09563v1",
          "authors": [
            "Oscar Skean",
            "Md Rifat Arefin",
            "Yann LeCun",
            "Ravid Shwartz-Ziv"
          ]
        },
        {
          "title": "Rate-In: Information-Driven Adaptive Dropout Rates for Improved Inference-Time Uncertainty Estimation",
          "year": 2024,
          "citations": 0,
          "abstract": "Accurate uncertainty estimation is crucial for deploying neural networks in risk-sensitive applications such as medical diagnosis. Monte Carlo Dropout is a widely used technique for approximating predictive uncertainty by performing stochastic forward passes with dropout during inference. However, using static dropout rates across all layers and inputs can lead to suboptimal uncertainty estimates, as it fails to adapt to the varying characteristics of individual inputs and network layers. Existing approaches optimize dropout rates during training using labeled data, resulting in fixed inference-time parameters that cannot adjust to new data distributions, compromising uncertainty estimates in Monte Carlo simulations.   In this paper, we propose Rate-In, an algorithm that dynamically adjusts dropout rates during inference by quantifying the information loss induced by dropout in each layer's feature maps. By treating dropout as controlled noise injection and leveraging information-theoretic principles, Rate-In adapts dropout rates per layer and per input instance without requiring ground truth labels. By quantifying the functional information loss in feature maps, we adaptively tune dropout rates to maintain perceptual quality across diverse medical imaging tasks and architectural configurations. Our extensive empirical study on synthetic data and real-world medical imaging tasks demonstrates that Rate-In improves calibration and sharpens uncertainty estimates compared to fixed or heuristic dropout rates without compromising predictive performance. Rate-In offers a practical, unsupervised, inference-time approach to optimizing dropout for more reliable predictive uncertainty estimation in critical applications.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2412.07169v4",
          "authors": [
            "Tal Zeevi",
            "Ravid Shwartz-Ziv",
            "Yann LeCun",
            "Lawrence H. Staib",
            "John A. Onofrey"
          ]
        },
        {
          "title": "Navigation World Models",
          "year": 2024,
          "citations": 0,
          "abstract": "Navigation is a fundamental skill of agents with visual-motor capabilities. We introduce a Navigation World Model (NWM), a controllable video generation model that predicts future visual observations based on past observations and navigation actions. To capture complex environment dynamics, NWM employs a Conditional Diffusion Transformer (CDiT), trained on a diverse collection of egocentric videos of both human and robotic agents, and scaled up to 1 billion parameters. In familiar environments, NWM can plan navigation trajectories by simulating them and evaluating whether they achieve the desired goal. Unlike supervised navigation policies with fixed behavior, NWM can dynamically incorporate constraints during planning. Experiments demonstrate its effectiveness in planning trajectories from scratch or by ranking trajectories sampled from an external policy. Furthermore, NWM leverages its learned visual priors to imagine trajectories in unfamiliar environments from a single input image, making it a flexible and powerful tool for next-generation navigation systems.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2412.03572v2",
          "authors": [
            "Amir Bar",
            "Gaoyue Zhou",
            "Danny Tran",
            "Trevor Darrell",
            "Yann LeCun"
          ]
        },
        {
          "title": "RoboPEPP: Vision-Based Robot Pose and Joint Angle Estimation through Embedding Predictive Pre-Training",
          "year": 2024,
          "citations": 0,
          "abstract": "Vision-based pose estimation of articulated robots with unknown joint angles has applications in collaborative robotics and human-robot interaction tasks. Current frameworks use neural network encoders to extract image features and downstream layers to predict joint angles and robot pose. While images of robots inherently contain rich information about the robot's physical structures, existing methods often fail to leverage it fully; therefore, limiting performance under occlusions and truncations. To address this, we introduce RoboPEPP, a method that fuses information about the robot's physical model into the encoder using a masking-based self-supervised embedding-predictive architecture. Specifically, we mask the robot's joints and pre-train an encoder-predictor model to infer the joints' embeddings from surrounding unmasked regions, enhancing the encoder's understanding of the robot's physical model. The pre-trained encoder-predictor pair, along with joint angle and keypoint prediction networks, is then fine-tuned for pose and joint angle estimation. Random masking of input during fine-tuning and keypoint filtering during evaluation further improves robustness. Our method, evaluated on several datasets, achieves the best results in robot pose and joint angle estimation while being the least sensitive to occlusions and requiring the lowest execution time.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2411.17662v2",
          "authors": [
            "Raktim Gautam Goswami",
            "Prashanth Krishnamurthy",
            "Yann LeCun",
            "Farshad Khorrami"
          ]
        },
        {
          "title": "Improving Pre-trained Self-Supervised Embeddings Through Effective Entropy Maximization",
          "year": 2024,
          "citations": 0,
          "abstract": "A number of different architectures and loss functions have been applied to the problem of self-supervised learning (SSL), with the goal of developing embeddings that provide the best possible pre-training for as-yet-unknown, lightly supervised downstream tasks. One of these SSL criteria is to maximize the entropy of a set of embeddings in some compact space. But the goal of maximizing the embedding entropy often depends -- whether explicitly or implicitly -- upon high dimensional entropy estimates, which typically perform poorly in more than a few dimensions. In this paper, we motivate an effective entropy maximization criterion (E2MC), defined in terms of easy-to-estimate, low-dimensional constraints. We demonstrate that using it to continue training an already-trained SSL model for only a handful of epochs leads to a consistent and, in some cases, significant improvement in downstream performance. We perform careful ablation studies to show that the improved performance is due to the proposed add-on criterion. We also show that continued pre-training with alternative criteria does not lead to notable improvements, and in some cases, even degrades performance.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2411.15931v2",
          "authors": [
            "Deep Chakraborty",
            "Yann LeCun",
            "Tim G. J. Rudner",
            "Erik Learned-Miller"
          ]
        },
        {
          "title": "DINO-WM: World Models on Pre-trained Visual Features enable Zero-shot Planning",
          "year": 2024,
          "citations": 0,
          "abstract": "The ability to predict future outcomes given control actions is fundamental for physical reasoning. However, such predictive models, often called world models, remains challenging to learn and are typically developed for task-specific solutions with online policy learning. To unlock world models' true potential, we argue that they should 1) be trainable on offline, pre-collected trajectories, 2) support test-time behavior optimization, and 3) facilitate task-agnostic reasoning. To this end, we present DINO World Model (DINO-WM), a new method to model visual dynamics without reconstructing the visual world. DINO-WM leverages spatial patch features pre-trained with DINOv2, enabling it to learn from offline behavioral trajectories by predicting future patch features. This allows DINO-WM to achieve observational goals through action sequence optimization, facilitating task-agnostic planning by treating goal features as prediction targets. We demonstrate that DINO-WM achieves zero-shot behavioral solutions at test time on six environments without expert demonstrations, reward modeling, or pre-learned inverse models, outperforming prior state-of-the-art work across diverse task families such as arbitrarily configured mazes, push manipulation with varied object shapes, and multi-particle scenarios.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2411.04983v2",
          "authors": [
            "Gaoyue Zhou",
            "Hengkai Pan",
            "Yann LeCun",
            "Lerrel Pinto"
          ]
        },
        {
          "title": "Seq-VCR: Preventing Collapse in Intermediate Transformer Representations for Enhanced Reasoning",
          "year": 2024,
          "citations": 0,
          "abstract": "Decoder-only Transformers often struggle with complex reasoning tasks, particularly arithmetic reasoning requiring multiple sequential operations. In this work, we identify representation collapse in the model's intermediate layers as a key factor limiting their reasoning capabilities. To address this, we propose Sequential Variance-Covariance Regularization (Seq-VCR), which enhances the entropy of intermediate representations and prevents collapse. Combined with dummy pause tokens as substitutes for chain-of-thought (CoT) tokens, our method significantly improves performance in arithmetic reasoning problems. In the challenging $5 \\times 5$ integer multiplication task, our approach achieves $99.5\\%$ exact match accuracy, outperforming models of the same size (which yield $0\\%$ accuracy) and GPT-4 with five-shot CoT prompting ($44\\%$). We also demonstrate superior results on arithmetic expression and longest increasing subsequence (LIS) datasets. Our findings highlight the importance of preventing intermediate layer representation collapse to enhance the reasoning capabilities of Transformers and show that Seq-VCR offers an effective solution without requiring explicit CoT supervision.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2411.02344v2",
          "authors": [
            "Md Rifat Arefin",
            "Gopeshh Subbaraj",
            "Nicolas Gontier",
            "Yann LeCun",
            "Irina Rish",
            "Ravid Shwartz-Ziv",
            "Christopher Pal"
          ]
        },
        {
          "title": "Multi-modal AI for comprehensive breast cancer prognostication",
          "year": 2024,
          "citations": 0,
          "abstract": "Treatment selection in breast cancer is guided by molecular subtypes and clinical characteristics. However, current tools including genomic assays lack the accuracy required for optimal clinical decision-making. We developed a novel artificial intelligence (AI)-based approach that integrates digital pathology images with clinical data, providing a more robust and effective method for predicting the risk of cancer recurrence in breast cancer patients. Specifically, we utilized a vision transformer pan-cancer foundation model trained with self-supervised learning to extract features from digitized H&E-stained slides. These features were integrated with clinical data to form a multi-modal AI test predicting cancer recurrence and death. The test was developed and evaluated using data from a total of 8,161 female breast cancer patients across 15 cohorts originating from seven countries. Of these, 3,502 patients from five cohorts were used exclusively for evaluation, while the remaining patients were used for training. Our test accurately predicted our primary endpoint, disease-free interval, in the five evaluation cohorts (C-index: 0.71 [0.68-0.75], HR: 3.63 [3.02-4.37, p<0.001]). In a direct comparison (n=858), the AI test was more accurate than Oncotype DX, the standard-of-care 21-gene assay, achieving a C-index of 0.67 [0.61-0.74] versus 0.61 [0.49-0.73], respectively. Additionally, the AI test added independent prognostic information to Oncotype DX in a multivariate analysis (HR: 3.11 [1.91-5.09, p<0.001)]). The test demonstrated robust accuracy across major molecular breast cancer subtypes, including TNBC (C-index: 0.71 [0.62-0.81], HR: 3.81 [2.35-6.17, p=0.02]), where no diagnostic tools are currently recommended by clinical guidelines. These results suggest that our AI test improves upon the accuracy of existing prognostic tests, while being applicable to a wider range of patients.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2410.21256v2",
          "authors": [
            "Jan Witowski",
            "Ken G. Zeng",
            "Joseph Cappadona",
            "Jailan Elayoubi",
            "Khalil Choucair",
            "Elena Diana Chiru",
            "Nancy Chan",
            "Young-Joon Kang",
            "Frederick Howard",
            "Irina Ostrovnaya",
            "Carlos Fernandez-Granda",
            "Freya Schnabel",
            "Zoe Steinsnyder",
            "Ugur Ozerdem",
            "Kangning Liu",
            "Waleed Abdulsattar",
            "Yu Zong",
            "Lina Daoud",
            "Rafic Beydoun",
            "Anas Saad",
            "Nitya Thakore",
            "Mohammad Sadic",
            "Frank Yeung",
            "Elisa Liu",
            "Theodore Hill",
            "Benjamin Swett",
            "Danielle Rigau",
            "Andrew Clayburn",
            "Valerie Speirs",
            "Marcus Vetter",
            "Lina Sojak",
            "Simone Soysal",
            "Daniel Baumhoer",
            "Jia-Wern Pan",
            "Haslina Makmur",
            "Soo-Hwang Teo",
            "Linda Ma Pak",
            "Victor Angel",
            "Dovile Zilenaite-Petrulaitiene",
            "Arvydas Laurinavicius",
            "Natalie Klar",
            "Brian D. Piening",
            "Carlo Bifulco",
            "Sun-Young Jun",
            "Jae Pak Yi",
            "Su Hyun Lim",
            "Adam Brufsky",
            "Francisco J. Esteva",
            "Lajos Pusztai",
            "Yann LeCun",
            "Krzysztof J. Geras"
          ]
        },
        {
          "title": "PooDLe: Pooled and dense self-supervised learning from naturalistic videos",
          "year": 2024,
          "citations": 0,
          "abstract": "Self-supervised learning has driven significant progress in learning from single-subject, iconic images. However, there are still unanswered questions about the use of minimally-curated, naturalistic video data, which contain dense scenes with many independent objects, imbalanced class distributions, and varying object sizes. In this paper, we propose PooDLe, a self-supervised learning method that combines an invariance-based objective on pooled representations with a dense SSL objective that enforces equivariance to optical flow warping. Our results show that a unified objective applied at multiple feature scales is essential for learning effective image representations from naturalistic videos. We validate our method with experiments on the BDD100K driving video dataset and the Walking Tours first-person video dataset, demonstrating its ability to capture spatial understanding from a dense objective and semantic understanding via a pooled representation objective.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2408.11208v3",
          "authors": [
            "Alex N. Wang",
            "Christopher Hoang",
            "Yuwen Xiong",
            "Yann LeCun",
            "Mengye Ren"
          ]
        },
        {
          "title": "$\\mathbb{X}$-Sample Contrastive Loss: Improving Contrastive Learning with Sample Similarity Graphs",
          "year": 2024,
          "citations": 0,
          "abstract": "Learning good representations involves capturing the diverse ways in which data samples relate. Contrastive loss - an objective matching related samples - underlies methods from self-supervised to multimodal learning. Contrastive losses, however, can be viewed more broadly as modifying a similarity graph to indicate how samples should relate in the embedding space. This view reveals a shortcoming in contrastive learning: the similarity graph is binary, as only one sample is the related positive sample. Crucially, similarities \\textit{across} samples are ignored. Based on this observation, we revise the standard contrastive loss to explicitly encode how a sample relates to others. We experiment with this new objective, called $\\mathbb{X}$-Sample Contrastive, to train vision models based on similarities in class or text caption descriptions. Our study spans three scales: ImageNet-1k with 1 million, CC3M with 3 million, and CC12M with 12 million samples. The representations learned via our objective outperform both contrastive self-supervised and vision-language models trained on the same data across a range of tasks. When training on CC12M, we outperform CLIP by $0.6\\%$ on both ImageNet and ImageNet Real. Our objective appears to work particularly well in lower-data regimes, with gains over CLIP of $16.8\\%$ on ImageNet and $18.1\\%$ on ImageNet Real when training with CC3M. Finally, our objective seems to encourage the model to learn representations that separate objects from their attributes and backgrounds, with gains of $3.3$-$5.6$\\% over CLIP on ImageNet9. We hope the proposed solution takes a small step towards developing richer learning objectives for understanding sample relations in foundation models.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2407.18134v2",
          "authors": [
            "Vlad Sobal",
            "Mark Ibrahim",
            "Randall Balestriero",
            "Vivien Cabannes",
            "Diane Bouchacourt",
            "Pietro Astolfi",
            "Kyunghyun Cho",
            "Yann LeCun"
          ]
        },
        {
          "title": "LiveBench: A Challenging, Contamination-Limited LLM Benchmark",
          "year": 2024,
          "citations": 0,
          "abstract": "Test set contamination, wherein test data from a benchmark ends up in a newer model's training set, is a well-documented obstacle for fair LLM evaluation and can quickly render benchmarks obsolete. To mitigate this, many recent benchmarks crowdsource new prompts and evaluations from human or LLM judges; however, these can introduce significant biases, and break down when scoring hard questions. In this work, we introduce a new benchmark for LLMs designed to be resistant to both test set contamination and the pitfalls of LLM judging and human crowdsourcing. We release LiveBench, the first benchmark that (1) contains frequently-updated questions from recent information sources, (2) scores answers automatically according to objective ground-truth values, and (3) contains a wide variety of challenging tasks, spanning math, coding, reasoning, language, instruction following, and data analysis. To achieve this, LiveBench contains questions that are based on recently-released math competitions, arXiv papers, news articles, and datasets, and it contains harder, contamination-limited versions of tasks from previous benchmarks such as Big-Bench Hard, AMPS, and IFEval. We evaluate many prominent closed-source models, as well as dozens of open-source models ranging from 0.5B to 405B in size. LiveBench is difficult, with top models achieving below 70% accuracy. We release all questions, code, and model answers. Questions are added and updated on a monthly basis, and we release new tasks and harder versions of tasks over time so that LiveBench can distinguish between the capabilities of LLMs as they improve in the future. We welcome community engagement and collaboration for expanding the benchmark tasks and models.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2406.19314v2",
          "authors": [
            "Colin White",
            "Samuel Dooley",
            "Manley Roberts",
            "Arka Pal",
            "Ben Feuer",
            "Siddhartha Jain",
            "Ravid Shwartz-Ziv",
            "Neel Jain",
            "Khalid Saifullah",
            "Sreemanti Dey",
            "Shubh-Agrawal",
            "Sandeep Singh Sandha",
            "Siddartha Naidu",
            "Chinmay Hegde",
            "Yann LeCun",
            "Tom Goldstein",
            "Willie Neiswanger",
            "Micah Goldblum"
          ]
        },
        {
          "title": "Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs",
          "year": 2024,
          "citations": 0,
          "abstract": "We introduce Cambrian-1, a family of multimodal LLMs (MLLMs) designed with a vision-centric approach. While stronger language models can enhance multimodal capabilities, the design choices for vision components are often insufficiently explored and disconnected from visual representation learning research. This gap hinders accurate sensory grounding in real-world scenarios. Our study uses LLMs and visual instruction tuning as an interface to evaluate various visual representations, offering new insights into different models and architectures -- self-supervised, strongly supervised, or combinations thereof -- based on experiments with over 20 vision encoders. We critically examine existing MLLM benchmarks, address the difficulties involved in consolidating and interpreting results from various tasks, and introduce a new vision-centric benchmark, CV-Bench. To further improve visual grounding, we propose the Spatial Vision Aggregator (SVA), a dynamic and spatially-aware connector that integrates high-resolution vision features with LLMs while reducing the number of tokens. Additionally, we discuss the curation of high-quality visual instruction-tuning data from publicly available sources, emphasizing the importance of data source balancing and distribution ratio. Collectively, Cambrian-1 not only achieves state-of-the-art performance but also serves as a comprehensive, open cookbook for instruction-tuned MLLMs. We provide model weights, code, supporting tools, datasets, and detailed instruction-tuning and evaluation recipes. We hope our release will inspire and accelerate advancements in multimodal systems and visual representation learning.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2406.16860v2",
          "authors": [
            "Shengbang Tong",
            "Ellis Brown",
            "Penghao Wu",
            "Sanghyun Woo",
            "Manoj Middepogu",
            "Sai Charitha Akula",
            "Jihan Yang",
            "Shusheng Yang",
            "Adithya Iyer",
            "Xichen Pan",
            "Ziteng Wang",
            "Rob Fergus",
            "Yann LeCun",
            "Saining Xie"
          ]
        },
        {
          "title": "Just How Flexible are Neural Networks in Practice?",
          "year": 2024,
          "citations": 0,
          "abstract": "It is widely believed that a neural network can fit a training set containing at least as many samples as it has parameters, underpinning notions of overparameterized and underparameterized models. In practice, however, we only find solutions accessible via our training procedure, including the optimizer and regularizers, limiting flexibility. Moreover, the exact parameterization of the function class, built into an architecture, shapes its loss surface and impacts the minima we find. In this work, we examine the ability of neural networks to fit data in practice. Our findings indicate that: (1) standard optimizers find minima where the model can only fit training sets with significantly fewer samples than it has parameters; (2) convolutional networks are more parameter-efficient than MLPs and ViTs, even on randomly labeled data; (3) while stochastic training is thought to have a regularizing effect, SGD actually finds minima that fit more training data than full-batch gradient descent; (4) the difference in capacity to fit correctly labeled and incorrectly labeled samples can be predictive of generalization; (5) ReLU activation functions result in finding minima that fit more data despite being designed to avoid vanishing and exploding gradients in deep architectures.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2406.11463v1",
          "authors": [
            "Ravid Shwartz-Ziv",
            "Micah Goldblum",
            "Arpit Bansal",
            "C. Bayan Bruss",
            "Yann LeCun",
            "Andrew Gordon Wilson"
          ]
        },
        {
          "title": "Towards an Improved Understanding and Utilization of Maximum Manifold Capacity Representations",
          "year": 2024,
          "citations": 0,
          "abstract": "Maximum Manifold Capacity Representations (MMCR) is a recent multi-view self-supervised learning (MVSSL) method that matches or surpasses other leading MVSSL methods. MMCR is intriguing because it does not fit neatly into any of the commonplace MVSSL lineages, instead originating from a statistical mechanical perspective on the linear separability of data manifolds. In this paper, we seek to improve our understanding and our utilization of MMCR. To better understand MMCR, we leverage tools from high dimensional probability to demonstrate that MMCR incentivizes alignment and uniformity of learned embeddings. We then leverage tools from information theory to show that such embeddings maximize a well-known lower bound on mutual information between views, thereby connecting the geometric perspective of MMCR to the information-theoretic perspective commonly discussed in MVSSL. To better utilize MMCR, we mathematically predict and experimentally confirm non-monotonic changes in the pretraining loss akin to double descent but with respect to atypical hyperparameters. We also discover compute scaling laws that enable predicting the pretraining loss as a function of gradients steps, batch size, embedding dimension and number of views. We then show that MMCR, originally applied to image data, is performant on multimodal image-text data. By more deeply understanding the theoretical and empirical behavior of MMCR, our work reveals insights on improving MVSSL methods.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2406.09366v1",
          "authors": [
            "Rylan Schaeffer",
            "Victor Lecomte",
            "Dhruv Bhandarkar Pai",
            "Andres Carranza",
            "Berivan Isik",
            "Alyssa Unell",
            "Mikail Khona",
            "Thomas Yerxa",
            "Yann LeCun",
            "SueYeon Chung",
            "Andrey Gromov",
            "Ravid Shwartz-Ziv",
            "Sanmi Koyejo"
          ]
        },
        {
          "title": "Hierarchical World Models as Visual Whole-Body Humanoid Controllers",
          "year": 2024,
          "citations": 0,
          "abstract": "Whole-body control for humanoids is challenging due to the high-dimensional nature of the problem, coupled with the inherent instability of a bipedal morphology. Learning from visual observations further exacerbates this difficulty. In this work, we explore highly data-driven approaches to visual whole-body humanoid control based on reinforcement learning, without any simplifying assumptions, reward design, or skill primitives. Specifically, we propose a hierarchical world model in which a high-level agent generates commands based on visual observations for a low-level agent to execute, both of which are trained with rewards. Our approach produces highly performant control policies in 8 tasks with a simulated 56-DoF humanoid, while synthesizing motions that are broadly preferred by humans.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2405.18418v3",
          "authors": [
            "Nicklas Hansen",
            "Jyothir S",
            "Vlad Sobal",
            "Yann LeCun",
            "Xiaolong Wang",
            "Hao Su"
          ]
        },
        {
          "title": "Towards a Framework for Openness in Foundation Models: Proceedings from the Columbia Convening on Openness in Artificial Intelligence",
          "year": 2024,
          "citations": 0,
          "abstract": "Over the past year, there has been a robust debate about the benefits and risks of open sourcing foundation models. However, this discussion has often taken place at a high level of generality or with a narrow focus on specific technical attributes. In part, this is because defining open source for foundation models has proven tricky, given its significant differences from traditional software development. In order to inform more practical and nuanced decisions about opening AI systems, including foundation models, this paper presents a framework for grappling with openness across the AI stack. It summarizes previous work on this topic, analyzes the various potential reasons to pursue openness, and outlines how openness varies in different parts of the AI stack, both at the model and at the system level. In doing so, its authors hope to provide a common descriptive framework to deepen a nuanced and rigorous understanding of openness in AI and enable further work around definitions of openness and safety in AI.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2405.15802v1",
          "authors": [
            "Adrien Basdevant",
            "Camille François",
            "Victor Storchan",
            "Kevin Bankston",
            "Ayah Bdeir",
            "Brian Behlendorf",
            "Merouane Debbah",
            "Sayash Kapoor",
            "Yann LeCun",
            "Mark Surman",
            "Helen King-Turvey",
            "Nathan Lambert",
            "Stefano Maffulli",
            "Nik Marda",
            "Govind Shivkumar",
            "Justine Tunney"
          ]
        },
        {
          "title": "Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning",
          "year": 2024,
          "citations": 0,
          "abstract": "Large vision-language models (VLMs) fine-tuned on specialized visual instruction-following data have exhibited impressive language reasoning capabilities across various scenarios. However, this fine-tuning paradigm may not be able to efficiently learn optimal decision-making agents in multi-step goal-directed tasks from interactive environments. To address this challenge, we propose an algorithmic framework that fine-tunes VLMs with reinforcement learning (RL). Specifically, our framework provides a task description and then prompts the VLM to generate chain-of-thought (CoT) reasoning, enabling the VLM to efficiently explore intermediate reasoning steps that lead to the final text-based action. Next, the open-ended text output is parsed into an executable action to interact with the environment to obtain goal-directed task rewards. Finally, our framework uses these task rewards to fine-tune the entire VLM with RL. Empirically, we demonstrate that our proposed framework enhances the decision-making capabilities of VLM agents across various tasks, enabling 7b models to outperform commercial models such as GPT4-V or Gemini. Furthermore, we find that CoT reasoning is a crucial component for performance improvement, as removing the CoT reasoning results in a significant decrease in the overall performance of our method.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2405.10292v3",
          "authors": [
            "Yuexiang Zhai",
            "Hao Bai",
            "Zipeng Lin",
            "Jiayi Pan",
            "Shengbang Tong",
            "Yifei Zhou",
            "Alane Suhr",
            "Saining Xie",
            "Yann LeCun",
            "Yi Ma",
            "Sergey Levine"
          ]
        },
        {
          "title": "The Entropy Enigma: Success and Failure of Entropy Minimization",
          "year": 2024,
          "citations": 0,
          "abstract": "Entropy minimization (EM) is frequently used to increase the accuracy of classification models when they're faced with new data at test time. EM is a self-supervised learning method that optimizes classifiers to assign even higher probabilities to their top predicted classes. In this paper, we analyze why EM works when adapting a model for a few steps and why it eventually fails after adapting for many steps. We show that, at first, EM causes the model to embed test images close to training images, thereby increasing model accuracy. After many steps of optimization, EM makes the model embed test images far away from the embeddings of training images, which results in a degradation of accuracy. Building upon our insights, we present a method for solving a practical problem: estimating a model's accuracy on a given arbitrary dataset without having access to its labels. Our method estimates accuracy by looking at how the embeddings of input images change as the model is optimized to minimize entropy. Experiments on 23 challenging datasets show that our method sets the SoTA with a mean absolute error of $5.75\\%$, an improvement of $29.62\\%$ over the previous SoTA on this task. Our code is available at https://github.com/oripress/EntropyEnigma",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2405.05012v2",
          "authors": [
            "Ori Press",
            "Ravid Shwartz-Ziv",
            "Yann LeCun",
            "Matthias Bethge"
          ]
        },
        {
          "title": "Advancing human-centric AI for robust X-ray analysis through holistic self-supervised learning",
          "year": 2024,
          "citations": 0,
          "abstract": "AI Foundation models are gaining traction in various applications, including medical fields like radiology. However, medical foundation models are often tested on limited tasks, leaving their generalisability and biases unexplored. We present RayDINO, a large visual encoder trained by self-supervision on 873k chest X-rays. We compare RayDINO to previous state-of-the-art models across nine radiology tasks, from classification and dense segmentation to text generation, and provide an in depth analysis of population, age and sex biases of our model. Our findings suggest that self-supervision allows patient-centric AI proving useful in clinical workflows and interpreting X-rays holistically. With RayDINO and small task-specific adapters, we reach state-of-the-art results and improve generalization to unseen populations while mitigating bias, illustrating the true promise of foundation models: versatility and robustness.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2405.01469v1",
          "authors": [
            "Théo Moutakanni",
            "Piotr Bojanowski",
            "Guillaume Chassagnon",
            "Céline Hudelot",
            "Armand Joulin",
            "Yann LeCun",
            "Matthew Muckley",
            "Maxime Oquab",
            "Marie-Pierre Revel",
            "Maria Vakalopoulou"
          ]
        },
        {
          "title": "EgoPet: Egomotion and Interaction Data from an Animal's Perspective",
          "year": 2024,
          "citations": 0,
          "abstract": "Animals perceive the world to plan their actions and interact with other agents to accomplish complex tasks, demonstrating capabilities that are still unmatched by AI systems. To advance our understanding and reduce the gap between the capabilities of animals and AI systems, we introduce a dataset of pet egomotion imagery with diverse examples of simultaneous egomotion and multi-agent interaction. Current video datasets separately contain egomotion and interaction examples, but rarely both at the same time. In addition, EgoPet offers a radically distinct perspective from existing egocentric datasets of humans or vehicles. We define two in-domain benchmark tasks that capture animal behavior, and a third benchmark to assess the utility of EgoPet as a pretraining resource to robotic quadruped locomotion, showing that models trained from EgoPet outperform those trained from prior datasets.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2404.09991v1",
          "authors": [
            "Amir Bar",
            "Arya Bakhtiar",
            "Danny Tran",
            "Antonio Loquercio",
            "Jathushan Rajasegaran",
            "Yann LeCun",
            "Amir Globerson",
            "Trevor Darrell"
          ]
        },
        {
          "title": "Learning and Leveraging World Models in Visual Representation Learning",
          "year": 2024,
          "citations": 0,
          "abstract": "Joint-Embedding Predictive Architecture (JEPA) has emerged as a promising self-supervised approach that learns by leveraging a world model. While previously limited to predicting missing parts of an input, we explore how to generalize the JEPA prediction task to a broader set of corruptions. We introduce Image World Models, an approach that goes beyond masked image modeling and learns to predict the effect of global photometric transformations in latent space. We study the recipe of learning performant IWMs and show that it relies on three key aspects: conditioning, prediction difficulty, and capacity. Additionally, we show that the predictive world model learned by IWM can be adapted through finetuning to solve diverse tasks; a fine-tuned IWM world model matches or surpasses the performance of previous self-supervised methods. Finally, we show that learning with an IWM allows one to control the abstraction level of the learned representations, learning invariant representations such as contrastive methods, or equivariant representations such as masked image modelling.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2403.00504v1",
          "authors": [
            "Quentin Garrido",
            "Mahmoud Assran",
            "Nicolas Ballas",
            "Adrien Bardes",
            "Laurent Najman",
            "Yann LeCun"
          ]
        },
        {
          "title": "Learning by Reconstruction Produces Uninformative Features For Perception",
          "year": 2024,
          "citations": 0,
          "abstract": "Input space reconstruction is an attractive representation learning paradigm. Despite interpretability of the reconstruction and generation, we identify a misalignment between learning by reconstruction, and learning for perception. We show that the former allocates a model's capacity towards a subspace of the data explaining the observed variance--a subspace with uninformative features for the latter. For example, the supervised TinyImagenet task with images projected onto the top subspace explaining 90\\% of the pixel variance can be solved with 45\\% test accuracy. Using the bottom subspace instead, accounting for only 20\\% of the pixel variance, reaches 55\\% test accuracy. The features for perception being learned last explains the need for long training time, e.g., with Masked Autoencoders. Learning by denoising is a popular strategy to alleviate that misalignment. We prove that while some noise strategies such as masking are indeed beneficial, others such as additive Gaussian noise are not. Yet, even in the case of masking, we find that the benefits vary as a function of the mask's shape, ratio, and the considered dataset. While tuning the noise strategy without knowledge of the perception task seems challenging, we provide first clues on how to detect if a noise strategy is never beneficial regardless of the perception task.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2402.11337v1",
          "authors": [
            "Randall Balestriero",
            "Yann LeCun"
          ]
        },
        {
          "title": "Revisiting Feature Prediction for Learning Visual Representations from Video",
          "year": 2024,
          "citations": 0,
          "abstract": "This paper explores feature prediction as a stand-alone objective for unsupervised learning from video and introduces V-JEPA, a collection of vision models trained solely using a feature prediction objective, without the use of pretrained image encoders, text, negative examples, reconstruction, or other sources of supervision. The models are trained on 2 million videos collected from public datasets and are evaluated on downstream image and video tasks. Our results show that learning by predicting video features leads to versatile visual representations that perform well on both motion and appearance-based tasks, without adaption of the model's parameters; e.g., using a frozen backbone. Our largest model, a ViT-H/16 trained only on videos, obtains 81.9% on Kinetics-400, 72.2% on Something-Something-v2, and 77.9% on ImageNet1K.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2404.08471v1",
          "authors": [
            "Adrien Bardes",
            "Quentin Garrido",
            "Jean Ponce",
            "Xinlei Chen",
            "Michael Rabbat",
            "Yann LeCun",
            "Mahmoud Assran",
            "Nicolas Ballas"
          ]
        },
        {
          "title": "G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering",
          "year": 2024,
          "citations": 0,
          "abstract": "Given a graph with textual attributes, we enable users to `chat with their graph': that is, to ask questions about the graph using a conversational interface. In response to a user's questions, our method provides textual replies and highlights the relevant parts of the graph. While existing works integrate large language models (LLMs) and graph neural networks (GNNs) in various ways, they mostly focus on either conventional graph tasks (such as node, edge, and graph classification), or on answering simple graph queries on small or synthetic graphs. In contrast, we develop a flexible question-answering framework targeting real-world textual graphs, applicable to multiple applications including scene graph understanding, common sense reasoning, and knowledge graph reasoning. Toward this goal, we first develop a Graph Question Answering (GraphQA) benchmark with data collected from different tasks. Then, we propose our G-Retriever method, introducing the first retrieval-augmented generation (RAG) approach for general textual graphs, which can be fine-tuned to enhance graph understanding via soft prompting. To resist hallucination and to allow for textual graphs that greatly exceed the LLM's context window size, G-Retriever performs RAG over a graph by formulating this task as a Prize-Collecting Steiner Tree optimization problem. Empirical evaluations show that our method outperforms baselines on textual graph tasks from multiple domains, scales well with larger graph sizes, and mitigates hallucination.~\\footnote{Our codes and datasets are available at: \\url{https://github.com/XiaoxinHe/G-Retriever}}",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2402.07630v3",
          "authors": [
            "Xiaoxin He",
            "Yijun Tian",
            "Yifei Sun",
            "Nitesh V. Chawla",
            "Thomas Laurent",
            "Yann LeCun",
            "Xavier Bresson",
            "Bryan Hooi"
          ]
        },
        {
          "title": "Fast and Exact Enumeration of Deep Networks Partitions Regions",
          "year": 2024,
          "citations": 0,
          "abstract": "One fruitful formulation of Deep Networks (DNs) enabling their theoretical study and providing practical guidelines to practitioners relies on Piecewise Affine Splines. In that realm, a DN's input-mapping is expressed as per-region affine mapping where those regions are implicitly determined by the model's architecture and form a partition of their input space. That partition -- which is involved in all the results spanned from this line of research -- has so far only been computed on $2/3$-dimensional slices of the DN's input space or estimated by random sampling. In this paper, we provide the first parallel algorithm that does exact enumeration of the DN's partition regions. The proposed algorithm enables one to finally assess the closeness of the commonly employed approximations methods, e.g. based on random sampling of the DN input space. One of our key finding is that if one is only interested in regions with ``large'' volume, then uniform sampling of the space is highly efficient, but that if one is also interested in discovering the ``small'' regions of the partition, then uniform sampling is exponentially costly with the DN's input space dimension. On the other hand, our proposed method has complexity scaling linearly with input dimension and the number of regions.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2401.11188v1",
          "authors": [
            "Randall Balestriero",
            "Yann LeCun"
          ]
        },
        {
          "title": "Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs",
          "year": 2024,
          "citations": 0,
          "abstract": "Is vision good enough for language? Recent advancements in multimodal models primarily stem from the powerful reasoning abilities of large language models (LLMs). However, the visual component typically depends only on the instance-level contrastive language-image pre-training (CLIP). Our research reveals that the visual capabilities in recent multimodal LLMs (MLLMs) still exhibit systematic shortcomings. To understand the roots of these errors, we explore the gap between the visual embedding space of CLIP and vision-only self-supervised learning. We identify ''CLIP-blind pairs'' - images that CLIP perceives as similar despite their clear visual differences. With these pairs, we construct the Multimodal Visual Patterns (MMVP) benchmark. MMVP exposes areas where state-of-the-art systems, including GPT-4V, struggle with straightforward questions across nine basic visual patterns, often providing incorrect answers and hallucinated explanations. We further evaluate various CLIP-based vision-and-language models and found a notable correlation between visual patterns that challenge CLIP models and those problematic for multimodal LLMs. As an initial effort to address these issues, we propose a Mixture of Features (MoF) approach, demonstrating that integrating vision self-supervised learning features with MLLMs can significantly enhance their visual grounding capabilities. Together, our research suggests visual representation learning remains an open challenge, and accurate visual grounding is crucial for future successful multimodal systems.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2401.06209v2",
          "authors": [
            "Shengbang Tong",
            "Zhuang Liu",
            "Yuexiang Zhai",
            "Yi Ma",
            "Yann LeCun",
            "Saining Xie"
          ]
        },
        {
          "title": "Gradient-based Planning with World Models",
          "year": 2023,
          "citations": 0,
          "abstract": "The enduring challenge in the field of artificial intelligence has been the control of systems to achieve desired behaviours. While for systems governed by straightforward dynamics equations, methods like Linear Quadratic Regulation (LQR) have historically proven highly effective, most real-world tasks, which require a general problem-solver, demand world models with dynamics that cannot be easily described by simple equations. Consequently, these models must be learned from data using neural networks. Most model predictive control (MPC) algorithms designed for visual world models have traditionally explored gradient-free population-based optimisation methods, such as Cross Entropy and Model Predictive Path Integral (MPPI) for planning. However, we present an exploration of a gradient-based alternative that fully leverages the differentiability of the world model. In our study, we conduct a comparative analysis between our method and other MPC-based alternatives, as well as policy-based algorithms. In a sample-efficient setting, our method achieves on par or superior performance compared to the alternative approaches in most tasks. Additionally, we introduce a hybrid model that combines policy networks and gradient-based MPC, which outperforms pure policy based methods thereby holding promise for Gradient-based planning with world models in complex real-world tasks.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2312.17227v1",
          "authors": [
            "Jyothir S",
            "Siddhartha Jalagam",
            "Yann LeCun",
            "Vlad Sobal"
          ]
        },
        {
          "title": "GAIA: a benchmark for General AI Assistants",
          "year": 2023,
          "citations": 0,
          "abstract": "We introduce GAIA, a benchmark for General AI Assistants that, if solved, would represent a milestone in AI research. GAIA proposes real-world questions that require a set of fundamental abilities such as reasoning, multi-modality handling, web browsing, and generally tool-use proficiency. GAIA questions are conceptually simple for humans yet challenging for most advanced AIs: we show that human respondents obtain 92\\% vs. 15\\% for GPT-4 equipped with plugins. This notable performance disparity contrasts with the recent trend of LLMs outperforming humans on tasks requiring professional skills in e.g. law or chemistry. GAIA's philosophy departs from the current trend in AI benchmarks suggesting to target tasks that are ever more difficult for humans. We posit that the advent of Artificial General Intelligence (AGI) hinges on a system's capability to exhibit similar robustness as the average human does on such questions. Using GAIA's methodology, we devise 466 questions and their answer. We release our questions while retaining answers to 300 of them to power a leader-board available at https://huggingface.co/gaia-benchmark.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2311.12983v1",
          "authors": [
            "Grégoire Mialon",
            "Clémentine Fourrier",
            "Craig Swift",
            "Thomas Wolf",
            "Yann LeCun",
            "Thomas Scialom"
          ]
        },
        {
          "title": "URLOST: Unsupervised Representation Learning without Stationarity or Topology",
          "year": 2023,
          "citations": 0,
          "abstract": "Unsupervised representation learning has seen tremendous progress. However, it is constrained by its reliance on domain specific stationarity and topology, a limitation not found in biological intelligence systems. For instance, unlike computer vision, human vision can process visual signals sampled from highly irregular and non-stationary sensors. We introduce a novel framework that learns from high-dimensional data without prior knowledge of stationarity and topology. Our model, abbreviated as URLOST, combines a learnable self-organizing layer, spectral clustering, and a masked autoencoder (MAE). We evaluate its effectiveness on three diverse data modalities including simulated biological vision data, neural recordings from the primary visual cortex, and gene expressions. Compared to state-of-the-art unsupervised learning methods like SimCLR and MAE, our model excels at learning meaningful representations across diverse modalities without knowing their stationarity or topology. It also outperforms other methods that are not dependent on these factors, setting a new benchmark in the field. We position this work as a step toward unsupervised learning methods capable of generalizing across diverse high-dimensional data modalities.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2310.04496v2",
          "authors": [
            "Zeyu Yun",
            "Juexiao Zhang",
            "Yann LeCun",
            "Yubei Chen"
          ]
        },
        {
          "title": "Stochastic positional embeddings improve masked image modeling",
          "year": 2023,
          "citations": 0,
          "abstract": "Masked Image Modeling (MIM) is a promising self-supervised learning approach that enables learning from unlabeled images. Despite its recent success, learning good representations through MIM remains challenging because it requires predicting the right semantic content in accurate locations. For example, given an incomplete picture of a dog, we can guess that there is a tail, but we cannot determine its exact location. In this work, we propose to incorporate location uncertainty into MIM by using stochastic positional embeddings (StoP). Specifically, we condition the model on stochastic masked token positions drawn from a Gaussian distribution. StoP reduces overfitting to location features and guides the model toward learning features that are more robust to location uncertainties. Quantitatively, StoP improves downstream MIM performance on a variety of downstream tasks, including $+1.7\\%$ on ImageNet linear probing using ViT-B, and $+2.5\\%$ for ViT-H using $1\\%$ of the data.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2308.00566v2",
          "authors": [
            "Amir Bar",
            "Florian Bordes",
            "Assaf Shocher",
            "Mahmoud Assran",
            "Pascal Vincent",
            "Nicolas Ballas",
            "Trevor Darrell",
            "Amir Globerson",
            "Yann LeCun"
          ]
        },
        {
          "title": "MC-JEPA: A Joint-Embedding Predictive Architecture for Self-Supervised Learning of Motion and Content Features",
          "year": 2023,
          "citations": 0,
          "abstract": "Self-supervised learning of visual representations has been focusing on learning content features, which do not capture object motion or location, and focus on identifying and differentiating objects in images and videos. On the other hand, optical flow estimation is a task that does not involve understanding the content of the images on which it is estimated. We unify the two approaches and introduce MC-JEPA, a joint-embedding predictive architecture and self-supervised learning approach to jointly learn optical flow and content features within a shared encoder, demonstrating that the two associated objectives; the optical flow estimation objective and the self-supervised learning objective; benefit from each other and thus learn content features that incorporate motion information. The proposed approach achieves performance on-par with existing unsupervised optical flow benchmarks, as well as with common self-supervised learning approaches on downstream tasks such as semantic segmentation of images and videos.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2307.12698v1",
          "authors": [
            "Adrien Bardes",
            "Jean Ponce",
            "Yann LeCun"
          ]
        },
        {
          "title": "Self-Supervised Learning with Lie Symmetries for Partial Differential Equations",
          "year": 2023,
          "citations": 0,
          "abstract": "Machine learning for differential equations paves the way for computationally efficient alternatives to numerical solvers, with potentially broad impacts in science and engineering. Though current algorithms typically require simulated training data tailored to a given setting, one may instead wish to learn useful information from heterogeneous sources, or from real dynamical systems observations that are messy or incomplete. In this work, we learn general-purpose representations of PDEs from heterogeneous data by implementing joint embedding methods for self-supervised learning (SSL), a framework for unsupervised representation learning that has had notable success in computer vision. Our representation outperforms baseline approaches to invariant tasks, such as regressing the coefficients of a PDE, while also improving the time-stepping performance of neural solvers. We hope that our proposed methodology will prove useful in the eventual development of general-purpose foundation models for PDEs. Code: https://github.com/facebookresearch/SSLForPDEs.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2307.05432v2",
          "authors": [
            "Grégoire Mialon",
            "Quentin Garrido",
            "Hannah Lawrence",
            "Danyal Rehman",
            "Yann LeCun",
            "Bobak T. Kiani"
          ]
        },
        {
          "title": "Variance-Covariance Regularization Improves Representation Learning",
          "year": 2023,
          "citations": 0,
          "abstract": "Transfer learning plays a key role in advancing machine learning models, yet conventional supervised pretraining often undermines feature transferability by prioritizing features that minimize the pretraining loss. In this work, we adapt a self-supervised learning regularization technique from the VICReg method to supervised learning contexts, introducing Variance-Covariance Regularization (VCReg). This adaptation encourages the network to learn high-variance, low-covariance representations, promoting learning more diverse features. We outline best practices for an efficient implementation of our framework, including applying it to the intermediate representations. Through extensive empirical evaluation, we demonstrate that our method significantly enhances transfer learning for images and videos, achieving state-of-the-art performance across numerous tasks and datasets. VCReg also improves performance in scenarios like long-tail learning and hierarchical classification. Additionally, we show its effectiveness may stem from its success in addressing challenges like gradient starvation and neural collapse. In summary, VCReg offers a universally applicable regularization framework that significantly advances transfer learning and highlights the connection between gradient starvation, neural collapse, and feature transferability.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2306.13292v2",
          "authors": [
            "Jiachen Zhu",
            "Katrina Evtimova",
            "Yubei Chen",
            "Ravid Shwartz-Ziv",
            "Yann LeCun"
          ]
        },
        {
          "title": "Introduction to Latent Variable Energy-Based Models: A Path Towards Autonomous Machine Intelligence",
          "year": 2023,
          "citations": 0,
          "abstract": "Current automated systems have crucial limitations that need to be addressed before artificial intelligence can reach human-like levels and bring new technological revolutions. Among others, our societies still lack Level 5 self-driving cars, domestic robots, and virtual assistants that learn reliable world models, reason, and plan complex action sequences. In these notes, we summarize the main ideas behind the architecture of autonomous intelligence of the future proposed by Yann LeCun. In particular, we introduce energy-based and latent variable models and combine their advantages in the building block of LeCun's proposal, that is, in the hierarchical joint embedding predictive architecture (H-JEPA).",
          "venue": null,
          "doi": "10.1088/1742-5468/ad292b",
          "url": "https://arxiv.org/abs/2306.02572v1",
          "authors": [
            "Anna Dawid",
            "Yann LeCun"
          ]
        },
        {
          "title": "Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning",
          "year": 2023,
          "citations": 0,
          "abstract": "Representation learning on text-attributed graphs (TAGs) has become a critical research problem in recent years. A typical example of a TAG is a paper citation graph, where the text of each paper serves as node attributes. Initial graph neural network (GNN) pipelines handled these text attributes by transforming them into shallow or hand-crafted features, such as skip-gram or bag-of-words features. Recent efforts have focused on enhancing these pipelines with language models (LMs), which typically demand intricate designs and substantial computational resources. With the advent of powerful large language models (LLMs) such as GPT or Llama2, which demonstrate an ability to reason and to utilize general knowledge, there is a growing need for techniques which combine the textual modelling abilities of LLMs with the structural learning capabilities of GNNs. Hence, in this work, we focus on leveraging LLMs to capture textual information as features, which can be used to boost GNN performance on downstream tasks. A key innovation is our use of explanations as features: we prompt an LLM to perform zero-shot classification, request textual explanations for its decision-making process, and design an LLM-to-LM interpreter to translate these explanations into informative features for downstream GNNs. Our experiments demonstrate that our method achieves state-of-the-art results on well-established TAG datasets, including Cora, PubMed, ogbn-arxiv, as well as our newly introduced dataset, tape-arxiv23. Furthermore, our method significantly speeds up training, achieving a 2.88 times improvement over the closest baseline on ogbn-arxiv. Lastly, we believe the versatility of the proposed method extends beyond TAGs and holds the potential to enhance other tasks involving graph-text data. Our codes and datasets are available at: https://github.com/XiaoxinHe/TAPE.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2305.19523v5",
          "authors": [
            "Xiaoxin He",
            "Xavier Bresson",
            "Thomas Laurent",
            "Adam Perold",
            "Yann LeCun",
            "Bryan Hooi"
          ]
        },
        {
          "title": "Reverse Engineering Self-Supervised Learning",
          "year": 2023,
          "citations": 0,
          "abstract": "Self-supervised learning (SSL) is a powerful tool in machine learning, but understanding the learned representations and their underlying mechanisms remains a challenge. This paper presents an in-depth empirical analysis of SSL-trained representations, encompassing diverse models, architectures, and hyperparameters. Our study reveals an intriguing aspect of the SSL training process: it inherently facilitates the clustering of samples with respect to semantic labels, which is surprisingly driven by the SSL objective's regularization term. This clustering process not only enhances downstream classification but also compresses the data information. Furthermore, we establish that SSL-trained representations align more closely with semantic classes rather than random classes. Remarkably, we show that learned representations align with semantic classes across various hierarchical levels, and this alignment increases during training and when moving deeper into the network. Our findings provide valuable insights into SSL's representation learning mechanisms and their impact on performance across different sets of classes.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2305.15614v2",
          "authors": [
            "Ido Ben-Shaul",
            "Ravid Shwartz-Ziv",
            "Tomer Galanti",
            "Shai Dekel",
            "Yann LeCun"
          ]
        },
        {
          "title": "A Cookbook of Self-Supervised Learning",
          "year": 2023,
          "citations": 0,
          "abstract": "Self-supervised learning, dubbed the dark matter of intelligence, is a promising path to advance machine learning. Yet, much like cooking, training SSL methods is a delicate art with a high barrier to entry. While many components are familiar, successfully training a SSL method involves a dizzying set of choices from the pretext tasks to training hyper-parameters. Our goal is to lower the barrier to entry into SSL research by laying the foundations and latest SSL recipes in the style of a cookbook. We hope to empower the curious researcher to navigate the terrain of methods, understand the role of the various knobs, and gain the know-how required to explore how delicious SSL can be.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2304.12210v2",
          "authors": [
            "Randall Balestriero",
            "Mark Ibrahim",
            "Vlad Sobal",
            "Ari Morcos",
            "Shashank Shekhar",
            "Tom Goldstein",
            "Florian Bordes",
            "Adrien Bardes",
            "Gregoire Mialon",
            "Yuandong Tian",
            "Avi Schwarzschild",
            "Andrew Gordon Wilson",
            "Jonas Geiping",
            "Quentin Garrido",
            "Pierre Fernandez",
            "Amir Bar",
            "Hamed Pirsiavash",
            "Yann LeCun",
            "Micah Goldblum"
          ]
        },
        {
          "title": "To Compress or Not to Compress- Self-Supervised Learning and Information Theory: A Review",
          "year": 2023,
          "citations": 0,
          "abstract": "Deep neural networks excel in supervised learning tasks but are constrained by the need for extensive labeled data. Self-supervised learning emerges as a promising alternative, allowing models to learn without explicit labels. Information theory, and notably the information bottleneck principle, has been pivotal in shaping deep neural networks. This principle focuses on optimizing the trade-off between compression and preserving relevant information, providing a foundation for efficient network design in supervised contexts. However, its precise role and adaptation in self-supervised learning remain unclear. In this work, we scrutinize various self-supervised learning approaches from an information-theoretic perspective, introducing a unified framework that encapsulates the \\textit{self-supervised information-theoretic learning problem}. We weave together existing research into a cohesive narrative, delve into contemporary self-supervised methodologies, and spotlight potential research avenues and inherent challenges. Additionally, we discuss the empirical evaluation of information-theoretic quantities and their estimation methods. Overall, this paper furnishes an exhaustive review of the intersection of information theory, self-supervised learning, and deep neural networks.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2304.09355v5",
          "authors": [
            "Ravid Shwartz-Ziv",
            "Yann LeCun"
          ]
        },
        {
          "title": "EMP-SSL: Towards Self-Supervised Learning in One Training Epoch",
          "year": 2023,
          "citations": 0,
          "abstract": "Recently, self-supervised learning (SSL) has achieved tremendous success in learning image representation. Despite the empirical success, most self-supervised learning methods are rather \"inefficient\" learners, typically taking hundreds of training epochs to fully converge. In this work, we show that the key towards efficient self-supervised learning is to increase the number of crops from each image instance. Leveraging one of the state-of-the-art SSL method, we introduce a simplistic form of self-supervised learning method called Extreme-Multi-Patch Self-Supervised-Learning (EMP-SSL) that does not rely on many heuristic techniques for SSL such as weight sharing between the branches, feature-wise normalization, output quantization, and stop gradient, etc, and reduces the training epochs by two orders of magnitude. We show that the proposed method is able to converge to 85.1% on CIFAR-10, 58.5% on CIFAR-100, 38.1% on Tiny ImageNet and 58.5% on ImageNet-100 in just one epoch. Furthermore, the proposed method achieves 91.5% on CIFAR-10, 70.1% on CIFAR-100, 51.5% on Tiny ImageNet and 78.9% on ImageNet-100 with linear probing in less than ten training epochs. In addition, we show that EMP-SSL shows significantly better transferability to out-of-domain datasets compared to baseline SSL methods. We will release the code in https://github.com/tsb0601/EMP-SSL.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2304.03977v1",
          "authors": [
            "Shengbang Tong",
            "Yubei Chen",
            "Yi Ma",
            "Yann Lecun"
          ]
        },
        {
          "title": "Active Self-Supervised Learning: A Few Low-Cost Relationships Are All You Need",
          "year": 2023,
          "citations": 0,
          "abstract": "Self-Supervised Learning (SSL) has emerged as the solution of choice to learn transferable representations from unlabeled data. However, SSL requires to build samples that are known to be semantically akin, i.e. positive views. Requiring such knowledge is the main limitation of SSL and is often tackled by ad-hoc strategies e.g. applying known data-augmentations to the same input. In this work, we formalize and generalize this principle through Positive Active Learning (PAL) where an oracle queries semantic relationships between samples. PAL achieves three main objectives. First, it unveils a theoretically grounded learning framework beyond SSL, based on similarity graphs, that can be extended to tackle supervised and semi-supervised learning depending on the employed oracle. Second, it provides a consistent algorithm to embed a priori knowledge, e.g. some observed labels, into any SSL losses without any change in the training pipeline. Third, it provides a proper active learning framework yielding low-cost solutions to annotate datasets, arguably bringing the gap between theory and practice of active learning that is based on simple-to-answer-by-non-experts queries of semantic relationships between inputs.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2303.15256v2",
          "authors": [
            "Vivien Cabannes",
            "Leon Bottou",
            "Yann Lecun",
            "Randall Balestriero"
          ]
        },
        {
          "title": "An Information-Theoretic Perspective on Variance-Invariance-Covariance Regularization",
          "year": 2023,
          "citations": 0,
          "abstract": "Variance-Invariance-Covariance Regularization (VICReg) is a self-supervised learning (SSL) method that has shown promising results on a variety of tasks. However, the fundamental mechanisms underlying VICReg remain unexplored. In this paper, we present an information-theoretic perspective on the VICReg objective. We begin by deriving information-theoretic quantities for deterministic networks as an alternative to unrealistic stochastic network assumptions. We then relate the optimization of the VICReg objective to mutual information optimization, highlighting underlying assumptions and facilitating a constructive comparison with other SSL algorithms and derive a generalization bound for VICReg, revealing its inherent advantages for downstream tasks. Building on these results, we introduce a family of SSL methods derived from information-theoretic principles that outperform existing SSL techniques.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2303.00633v4",
          "authors": [
            "Ravid Shwartz-Ziv",
            "Randall Balestriero",
            "Kenji Kawaguchi",
            "Tim G. J. Rudner",
            "Yann LeCun"
          ]
        },
        {
          "title": "Augmented Language Models: a Survey",
          "year": 2023,
          "citations": 0,
          "abstract": "This survey reviews works in which language models (LMs) are augmented with reasoning skills and the ability to use tools. The former is defined as decomposing a potentially complex task into simpler subtasks while the latter consists in calling external modules such as a code interpreter. LMs can leverage these augmentations separately or in combination via heuristics, or learn to do so from demonstrations. While adhering to a standard missing tokens prediction objective, such augmented LMs can use various, possibly non-parametric external modules to expand their context processing ability, thus departing from the pure language modeling paradigm. We therefore refer to them as Augmented Language Models (ALMs). The missing token objective allows ALMs to learn to reason, use tools, and even act, while still performing standard natural language tasks and even outperforming most regular LMs on several benchmarks. In this work, after reviewing current advance in ALMs, we conclude that this new research direction has the potential to address common limitations of traditional LMs such as interpretability, consistency, and scalability issues.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2302.07842v1",
          "authors": [
            "Grégoire Mialon",
            "Roberto Dessì",
            "Maria Lomeli",
            "Christoforos Nalmpantis",
            "Ram Pasunuru",
            "Roberta Raileanu",
            "Baptiste Rozière",
            "Timo Schick",
            "Jane Dwivedi-Yu",
            "Asli Celikyilmaz",
            "Edouard Grave",
            "Yann LeCun",
            "Thomas Scialom"
          ]
        },
        {
          "title": "Self-supervised learning of Split Invariant Equivariant representations",
          "year": 2023,
          "citations": 0,
          "abstract": "Recent progress has been made towards learning invariant or equivariant representations with self-supervised learning. While invariant methods are evaluated on large scale datasets, equivariant ones are evaluated in smaller, more controlled, settings. We aim at bridging the gap between the two in order to learn more diverse representations that are suitable for a wide range of tasks. We start by introducing a dataset called 3DIEBench, consisting of renderings from 3D models over  55 classes and more than 2.5 million images where we have full control on the transformations applied to the objects. We further introduce a predictor architecture based on hypernetworks to learn equivariant representations with no possible collapse to invariance. We introduce SIE (Split Invariant-Equivariant) which combines the hypernetwork-based predictor with representations split in two parts, one invariant, the other equivariant, to learn richer representations. We demonstrate significant performance gains over existing methods on equivariance related tasks from both a qualitative and quantitative point of view. We further analyze our introduced predictor and show how it steers the learned latent space. We hope that both our introduced dataset and approach will enable learning richer representations without supervision in more complex scenarios. Code and data are available at https://github.com/facebookresearch/SIE.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2302.10283v2",
          "authors": [
            "Quentin Garrido",
            "Laurent Najman",
            "Yann Lecun"
          ]
        },
        {
          "title": "The SSL Interplay: Augmentations, Inductive Bias, and Generalization",
          "year": 2023,
          "citations": 0,
          "abstract": "Self-supervised learning (SSL) has emerged as a powerful framework to learn representations from raw data without supervision. Yet in practice, engineers face issues such as instability in tuning optimizers and collapse of representations during training. Such challenges motivate the need for a theory to shed light on the complex interplay between the choice of data augmentation, network architecture, and training algorithm. We study such an interplay with a precise analysis of generalization performance on both pretraining and downstream tasks in a theory friendly setup, and highlight several insights for SSL practitioners that arise from our theory.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2302.02774v2",
          "authors": [
            "Vivien Cabannes",
            "Bobak T. Kiani",
            "Randall Balestriero",
            "Yann LeCun",
            "Alberto Bietti"
          ]
        },
        {
          "title": "Blockwise Self-Supervised Learning at Scale",
          "year": 2023,
          "citations": 0,
          "abstract": "Current state-of-the-art deep networks are all powered by backpropagation. In this paper, we explore alternatives to full backpropagation in the form of blockwise learning rules, leveraging the latest developments in self-supervised learning. We show that a blockwise pretraining procedure consisting of training independently the 4 main blocks of layers of a ResNet-50 with Barlow Twins' loss function at each block performs almost as well as end-to-end backpropagation on ImageNet: a linear probe trained on top of our blockwise pretrained model obtains a top-1 classification accuracy of 70.48%, only 1.1% below the accuracy of an end-to-end pretrained network (71.57% accuracy). We perform extensive experiments to understand the impact of different components within our method and explore a variety of adaptations of self-supervised learning to the blockwise paradigm, building an exhaustive understanding of the critical avenues for scaling local learning rules to large networks, with implications ranging from hardware design to neuroscience.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2302.01647v2",
          "authors": [
            "Shoaib Ahmed Siddiqui",
            "David Krueger",
            "Yann LeCun",
            "Stéphane Deny"
          ]
        },
        {
          "title": "Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture",
          "year": 2023,
          "citations": 0,
          "abstract": "This paper demonstrates an approach for learning highly semantic image representations without relying on hand-crafted data-augmentations. We introduce the Image-based Joint-Embedding Predictive Architecture (I-JEPA), a non-generative approach for self-supervised learning from images. The idea behind I-JEPA is simple: from a single context block, predict the representations of various target blocks in the same image. A core design choice to guide I-JEPA towards producing semantic representations is the masking strategy; specifically, it is crucial to (a) sample target blocks with sufficiently large scale (semantic), and to (b) use a sufficiently informative (spatially distributed) context block. Empirically, when combined with Vision Transformers, we find I-JEPA to be highly scalable. For instance, we train a ViT-Huge/14 on ImageNet using 16 A100 GPUs in under 72 hours to achieve strong downstream performance across a wide range of tasks, from linear classification to object counting and depth prediction.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2301.08243v3",
          "authors": [
            "Mahmoud Assran",
            "Quentin Duval",
            "Ishan Misra",
            "Piotr Bojanowski",
            "Pascal Vincent",
            "Michael Rabbat",
            "Yann LeCun",
            "Nicolas Ballas"
          ]
        },
        {
          "title": "A Generalization of ViT/MLP-Mixer to Graphs",
          "year": 2022,
          "citations": 0,
          "abstract": "Graph Neural Networks (GNNs) have shown great potential in the field of graph representation learning. Standard GNNs define a local message-passing mechanism which propagates information over the whole graph domain by stacking multiple layers. This paradigm suffers from two major limitations, over-squashing and poor long-range dependencies, that can be solved using global attention but significantly increases the computational cost to quadratic complexity. In this work, we propose an alternative approach to overcome these structural limitations by leveraging the ViT/MLP-Mixer architectures introduced in computer vision. We introduce a new class of GNNs, called Graph ViT/MLP-Mixer, that holds three key properties. First, they capture long-range dependency and mitigate the issue of over-squashing as demonstrated on Long Range Graph Benchmark and TreeNeighbourMatch datasets. Second, they offer better speed and memory efficiency with a complexity linear to the number of nodes and edges, surpassing the related Graph Transformer and expressive GNN models. Third, they show high expressivity in terms of graph isomorphism as they can distinguish at least 3-WL non-isomorphic graphs. We test our architecture on 4 simulated datasets and 7 real-world benchmarks, and show highly competitive results on all of them. The source code is available for reproducibility at: \\url{https://github.com/XiaoxinHe/Graph-ViT-MLPMixer}.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2212.13350v2",
          "authors": [
            "Xiaoxin He",
            "Bryan Hooi",
            "Thomas Laurent",
            "Adam Perold",
            "Yann LeCun",
            "Xavier Bresson"
          ]
        },
        {
          "title": "Joint Embedding Predictive Architectures Focus on Slow Features",
          "year": 2022,
          "citations": 0,
          "abstract": "Many common methods for learning a world model for pixel-based environments use generative architectures trained with pixel-level reconstruction objectives. Recently proposed Joint Embedding Predictive Architectures (JEPA) offer a reconstruction-free alternative. In this work, we analyze performance of JEPA trained with VICReg and SimCLR objectives in the fully offline setting without access to rewards, and compare the results to the performance of the generative architecture. We test the methods in a simple environment with a moving dot with various background distractors, and probe learned representations for the dot's location. We find that JEPA methods perform on par or better than reconstruction when distractor noise changes every time step, but fail when the noise is fixed. Furthermore, we provide a theoretical explanation for the poor performance of JEPA-based methods with fixed noise, highlighting an important limitation.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2211.10831v1",
          "authors": [
            "Vlad Sobal",
            "Jyothir S",
            "Siddhartha Jalagam",
            "Nicolas Carion",
            "Kyunghyun Cho",
            "Yann LeCun"
          ]
        },
        {
          "title": "POLICE: Provably Optimal Linear Constraint Enforcement for Deep Neural Networks",
          "year": 2022,
          "citations": 0,
          "abstract": "Deep Neural Networks (DNNs) outshine alternative function approximators in many settings thanks to their modularity in composing any desired differentiable operator. The formed parametrized functional is then tuned to solve a task at hand from simple gradient descent. This modularity comes at the cost of making strict enforcement of constraints on DNNs, e.g. from a priori knowledge of the task, or from desired physical properties, an open challenge. In this paper we propose the first provable affine constraint enforcement method for DNNs that only requires minimal changes into a given DNN's forward-pass, that is computationally friendly, and that leaves the optimization of the DNN's parameter to be unconstrained, i.e. standard gradient-based method can be employed. Our method does not require any sampling and provably ensures that the DNN fulfills the affine constraint on a given input space's region at any point during training, and testing. We coin this method POLICE, standing for Provably Optimal LInear Constraint Enforcement. Github: https://github.com/RandallBalestriero/POLICE",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2211.01340v3",
          "authors": [
            "Randall Balestriero",
            "Yann LeCun"
          ]
        },
        {
          "title": "Unsupervised Learning of Structured Representations via Closed-Loop Transcription",
          "year": 2022,
          "citations": 0,
          "abstract": "This paper proposes an unsupervised method for learning a unified representation that serves both discriminative and generative purposes. While most existing unsupervised learning approaches focus on a representation for only one of these two goals, we show that a unified representation can enjoy the mutual benefits of having both. Such a representation is attainable by generalizing the recently proposed \\textit{closed-loop transcription} framework, known as CTRL, to the unsupervised setting. This entails solving a constrained maximin game over a rate reduction objective that expands features of all samples while compressing features of augmentations of each sample. Through this process, we see discriminative low-dimensional structures emerge in the resulting representations. Under comparable experimental conditions and network complexities, we demonstrate that these structured representations enable classification performance close to state-of-the-art unsupervised discriminative representations, and conditionally generated image quality significantly higher than that of state-of-the-art unsupervised generative models. Source code can be found at https://github.com/Delay-Xili/uCTRL.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2210.16782v1",
          "authors": [
            "Shengbang Tong",
            "Xili Dai",
            "Yubei Chen",
            "Mingyang Li",
            "Zengyi Li",
            "Brent Yi",
            "Yann LeCun",
            "Yi Ma"
          ]
        },
        {
          "title": "Toward Next-Generation Artificial Intelligence: Catalyzing the NeuroAI Revolution",
          "year": 2022,
          "citations": 0,
          "abstract": "Neuroscience has long been an essential driver of progress in artificial intelligence (AI). We propose that to accelerate progress in AI, we must invest in fundamental research in NeuroAI. A core component of this is the embodied Turing test, which challenges AI animal models to interact with the sensorimotor world at skill levels akin to their living counterparts. The embodied Turing test shifts the focus from those capabilities like game playing and language that are especially well-developed or uniquely human to those capabilities, inherited from over 500 million years of evolution, that are shared with all animals. Building models that can pass the embodied Turing test will provide a roadmap for the next generation of AI.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2210.08340v3",
          "authors": [
            "Anthony Zador",
            "Sean Escola",
            "Blake Richards",
            "Bence Ölveczky",
            "Yoshua Bengio",
            "Kwabena Boahen",
            "Matthew Botvinick",
            "Dmitri Chklovskii",
            "Anne Churchland",
            "Claudia Clopath",
            "James DiCarlo",
            "Surya Ganguli",
            "Jeff Hawkins",
            "Konrad Koerding",
            "Alexei Koulakov",
            "Yann LeCun",
            "Timothy Lillicrap",
            "Adam Marblestone",
            "Bruno Olshausen",
            "Alexandre Pouget",
            "Cristina Savin",
            "Terrence Sejnowski",
            "Eero Simoncelli",
            "Sara Solla",
            "David Sussillo",
            "Andreas S. Tolias",
            "Doris Tsao"
          ]
        },
        {
          "title": "VoLTA: Vision-Language Transformer with Weakly-Supervised Local-Feature Alignment",
          "year": 2022,
          "citations": 0,
          "abstract": "Vision-language pre-training (VLP) has recently proven highly effective for various uni- and multi-modal downstream applications. However, most existing end-to-end VLP methods use high-resolution image-text box data to perform well on fine-grained region-level tasks, such as object detection, segmentation, and referring expression comprehension. Unfortunately, such high-resolution images with accurate bounding box annotations are expensive to collect and use for supervision at scale. In this work, we propose VoLTA (Vision-Language Transformer with weakly-supervised local-feature Alignment), a new VLP paradigm that only utilizes image-caption data but achieves fine-grained region-level image understanding, eliminating the use of expensive box annotations. VoLTA adopts graph optimal transport-based weakly-supervised alignment on local image patches and text tokens to germinate an explicit, self-normalized, and interpretable low-level matching criterion. In addition, VoLTA pushes multi-modal fusion deep into the uni-modal backbones during pre-training and removes fusion-specific transformer layers, further reducing memory requirements. Extensive experiments on a wide range of vision- and vision-language downstream tasks demonstrate the effectiveness of VoLTA on fine-grained applications without compromising the coarse-grained downstream performance, often outperforming methods using significantly more caption and box annotations.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2210.04135v3",
          "authors": [
            "Shraman Pramanick",
            "Li Jing",
            "Sayan Nag",
            "Jiachen Zhu",
            "Hardik Shah",
            "Yann LeCun",
            "Rama Chellappa"
          ]
        },
        {
          "title": "RankMe: Assessing the downstream performance of pretrained self-supervised representations by their rank",
          "year": 2022,
          "citations": 0,
          "abstract": "Joint-Embedding Self Supervised Learning (JE-SSL) has seen a rapid development, with the emergence of many method variations but only few principled guidelines that would help practitioners to successfully deploy them. The main reason for that pitfall comes from JE-SSL's core principle of not employing any input reconstruction therefore lacking visual cues of unsuccessful training. Adding non informative loss values to that, it becomes difficult to deploy SSL on a new dataset for which no labels can help to judge the quality of the learned representation. In this study, we develop a simple unsupervised criterion that is indicative of the quality of the learned JE-SSL representations: their effective rank. Albeit simple and computationally friendly, this method -- coined RankMe -- allows one to assess the performance of JE-SSL representations, even on different downstream datasets, without requiring any labels. A further benefit of RankMe is that it does not have any training or hyper-parameters to tune. Through thorough empirical experiments involving hundreds of training episodes, we demonstrate how RankMe can be used for hyperparameter selection with nearly no reduction in final performance compared to the current selection method that involve a dataset's labels. We hope that RankMe will facilitate the deployment of JE-SSL towards domains that do not have the opportunity to rely on labels for representations' quality assessment.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2210.02885v3",
          "authors": [
            "Quentin Garrido",
            "Randall Balestriero",
            "Laurent Najman",
            "Yann Lecun"
          ]
        },
        {
          "title": "VICRegL: Self-Supervised Learning of Local Visual Features",
          "year": 2022,
          "citations": 0,
          "abstract": "Most recent self-supervised methods for learning image representations focus on either producing a global feature with invariance properties, or producing a set of local features. The former works best for classification tasks while the latter is best for detection and segmentation tasks. This paper explores the fundamental trade-off between learning local and global features. A new method called VICRegL is proposed that learns good global and local features simultaneously, yielding excellent performance on detection and segmentation tasks while maintaining good performance on classification tasks. Concretely, two identical branches of a standard convolutional net architecture are fed two differently distorted versions of the same image. The VICReg criterion is applied to pairs of global feature vectors. Simultaneously, the VICReg criterion is applied to pairs of local feature vectors occurring before the last pooling layer. Two local feature vectors are attracted to each other if their l2-distance is below a threshold or if their relative locations are consistent with a known geometric transformation between the two input images. We demonstrate strong performance on linear classification and segmentation transfer tasks. Code and pretrained models are publicly available at: https://github.com/facebookresearch/VICRegL",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2210.01571v1",
          "authors": [
            "Adrien Bardes",
            "Jean Ponce",
            "Yann LeCun"
          ]
        },
        {
          "title": "Minimalistic Unsupervised Learning with the Sparse Manifold Transform",
          "year": 2022,
          "citations": 0,
          "abstract": "We describe a minimalistic and interpretable method for unsupervised learning, without resorting to data augmentation, hyperparameter tuning, or other engineering designs, that achieves performance close to the SOTA SSL methods. Our approach leverages the sparse manifold transform, which unifies sparse coding, manifold learning, and slow feature analysis. With a one-layer deterministic sparse manifold transform, one can achieve 99.3% KNN top-1 accuracy on MNIST, 81.1% KNN top-1 accuracy on CIFAR-10 and 53.2% on CIFAR-100. With a simple gray-scale augmentation, the model gets 83.2% KNN top-1 accuracy on CIFAR-10 and 57% on CIFAR-100. These results significantly close the gap between simplistic \"white-box\" methods and the SOTA methods. Additionally, we provide visualization to explain how an unsupervised representation transform is formed. The proposed method is closely connected to latent-embedding self-supervised methods and can be treated as the simplest form of VICReg. Though there remains a small performance gap between our simple constructive model and SOTA methods, the evidence points to this as a promising direction for achieving a principled and white-box approach to unsupervised learning.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2209.15261v2",
          "authors": [
            "Yubei Chen",
            "Zeyu Yun",
            "Yi Ma",
            "Bruno Olshausen",
            "Yann LeCun"
          ]
        },
        {
          "title": "Variance Covariance Regularization Enforces Pairwise Independence in Self-Supervised Representations",
          "year": 2022,
          "citations": 0,
          "abstract": "Self-Supervised Learning (SSL) methods such as VICReg, Barlow Twins or W-MSE avoid collapse of their joint embedding architectures by constraining or regularizing the covariance matrix of their projector's output. This study highlights important properties of such strategy, which we coin Variance-Covariance regularization (VCReg). More precisely, we show that {\\em VCReg combined to a MLP projector enforces pairwise independence between the features of the learned representation}. This result emerges by bridging VCReg applied on the projector's output to kernel independence criteria applied on the projector's input. We empirically validate our findings where (i) we put in evidence which projector's characteristics favor pairwise independence, (ii) we demonstrate pairwise independence to be beneficial for out-of-domain generalization, (iii) we demonstrate that the scope of VCReg goes beyond SSL by using it to solve Independent Component Analysis. This provides the first theoretical motivation and explanation of MLP projectors in SSL.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2209.14905v2",
          "authors": [
            "Grégoire Mialon",
            "Randall Balestriero",
            "Yann LeCun"
          ]
        },
        {
          "title": "Joint Embedding Self-Supervised Learning in the Kernel Regime",
          "year": 2022,
          "citations": 0,
          "abstract": "The fundamental goal of self-supervised learning (SSL) is to produce useful representations of data without access to any labels for classifying the data. Modern methods in SSL, which form representations based on known or constructed relationships between samples, have been particularly effective at this task. Here, we aim to extend this framework to incorporate algorithms based on kernel methods where embeddings are constructed by linear maps acting on the feature space of a kernel. In this kernel regime, we derive methods to find the optimal form of the output representations for contrastive and non-contrastive loss functions. This procedure produces a new representation space with an inner product denoted as the induced kernel which generally correlates points which are related by an augmentation in kernel space and de-correlates points otherwise. We analyze our kernel model on small datasets to identify common features of self-supervised learning algorithms and gain theoretical insights into their performance on downstream tasks.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2209.14884v1",
          "authors": [
            "Bobak T. Kiani",
            "Randall Balestriero",
            "Yubei Chen",
            "Seth Lloyd",
            "Yann LeCun"
          ]
        },
        {
          "title": "Light-weight probing of unsupervised representations for Reinforcement Learning",
          "year": 2022,
          "citations": 0,
          "abstract": "Unsupervised visual representation learning offers the opportunity to leverage large corpora of unlabeled trajectories to form useful visual representations, which can benefit the training of reinforcement learning (RL) algorithms. However, evaluating the fitness of such representations requires training RL algorithms which is computationally intensive and has high variance outcomes. Inspired by the vision community, we study whether linear probing can be a proxy evaluation task for the quality of unsupervised RL representation. Specifically, we probe for the observed reward in a given state and the action of an expert in a given state, both of which are generally applicable to many RL domains. Through rigorous experimentation, we show that the probing tasks are strongly rank correlated with the downstream RL performance on the Atari100k Benchmark, while having lower variance and up to 600x lower computational cost. This provides a more efficient method for exploring the space of pretraining algorithms and identifying promising pretraining recipes without the need to run RL evaluations for every setting. Leveraging this framework, we further improve existing self-supervised learning (SSL) recipes for RL, highlighting the importance of the forward model, the size of the visual backbone, and the precise formulation of the unsupervised objective.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2208.12345v2",
          "authors": [
            "Wancong Zhang",
            "Anthony GX-Chen",
            "Vlad Sobal",
            "Yann LeCun",
            "Nicolas Carion"
          ]
        },
        {
          "title": "What Do We Maximize in Self-Supervised Learning?",
          "year": 2022,
          "citations": 0,
          "abstract": "In this paper, we examine self-supervised learning methods, particularly VICReg, to provide an information-theoretical understanding of their construction. As a first step, we demonstrate how information-theoretic quantities can be obtained for a deterministic network, offering a possible alternative to prior work that relies on stochastic models. This enables us to demonstrate how VICReg can be (re)discovered from first principles and its assumptions about data distribution. Furthermore, we empirically demonstrate the validity of our assumptions, confirming our novel understanding of VICReg. Finally, we believe that the derivation and insights we obtain can be generalized to many other SSL methods, opening new avenues for theoretical and practical understanding of SSL and transfer learning.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2207.10081v1",
          "authors": [
            "Ravid Shwartz-Ziv",
            "Randall Balestriero",
            "Yann LeCun"
          ]
        },
        {
          "title": "TiCo: Transformation Invariance and Covariance Contrast for Self-Supervised Visual Representation Learning",
          "year": 2022,
          "citations": 0,
          "abstract": "We present Transformation Invariance and Covariance Contrast (TiCo) for self-supervised visual representation learning. Similar to other recent self-supervised learning methods, our method is based on maximizing the agreement among embeddings of different distorted versions of the same image, which pushes the encoder to produce transformation invariant representations. To avoid the trivial solution where the encoder generates constant vectors, we regularize the covariance matrix of the embeddings from different images by penalizing low rank solutions. By jointly minimizing the transformation invariance loss and covariance contrast loss, we get an encoder that is able to produce useful representations for downstream tasks. We analyze our method and show that it can be viewed as a variant of MoCo with an implicit memory bank of unlimited size at no extra memory cost. This makes our method perform better than alternative methods when using small batch sizes. TiCo can also be seen as a modification of Barlow Twins. By connecting the contrastive and redundancy-reduction methods together, TiCo gives us new insights into how joint embedding methods work.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2206.10698v2",
          "authors": [
            "Jiachen Zhu",
            "Rafael M. Moraes",
            "Serkan Karakulak",
            "Vlad Sobol",
            "Alfredo Canziani",
            "Yann LeCun"
          ]
        },
        {
          "title": "Bag of Image Patch Embedding Behind the Success of Self-Supervised Learning",
          "year": 2022,
          "citations": 0,
          "abstract": "Self-supervised learning (SSL) has recently achieved tremendous empirical advancements in learning image representation. However, our understanding of the principle behind learning such a representation is still limited. This work shows that joint-embedding SSL approaches primarily learn a representation of image patches, which reflects their co-occurrence. Such a connection to co-occurrence modeling can be established formally, and it supplements the prevailing invariance perspective. We empirically show that learning a representation for fixed-scale patches and aggregating local patch representations as the image representation achieves similar or even better results than the baseline methods. We denote this process as BagSSL. Even with 32x32 patch representation, BagSSL achieves 62% top-1 linear probing accuracy on ImageNet. On the other hand, with a multi-scale pretrained model, we show that the whole image embedding is approximately the average of local patch embeddings. While the SSL representation is relatively invariant at the global scale, we show that locality is preserved when we zoom into local patch-level representation. Further, we show that patch representation aggregation can improve various SOTA baseline methods by a large margin. The patch representation is considerably easier to understand, and this work makes a step to demystify self-supervised representation learning.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2206.08954v2",
          "authors": [
            "Yubei Chen",
            "Adrien Bardes",
            "Zengyi Li",
            "Yann LeCun"
          ]
        },
        {
          "title": "Masked Siamese ConvNets",
          "year": 2022,
          "citations": 0,
          "abstract": "Self-supervised learning has shown superior performances over supervised methods on various vision benchmarks. The siamese network, which encourages embeddings to be invariant to distortions, is one of the most successful self-supervised visual representation learning approaches. Among all the augmentation methods, masking is the most general and straightforward method that has the potential to be applied to all kinds of input and requires the least amount of domain knowledge. However, masked siamese networks require particular inductive bias and practically only work well with Vision Transformers. This work empirically studies the problems behind masked siamese networks with ConvNets. We propose several empirical designs to overcome these problems gradually. Our method performs competitively on low-shot image classification and outperforms previous methods on object detection benchmarks. We discuss several remaining issues and hope this work can provide useful data points for future general-purpose self-supervised learning.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2206.07700v1",
          "authors": [
            "Li Jing",
            "Jiachen Zhu",
            "Yann LeCun"
          ]
        },
        {
          "title": "Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone",
          "year": 2022,
          "citations": 0,
          "abstract": "Vision-language (VL) pre-training has recently received considerable attention. However, most existing end-to-end pre-training approaches either only aim to tackle VL tasks such as image-text retrieval, visual question answering (VQA) and image captioning that test high-level understanding of images, or only target region-level understanding for tasks such as phrase grounding and object detection. We present FIBER (Fusion-In-the-Backbone-based transformER), a new VL model architecture that can seamlessly handle both these types of tasks. Instead of having dedicated transformer layers for fusion after the uni-modal backbones, FIBER pushes multimodal fusion deep into the model by inserting cross-attention into the image and text backbones, bringing gains in terms of memory and performance. In addition, unlike previous work that is either only pre-trained on image-text data or on fine-grained data with box-level annotations, we present a two-stage pre-training strategy that uses both these kinds of data efficiently: (i) coarse-grained pre-training based on image-text data; followed by (ii) fine-grained pre-training based on image-text-box data. We conduct comprehensive experiments on a wide range of VL tasks, ranging from VQA, image captioning, and retrieval, to phrase grounding, referring expression comprehension, and object detection. Using deep multimodal fusion coupled with the two-stage pre-training, FIBER provides consistent performance improvements over strong baselines across all tasks, often outperforming methods using magnitudes more data. Code is available at https://github.com/microsoft/FIBER.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2206.07643v2",
          "authors": [
            "Zi-Yi Dou",
            "Aishwarya Kamath",
            "Zhe Gan",
            "Pengchuan Zhang",
            "Jianfeng Wang",
            "Linjie Li",
            "Zicheng Liu",
            "Ce Liu",
            "Yann LeCun",
            "Nanyun Peng",
            "Jianfeng Gao",
            "Lijuan Wang"
          ]
        },
        {
          "title": "On the duality between contrastive and non-contrastive self-supervised learning",
          "year": 2022,
          "citations": 0,
          "abstract": "Recent approaches in self-supervised learning of image representations can be categorized into different families of methods and, in particular, can be divided into contrastive and non-contrastive approaches. While differences between the two families have been thoroughly discussed to motivate new approaches, we focus more on the theoretical similarities between them. By designing contrastive and covariance based non-contrastive criteria that can be related algebraically and shown to be equivalent under limited assumptions, we show how close those families can be. We further study popular methods and introduce variations of them, allowing us to relate this theoretical result to current practices and show the influence (or lack thereof) of design choices on downstream performance. Motivated by our equivalence result, we investigate the low performance of SimCLR and show how it can match VICReg's with careful hyperparameter tuning, improving significantly over known baselines. We also challenge the popular assumption that non-contrastive methods need large output dimensions. Our theoretical and quantitative results suggest that the numerical gaps between contrastive and non-contrastive methods in certain regimes can be closed given better network design choices and hyperparameter tuning. The evidence shows that unifying different SOTA methods is an important direction to build a better understanding of self-supervised learning.",
          "venue": null,
          "doi": "10.48550/arXiv.2206.02574",
          "url": "https://arxiv.org/abs/2206.02574v3",
          "authors": [
            "Quentin Garrido",
            "Yubei Chen",
            "Adrien Bardes",
            "Laurent Najman",
            "Yann Lecun"
          ]
        },
        {
          "title": "Contrastive and Non-Contrastive Self-Supervised Learning Recover Global and Local Spectral Embedding Methods",
          "year": 2022,
          "citations": 0,
          "abstract": "Self-Supervised Learning (SSL) surmises that inputs and pairwise positive relationships are enough to learn meaningful representations. Although SSL has recently reached a milestone: outperforming supervised methods in many modalities\\dots the theoretical foundations are limited, method-specific, and fail to provide principled design guidelines to practitioners. In this paper, we propose a unifying framework under the helm of spectral manifold learning to address those limitations. Through the course of this study, we will rigorously demonstrate that VICReg, SimCLR, BarlowTwins et al. correspond to eponymous spectral methods such as Laplacian Eigenmaps, Multidimensional Scaling et al.   This unification will then allow us to obtain (i) the closed-form optimal representation for each method, (ii) the closed-form optimal network parameters in the linear regime for each method, (iii) the impact of the pairwise relations used during training on each of those quantities and on downstream task performances, and most importantly, (iv) the first theoretical bridge between contrastive and non-contrastive methods towards global and local spectral embedding methods respectively, hinting at the benefits and limitations of each. For example, (i) if the pairwise relation is aligned with the downstream task, any SSL method can be employed successfully and will recover the supervised method, but in the low data regime, VICReg's invariance hyper-parameter should be high; (ii) if the pairwise relation is misaligned with the downstream task, VICReg with small invariance hyper-parameter should be preferred over SimCLR or BarlowTwins.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2205.11508v3",
          "authors": [
            "Randall Balestriero",
            "Yann LeCun"
          ]
        },
        {
          "title": "Pre-Train Your Loss: Easy Bayesian Transfer Learning with Informative Priors",
          "year": 2022,
          "citations": 0,
          "abstract": "Deep learning is increasingly moving towards a transfer learning paradigm whereby large foundation models are fine-tuned on downstream tasks, starting from an initialization learned on the source task. But an initialization contains relatively little information about the source task. Instead, we show that we can learn highly informative posteriors from the source task, through supervised or self-supervised approaches, which then serve as the basis for priors that modify the whole loss surface on the downstream task. This simple modular approach enables significant performance gains and more data-efficient learning on a variety of downstream classification and segmentation tasks, serving as a drop-in replacement for standard pre-training strategies. These highly informative priors also can be saved for future use, similar to pre-trained weights, and stand in contrast to the zero-mean isotropic uninformative priors that are typically used in Bayesian deep learning.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2205.10279v1",
          "authors": [
            "Ravid Shwartz-Ziv",
            "Micah Goldblum",
            "Hossein Souri",
            "Sanyam Kapoor",
            "Chen Zhu",
            "Yann LeCun",
            "Andrew Gordon Wilson"
          ]
        },
        {
          "title": "Separating the World and Ego Models for Self-Driving",
          "year": 2022,
          "citations": 0,
          "abstract": "Training self-driving systems to be robust to the long-tail of driving scenarios is a critical problem. Model-based approaches leverage simulation to emulate a wide range of scenarios without putting users at risk in the real world. One promising path to faithful simulation is to train a forward model of the world to predict the future states of both the environment and the ego-vehicle given past states and a sequence of actions. In this paper, we argue that it is beneficial to model the state of the ego-vehicle, which often has simple, predictable and deterministic behavior, separately from the rest of the environment, which is much more complex and highly multimodal. We propose to model the ego-vehicle using a simple and differentiable kinematic model, while training a stochastic convolutional forward model on raster representations of the state to predict the behavior of the rest of the environment. We explore several configurations of such decoupled models, and evaluate their performance both with Model Predictive Control (MPC) and direct policy learning. We test our methods on the task of highway driving and demonstrate lower crash rates and better stability. The code is available at https://github.com/vladisai/pytorch-PPUU/tree/ICLR2022.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2204.07184v1",
          "authors": [
            "Vlad Sobal",
            "Alfredo Canziani",
            "Nicolas Carion",
            "Kyunghyun Cho",
            "Yann LeCun"
          ]
        },
        {
          "title": "The Effects of Regularization and Data Augmentation are Class Dependent",
          "year": 2022,
          "citations": 0,
          "abstract": "Regularization is a fundamental technique to prevent over-fitting and to improve generalization performances by constraining a model's complexity. Current Deep Networks heavily rely on regularizers such as Data-Augmentation (DA) or weight-decay, and employ structural risk minimization, i.e. cross-validation, to select the optimal regularization hyper-parameters. In this study, we demonstrate that techniques such as DA or weight decay produce a model with a reduced complexity that is unfair across classes. The optimal amount of DA or weight decay found from cross-validation leads to disastrous model performances on some classes e.g. on Imagenet with a resnet50, the \"barn spider\" classification test accuracy falls from $68\\%$ to $46\\%$ only by introducing random crop DA during training. Even more surprising, such performance drop also appears when introducing uninformative regularization techniques such as weight decay. Those results demonstrate that our search for ever increasing generalization performance -- averaged over all classes and samples -- has left us with models and regularizers that silently sacrifice performances on some classes. This scenario can become dangerous when deploying a model on downstream tasks e.g. an Imagenet pre-trained resnet50 deployed on INaturalist sees its performances fall from $70\\%$ to $30\\%$ on class \\#8889 when introducing random crop DA during the Imagenet pre-training phase. Those results demonstrate that designing novel regularizers without class-dependent bias remains an open research question.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2204.03632v2",
          "authors": [
            "Randall Balestriero",
            "Leon Bottou",
            "Yann LeCun"
          ]
        },
        {
          "title": "projUNN: efficient method for training deep networks with unitary matrices",
          "year": 2022,
          "citations": 0,
          "abstract": "In learning with recurrent or very deep feed-forward networks, employing unitary matrices in each layer can be very effective at maintaining long-range stability. However, restricting network parameters to be unitary typically comes at the cost of expensive parameterizations or increased training runtime. We propose instead an efficient method based on rank-$k$ updates -- or their rank-$k$ approximation -- that maintains performance at a nearly optimal training runtime. We introduce two variants of this method, named Direct (projUNN-D) and Tangent (projUNN-T) projected Unitary Neural Networks, that can parameterize full $N$-dimensional unitary or orthogonal matrices with a training runtime scaling as $O(kN^2)$. Our method either projects low-rank gradients onto the closest unitary matrix (projUNN-T) or transports unitary matrices in the direction of the low-rank gradient (projUNN-D). Even in the fastest setting ($k=1$), projUNN is able to train a model's unitary parameters to reach comparable performances against baseline implementations. In recurrent neural network settings, projUNN closely matches or exceeds benchmarked results from prior unitary neural networks. Finally, we preliminarily explore projUNN in training orthogonal convolutional neural networks, which are currently unable to outperform state of the art models but can potentially enhance stability and robustness at large depth.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2203.05483v3",
          "authors": [
            "Bobak Kiani",
            "Randall Balestriero",
            "Yann LeCun",
            "Seth Lloyd"
          ]
        },
        {
          "title": "A Data-Augmentation Is Worth A Thousand Samples: Exact Quantification From Analytical Augmented Sample Moments",
          "year": 2022,
          "citations": 0,
          "abstract": "Data-Augmentation (DA) is known to improve performance across tasks and datasets. We propose a method to theoretically analyze the effect of DA and study questions such as: how many augmented samples are needed to correctly estimate the information encoded by that DA? How does the augmentation policy impact the final parameters of a model? We derive several quantities in close-form, such as the expectation and variance of an image, loss, and model's output under a given DA distribution. Those derivations open new avenues to quantify the benefits and limitations of DA. For example, we show that common DAs require tens of thousands of samples for the loss at hand to be correctly estimated and for the model training to converge. We show that for a training loss to be stable under DA sampling, the model's saliency map (gradient of the loss with respect to the model's input) must align with the smallest eigenvector of the sample variance under the considered DA augmentation, hinting at a possible explanation on why models tend to shift their focus from edges to textures.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2202.08325v1",
          "authors": [
            "Randall Balestriero",
            "Ishan Misra",
            "Yann LeCun"
          ]
        },
        {
          "title": "Neural Manifold Clustering and Embedding",
          "year": 2022,
          "citations": 0,
          "abstract": "Given a union of non-linear manifolds, non-linear subspace clustering or manifold clustering aims to cluster data points based on manifold structures and also learn to parameterize each manifold as a linear subspace in a feature space. Deep neural networks have the potential to achieve this goal under highly non-linear settings given their large capacity and flexibility. We argue that achieving manifold clustering with neural networks requires two essential ingredients: a domain-specific constraint that ensures the identification of the manifolds, and a learning algorithm for embedding each manifold to a linear subspace in the feature space. This work shows that many constraints can be implemented by data augmentation. For subspace feature learning, Maximum Coding Rate Reduction (MCR$^2$) objective can be used. Putting them together yields {\\em Neural Manifold Clustering and Embedding} (NMCE), a novel method for general purpose manifold clustering, which significantly outperforms autoencoder-based deep subspace clustering. Further, on more challenging natural image datasets, NMCE can also outperform other algorithms specifically designed for clustering. Qualitatively, we demonstrate that NMCE learns a meaningful and interpretable feature space. As the formulation of NMCE is closely related to several important Self-supervised learning (SSL) methods, we believe this work can help us build a deeper understanding on SSL representation learning.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2201.10000v1",
          "authors": [
            "Zengyi Li",
            "Yubei Chen",
            "Yann LeCun",
            "Friedrich T. Sommer"
          ]
        },
        {
          "title": "Sparse Coding with Multi-Layer Decoders using Variance Regularization",
          "year": 2021,
          "citations": 0,
          "abstract": "Sparse representations of images are useful in many computer vision applications. Sparse coding with an $l_1$ penalty and a learned linear dictionary requires regularization of the dictionary to prevent a collapse in the $l_1$ norms of the codes. Typically, this regularization entails bounding the Euclidean norms of the dictionary's elements. In this work, we propose a novel sparse coding protocol which prevents a collapse in the codes without the need to regularize the decoder. Our method regularizes the codes directly so that each latent code component has variance greater than a fixed threshold over a set of sparse representations for a given set of inputs. Furthermore, we explore ways to effectively train sparse coding systems with multi-layer decoders since they can model more complex relationships than linear dictionaries. In our experiments with MNIST and natural image patches, we show that decoders learned with our approach have interpretable features both in the linear and multi-layer case. Moreover, we show that sparse autoencoders with multi-layer decoders trained using our variance regularization method produce higher quality reconstructions with sparser representations when compared to autoencoders with linear dictionaries. Additionally, sparse representations obtained with our variance regularization approach are useful in the downstream tasks of denoising and classification in the low-data regime.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2112.09214v2",
          "authors": [
            "Katrina Evtimova",
            "Yann LeCun"
          ]
        },
        {
          "title": "Learning in High Dimension Always Amounts to Extrapolation",
          "year": 2021,
          "citations": 0,
          "abstract": "The notion of interpolation and extrapolation is fundamental in various fields from deep learning to function approximation. Interpolation occurs for a sample $x$ whenever this sample falls inside or on the boundary of the given dataset's convex hull. Extrapolation occurs when $x$ falls outside of that convex hull. One fundamental (mis)conception is that state-of-the-art algorithms work so well because of their ability to correctly interpolate training data. A second (mis)conception is that interpolation happens throughout tasks and datasets, in fact, many intuitions and theories rely on that assumption. We empirically and theoretically argue against those two points and demonstrate that on any high-dimensional ($>$100) dataset, interpolation almost surely never happens. Those results challenge the validity of our current interpolation/extrapolation definition as an indicator of generalization performances.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2110.09485v2",
          "authors": [
            "Randall Balestriero",
            "Jerome Pesenti",
            "Yann LeCun"
          ]
        },
        {
          "title": "Understanding Dimensional Collapse in Contrastive Self-supervised Learning",
          "year": 2021,
          "citations": 0,
          "abstract": "Self-supervised visual representation learning aims to learn useful representations without relying on human annotations. Joint embedding approach bases on maximizing the agreement between embedding vectors from different views of the same image. Various methods have been proposed to solve the collapsing problem where all embedding vectors collapse to a trivial constant solution. Among these methods, contrastive learning prevents collapse via negative sample pairs. It has been shown that non-contrastive methods suffer from a lesser collapse problem of a different nature: dimensional collapse, whereby the embedding vectors end up spanning a lower-dimensional subspace instead of the entire available embedding space. Here, we show that dimensional collapse also happens in contrastive learning. In this paper, we shed light on the dynamics at play in contrastive learning that leads to dimensional collapse. Inspired by our theory, we propose a novel contrastive learning method, called DirectCLR, which directly optimizes the representation space without relying on an explicit trainable projector. Experiments show that DirectCLR outperforms SimCLR with a trainable linear projector on ImageNet.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2110.09348v3",
          "authors": [
            "Li Jing",
            "Pascal Vincent",
            "Yann LeCun",
            "Yuandong Tian"
          ]
        },
        {
          "title": "Decoupled Contrastive Learning",
          "year": 2021,
          "citations": 0,
          "abstract": "Contrastive learning (CL) is one of the most successful paradigms for self-supervised learning (SSL). In a principled way, it considers two augmented \"views\" of the same image as positive to be pulled closer, and all other images as negative to be pushed further apart. However, behind the impressive success of CL-based techniques, their formulation often relies on heavy-computation settings, including large sample batches, extensive training epochs, etc. We are thus motivated to tackle these issues and establish a simple, efficient, yet competitive baseline of contrastive learning. Specifically, we identify, from theoretical and empirical studies, a noticeable negative-positive-coupling (NPC) effect in the widely used InfoNCE loss, leading to unsuitable learning efficiency concerning the batch size. By removing the NPC effect, we propose decoupled contrastive learning (DCL) loss, which removes the positive term from the denominator and significantly improves the learning efficiency. DCL achieves competitive performance with less sensitivity to sub-optimal hyperparameters, requiring neither large batches in SimCLR, momentum encoding in MoCo, or large epochs. We demonstrate with various benchmarks while manifesting robustness as much less sensitive to suboptimal hyperparameters. Notably, SimCLR with DCL achieves 68.2% ImageNet-1K top-1 accuracy using batch size 256 within 200 epochs pre-training, outperforming its SimCLR baseline by 6.4%. Further, DCL can be combined with the SOTA contrastive learning method, NNCLR, to achieve 72.3% ImageNet-1K top-1 accuracy with 512 batch size in 400 epochs, which represents a new SOTA in contrastive learning. We believe DCL provides a valuable baseline for future contrastive SSL studies.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2110.06848v3",
          "authors": [
            "Chun-Hsiao Yeh",
            "Cheng-Yao Hong",
            "Yen-Chi Hsu",
            "Tyng-Luh Liu",
            "Yubei Chen",
            "Yann LeCun"
          ]
        },
        {
          "title": "Compact and Optimal Deep Learning with Recurrent Parameter Generators",
          "year": 2021,
          "citations": 0,
          "abstract": "Deep learning has achieved tremendous success by training increasingly large models, which are then compressed for practical deployment. We propose a drastically different approach to compact and optimal deep learning: We decouple the Degrees of freedom (DoF) and the actual number of parameters of a model, optimize a small DoF with predefined random linear constraints for a large model of arbitrary architecture, in one-stage end-to-end learning. Specifically, we create a recurrent parameter generator (RPG), which repeatedly fetches parameters from a ring and unpacks them onto a large model with random permutation and sign flipping to promote parameter decorrelation. We show that gradient descent can automatically find the best model under constraints with faster convergence. Our extensive experimentation reveals a log-linear relationship between model DoF and accuracy. Our RPG demonstrates remarkable DoF reduction and can be further pruned and quantized for additional run-time performance gain. For example, in terms of top-1 accuracy on ImageNet, RPG achieves $96\\%$ of ResNet18's performance with only $18\\%$ DoF (the equivalent of one convolutional layer) and $52\\%$ of ResNet34's performance with only $0.25\\%$ DoF! Our work shows a significant potential of constrained neural optimization in compact and optimal deep learning.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2107.07110v3",
          "authors": [
            "Jiayun Wang",
            "Yubei Chen",
            "Stella X. Yu",
            "Brian Cheung",
            "Yann LeCun"
          ]
        },
        {
          "title": "VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning",
          "year": 2021,
          "citations": 0,
          "abstract": "Recent self-supervised methods for image representation learning are based on maximizing the agreement between embedding vectors from different views of the same image. A trivial solution is obtained when the encoder outputs constant vectors. This collapse problem is often avoided through implicit biases in the learning architecture, that often lack a clear justification or interpretation. In this paper, we introduce VICReg (Variance-Invariance-Covariance Regularization), a method that explicitly avoids the collapse problem with a simple regularization term on the variance of the embeddings along each dimension individually. VICReg combines the variance term with a decorrelation mechanism based on redundancy reduction and covariance regularization, and achieves results on par with the state of the art on several downstream tasks. In addition, we show that incorporating our new variance term into other methods helps stabilize the training and leads to performance improvements.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2105.04906v3",
          "authors": [
            "Adrien Bardes",
            "Jean Ponce",
            "Yann LeCun"
          ]
        },
        {
          "title": "MDETR -- Modulated Detection for End-to-End Multi-Modal Understanding",
          "year": 2021,
          "citations": 0,
          "abstract": "Multi-modal reasoning systems rely on a pre-trained object detector to extract regions of interest from the image. However, this crucial module is typically used as a black box, trained independently of the downstream task and on a fixed vocabulary of objects and attributes. This makes it challenging for such systems to capture the long tail of visual concepts expressed in free form text. In this paper we propose MDETR, an end-to-end modulated detector that detects objects in an image conditioned on a raw text query, like a caption or a question. We use a transformer-based architecture to reason jointly over text and image by fusing the two modalities at an early stage of the model. We pre-train the network on 1.3M text-image pairs, mined from pre-existing multi-modal datasets having explicit alignment between phrases in text and objects in the image. We then fine-tune on several downstream tasks such as phrase grounding, referring expression comprehension and segmentation, achieving state-of-the-art results on popular benchmarks. We also investigate the utility of our model as an object detector on a given label set when fine-tuned in a few-shot setting. We show that our pre-training approach provides a way to handle the long tail of object categories which have very few labelled instances. Our approach can be easily extended for visual question answering, achieving competitive performance on GQA and CLEVR. The code and models are available at https://github.com/ashkamath/mdetr.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2104.12763v2",
          "authors": [
            "Aishwarya Kamath",
            "Mannat Singh",
            "Yann LeCun",
            "Gabriel Synnaeve",
            "Ishan Misra",
            "Nicolas Carion"
          ]
        },
        {
          "title": "Transformer visualization via dictionary learning: contextualized embedding as a linear superposition of transformer factors",
          "year": 2021,
          "citations": 0,
          "abstract": "Transformer networks have revolutionized NLP representation learning since they were introduced. Though a great effort has been made to explain the representation in transformers, it is widely recognized that our understanding is not sufficient. One important reason is that there lack enough visualization tools for detailed analysis. In this paper, we propose to use dictionary learning to open up these \"black boxes\" as linear superpositions of transformer factors. Through visualization, we demonstrate the hierarchical semantic structures captured by the transformer factors, e.g., word-level polysemy disambiguation, sentence-level pattern formation, and long-range dependency. While some of these patterns confirm the conventional prior linguistic knowledge, the rest are relatively unexpected, which may provide new insights. We hope this visualization tool can bring further knowledge and a better understanding of how transformer networks work. The code is available at https://github.com/zeyuyun1/TransformerVis",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2103.15949v2",
          "authors": [
            "Zeyu Yun",
            "Yubei Chen",
            "Bruno A Olshausen",
            "Yann LeCun"
          ]
        },
        {
          "title": "Barlow Twins: Self-Supervised Learning via Redundancy Reduction",
          "year": 2021,
          "citations": 0,
          "abstract": "Self-supervised learning (SSL) is rapidly closing the gap with supervised methods on large computer vision benchmarks. A successful approach to SSL is to learn embeddings which are invariant to distortions of the input sample. However, a recurring issue with this approach is the existence of trivial constant solutions. Most current methods avoid such solutions by careful implementation details. We propose an objective function that naturally avoids collapse by measuring the cross-correlation matrix between the outputs of two identical networks fed with distorted versions of a sample, and making it as close to the identity matrix as possible. This causes the embedding vectors of distorted versions of a sample to be similar, while minimizing the redundancy between the components of these vectors. The method is called Barlow Twins, owing to neuroscientist H. Barlow's redundancy-reduction principle applied to a pair of identical networks. Barlow Twins does not require large batches nor asymmetry between the network twins such as a predictor network, gradient stopping, or a moving average on the weight updates. Intriguingly it benefits from very high-dimensional output vectors. Barlow Twins outperforms previous methods on ImageNet for semi-supervised classification in the low-data regime, and is on par with current state of the art for ImageNet classification with a linear classifier head, and for transfer tasks of classification and object detection.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2103.03230v3",
          "authors": [
            "Jure Zbontar",
            "Li Jing",
            "Ishan Misra",
            "Yann LeCun",
            "Stéphane Deny"
          ]
        },
        {
          "title": "Implicit Rank-Minimizing Autoencoder",
          "year": 2020,
          "citations": 0,
          "abstract": "An important component of autoencoders is the method by which the information capacity of the latent representation is minimized or limited. In this work, the rank of the covariance matrix of the codes is implicitly minimized by relying on the fact that gradient descent learning in multi-layer linear networks leads to minimum-rank solutions. By inserting a number of extra linear layers between the encoder and the decoder, the system spontaneously learns representations with a low effective dimension. The model, dubbed Implicit Rank-Minimizing Autoencoder (IRMAE), is simple, deterministic, and learns compact latent spaces. We demonstrate the validity of the method on several image generation and representation learning tasks.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/2010.00679v2",
          "authors": [
            "Li Jing",
            "Jure Zbontar",
            "Yann LeCun"
          ]
        },
        {
          "title": "Inspirational Adversarial Image Generation",
          "year": 2019,
          "citations": 0,
          "abstract": "The task of image generation started to receive some attention from artists and designers to inspire them in new creations. However, exploiting the results of deep generative models such as Generative Adversarial Networks can be long and tedious given the lack of existing tools. In this work, we propose a simple strategy to inspire creators with new generations learned from a dataset of their choice, while providing some control on them. We design a simple optimization method to find the optimal latent parameters corresponding to the closest generation to any input inspirational image. Specifically, we allow the generation given an inspirational image of the user choice by performing several optimization steps to recover optimal parameters from the model's latent space. We tested several exploration methods starting with classic gradient descents to gradient-free optimizers. Many gradient-free optimizers just need comparisons (better/worse than another image), so that they can even be used without numerical criterion, without inspirational image, but with only with human preference. Thus, by iterating on one's preferences we could make robust Facial Composite or Fashion Generation algorithms. High resolution of the produced design generations are obtained using progressive growing of GANs. Our results on four datasets of faces, fashion images, and textures show that satisfactory images are effectively retrieved in most cases.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1906.11661v2",
          "authors": [
            "Baptiste Rozière",
            "Morgane Riviere",
            "Olivier Teytaud",
            "Jérémy Rapin",
            "Yann LeCun",
            "Camille Couprie"
          ]
        },
        {
          "title": "Unsupervised Image Matching and Object Discovery as Optimization",
          "year": 2019,
          "citations": 0,
          "abstract": "Learning with complete or partial supervision is powerful but relies on ever-growing human annotation efforts. As a way to mitigate this serious problem, as well as to serve specific applications, unsupervised learning has emerged as an important field of research. In computer vision, unsupervised learning comes in various guises. We focus here on the unsupervised discovery and matching of object categories among images in a collection, following the work of Cho et al. 2015. We show that the original approach can be reformulated and solved as a proper optimization problem. Experiments on several benchmarks establish the merit of our approach.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1904.03148v1",
          "authors": [
            "Huy V. Vo",
            "Francis Bach",
            "Minsu Cho",
            "Kai Han",
            "Yann LeCun",
            "Patrick Perez",
            "Jean Ponce"
          ]
        },
        {
          "title": "Learning about an exponential amount of conditional distributions",
          "year": 2019,
          "citations": 0,
          "abstract": "We introduce the Neural Conditioner (NC), a self-supervised machine able to learn about all the conditional distributions of a random vector $X$. The NC is a function $NC(x \\cdot a, a, r)$ that leverages adversarial training to match each conditional distribution $P(X_r|X_a=x_a)$. After training, the NC generalizes to sample from conditional distributions never seen, including the joint distribution. The NC is also able to auto-encode examples, providing data representations useful for downstream classification tasks. In sum, the NC integrates different self-supervised tasks (each being the estimation of a conditional distribution) and levels of supervision (partially observed data) seamlessly into a single learning experience.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1902.08401v1",
          "authors": [
            "Mohamed Ishmael Belghazi",
            "Maxime Oquab",
            "Yann LeCun",
            "David Lopez-Paz"
          ]
        },
        {
          "title": "Model-Predictive Policy Learning with Uncertainty Regularization for Driving in Dense Traffic",
          "year": 2019,
          "citations": 0,
          "abstract": "Learning a policy using only observational data is challenging because the distribution of states it induces at execution time may differ from the distribution observed during training. We propose to train a policy by unrolling a learned model of the environment dynamics over multiple time steps while explicitly penalizing two costs: the original cost the policy seeks to optimize, and an uncertainty cost which represents its divergence from the states it is trained on. We measure this second cost by using the uncertainty of the dynamics model about its own predictions, using recent ideas from uncertainty estimation for deep networks. We evaluate our approach using a large-scale observational dataset of driving behavior recorded from traffic cameras, and show that we are able to learn effective driving policies from purely observational data, with no environment interaction.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1901.02705v1",
          "authors": [
            "Mikael Henaff",
            "Alfredo Canziani",
            "Yann LeCun"
          ]
        },
        {
          "title": "A Spectral Regularizer for Unsupervised Disentanglement",
          "year": 2018,
          "citations": 0,
          "abstract": "A generative model with a disentangled representation allows for independent control over different aspects of the output. Learning disentangled representations has been a recent topic of great interest, but it remains poorly understood. We show that even for GANs that do not possess disentangled representations, one can find curved trajectories in latent space over which local disentanglement occurs. These trajectories are found by iteratively following the leading right-singular vectors of the Jacobian of the generator with respect to its input. Based on this insight, we describe an efficient regularizer that aligns these vectors with the coordinate axes, and show that it can be used to induce disentangled representations in GANs, in a completely unsupervised manner.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1812.01161v2",
          "authors": [
            "Aditya Ramesh",
            "Youngduck Choi",
            "Yann LeCun"
          ]
        },
        {
          "title": "Adversarially-Trained Normalized Noisy-Feature Auto-Encoder for Text Generation",
          "year": 2018,
          "citations": 0,
          "abstract": "This article proposes Adversarially-Trained Normalized Noisy-Feature Auto-Encoder (ATNNFAE) for byte-level text generation. An ATNNFAE consists of an auto-encoder where the internal code is normalized on the unit sphere and corrupted by additive noise. Simultaneously, a replica of the decoder (sharing the same parameters as the AE decoder) is used as the generator and fed with random latent vectors. An adversarial discriminator is trained to distinguish training samples reconstructed from the AE from samples produced through the random-input generator, making the entire generator-discriminator path differentiable for discrete data like text. The combined effect of noise injection in the code and shared weights between the decoder and the generator can prevent the mode collapsing phenomenon commonly observed in GANs. Since perplexity cannot be applied to non-sequential text generation, we propose a new evaluation method using the total variance distance between frequencies of hash-coded byte-level n-grams (NGTVD). NGTVD is a single benchmark that can characterize both the quality and the diversity of the generated texts. Experiments are offered in 6 large-scale datasets in Arabic, Chinese and English, with comparisons against n-gram baselines and recurrent neural networks (RNNs). Ablation study on both the noise level and the discriminator is performed. We find that RNNs have trouble competing with the n-gram baselines, and the ATNNFAE results are generally competitive.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1811.04201v1",
          "authors": [
            "Xiang Zhang",
            "Yann LeCun"
          ]
        },
        {
          "title": "GLoMo: Unsupervisedly Learned Relational Graphs as Transferable Representations",
          "year": 2018,
          "citations": 0,
          "abstract": "Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Our proposed transfer learning framework improves performance on various tasks including question answering, natural language inference, sentiment analysis, and image classification. We also show that the learned graphs are generic enough to be transferred to different embeddings on which the graphs have not been trained (including GloVe embeddings, ELMo embeddings, and task-specific RNN hidden unit), or embedding-free units such as image pixels.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1806.05662v3",
          "authors": [
            "Zhilin Yang",
            "Jake Zhao",
            "Bhuwan Dhingra",
            "Kaiming He",
            "William W. Cohen",
            "Ruslan Salakhutdinov",
            "Yann LeCun"
          ]
        },
        {
          "title": "Backpropagation for Implicit Spectral Densities",
          "year": 2018,
          "citations": 0,
          "abstract": "Most successful machine intelligence systems rely on gradient-based learning, which is made possible by backpropagation. Some systems are designed to aid us in interpreting data when explicit goals cannot be provided. These unsupervised systems are commonly trained by backpropagating through a likelihood function. We introduce a tool that allows us to do this even when the likelihood is not explicitly set, by instead using the implicit likelihood of the model. Explicitly defining the likelihood often entails making heavy-handed assumptions that impede our ability to solve challenging tasks. On the other hand, the implicit likelihood of the model is accessible without the need for such assumptions. Our tool, which we call spectral backpropagation, allows us to optimize it in much greater generality than what has been attempted before. GANs can also be viewed as a technique for optimizing implicit likelihoods. We study them using spectral backpropagation in order to demonstrate robustness for high-dimensional problems, and identify two novel properties of the generator G: (1) there exist aberrant, nonsensical outputs to which G assigns very high likelihood, and (2) the eigenvectors of the metric induced by G over latent space correspond to quasi-disentangled explanatory factors.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1806.00499v1",
          "authors": [
            "Aditya Ramesh",
            "Yann LeCun"
          ]
        },
        {
          "title": "Towards Understanding the Role of Over-Parametrization in Generalization of Neural Networks",
          "year": 2018,
          "citations": 0,
          "abstract": "Despite existing work on ensuring generalization of neural networks in terms of scale sensitive complexity measures, such as norms, margin and sharpness, these complexity measures do not offer an explanation of why neural networks generalize better with over-parametrization. In this work we suggest a novel complexity measure based on unit-wise capacities resulting in a tighter generalization bound for two layer ReLU networks. Our capacity bound correlates with the behavior of test error with increasing network sizes, and could potentially explain the improvement in generalization with over-parametrization. We further present a matching lower bound for the Rademacher complexity that improves over previous capacity lower bounds for neural networks.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1805.12076v1",
          "authors": [
            "Behnam Neyshabur",
            "Zhiyuan Li",
            "Srinadh Bhojanapalli",
            "Yann LeCun",
            "Nathan Srebro"
          ]
        },
        {
          "title": "DeSIGN: Design Inspiration from Generative Networks",
          "year": 2018,
          "citations": 0,
          "abstract": "Can an algorithm create original and compelling fashion designs to serve as an inspirational assistant? To help answer this question, we design and investigate different image generation models associated with different loss functions to boost creativity in fashion generation. The dimensions of our explorations include: (i) different Generative Adversarial Networks architectures that start from noise vectors to generate fashion items, (ii) novel loss functions that encourage novelty, inspired from Sharma-Mittal divergence, a generalized mutual information measure for the widely used relative entropies such as Kullback-Leibler, and (iii) a generation process following the key elements of fashion design (disentangling shape and texture components). A key challenge of this study is the evaluation of generated designs and the retrieval of best ones, hence we put together an evaluation protocol associating automatic metrics and human experimental studies that we hope will help ease future research. We show that our proposed creativity criterion yield better overall appreciation than the one employed in Creative Adversarial Networks. In the end, about 61% of our images are thought to be created by human designers rather than by a computer while also being considered original per our human subject experiments, and our proposed loss scores the highest compared to existing losses in both novelty and likability.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1804.00921v2",
          "authors": [
            "Othman Sbai",
            "Mohamed Elhoseiny",
            "Antoine Bordes",
            "Yann LeCun",
            "Camille Couprie"
          ]
        },
        {
          "title": "Predicting Future Instance Segmentation by Forecasting Convolutional Features",
          "year": 2018,
          "citations": 0,
          "abstract": "Anticipating future events is an important prerequisite towards intelligent behavior. Video forecasting has been studied as a proxy task towards this goal. Recent work has shown that to predict semantic segmentation of future frames, forecasting at the semantic level is more effective than forecasting RGB frames and then segmenting these. In this paper we consider the more challenging problem of future instance segmentation, which additionally segments out individual objects. To deal with a varying number of output labels per image, we develop a predictive model in the space of fixed-sized convolutional features of the Mask R-CNN instance segmentation model. We apply the \"detection head'\" of Mask R-CNN on the predicted features to produce the instance segmentation of future frames. Experiments show that this approach significantly improves over strong baselines based on optical flow and repurposed instance segmentation architectures.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1803.11496v2",
          "authors": [
            "Pauline Luc",
            "Camille Couprie",
            "Yann LeCun",
            "Jakob Verbeek"
          ]
        },
        {
          "title": "Byte-Level Recursive Convolutional Auto-Encoder for Text",
          "year": 2018,
          "citations": 0,
          "abstract": "This article proposes to auto-encode text at byte-level using convolutional networks with a recursive architecture. The motivation is to explore whether it is possible to have scalable and homogeneous text generation at byte-level in a non-sequential fashion through the simple task of auto-encoding. We show that non-sequential text generation from a fixed-length representation is not only possible, but also achieved much better auto-encoding results than recurrent networks. The proposed model is a multi-stage deep convolutional encoder-decoder framework using residual connections, containing up to 160 parameterized layers. Each encoder or decoder contains a shared group of modules that consists of either pooling or upsampling layers, making the network recursive in terms of abstraction levels in representation. Results for 6 large-scale paragraph datasets are reported, in 3 languages including Arabic, Chinese and English. Analyses are conducted to study several properties of the proposed model.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1802.01817v1",
          "authors": [
            "Xiang Zhang",
            "Yann LeCun"
          ]
        },
        {
          "title": "A Closer Look at Spatiotemporal Convolutions for Action Recognition",
          "year": 2017,
          "citations": 0,
          "abstract": "In this paper we discuss several forms of spatiotemporal convolutions for video analysis and study their effects on action recognition. Our motivation stems from the observation that 2D CNNs applied to individual frames of the video have remained solid performers in action recognition. In this work we empirically demonstrate the accuracy advantages of 3D CNNs over 2D CNNs within the framework of residual learning. Furthermore, we show that factorizing the 3D convolutional filters into separate spatial and temporal components yields significantly advantages in accuracy. Our empirical study leads to the design of a new spatiotemporal convolutional block \"R(2+1)D\" which gives rise to CNNs that achieve results comparable or superior to the state-of-the-art on Sports-1M, Kinetics, UCF101 and HMDB51.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1711.11248v3",
          "authors": [
            "Du Tran",
            "Heng Wang",
            "Lorenzo Torresani",
            "Jamie Ray",
            "Yann LeCun",
            "Manohar Paluri"
          ]
        },
        {
          "title": "Prediction Under Uncertainty with Error-Encoding Networks",
          "year": 2017,
          "citations": 0,
          "abstract": "In this work we introduce a new framework for performing temporal predictions in the presence of uncertainty. It is based on a simple idea of disentangling components of the future state which are predictable from those which are inherently unpredictable, and encoding the unpredictable components into a low-dimensional latent variable which is fed into a forward model. Our method uses a supervised training objective which is fast and easy to train. We evaluate it in the context of video prediction on multiple datasets and show that it is able to consistently generate diverse predictions without the need for alternating minimization over a latent space or adversarial training.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1711.04994v3",
          "authors": [
            "Mikael Henaff",
            "Junbo Zhao",
            "Yann LeCun"
          ]
        },
        {
          "title": "A hierarchical loss and its problems when classifying non-hierarchically",
          "year": 2017,
          "citations": 0,
          "abstract": "Failing to distinguish between a sheepdog and a skyscraper should be worse and penalized more than failing to distinguish between a sheepdog and a poodle; after all, sheepdogs and poodles are both breeds of dogs. However, existing metrics of failure (so-called \"loss\" or \"win\") used in textual or visual classification/recognition via neural networks seldom leverage a-priori information, such as a sheepdog being more similar to a poodle than to a skyscraper. We define a metric that, inter alia, can penalize failure to distinguish between a sheepdog and a skyscraper more than failure to distinguish between a sheepdog and a poodle. Unlike previously employed possibilities, this metric is based on an ultrametric tree associated with any given tree organization into a semantically meaningful hierarchy of a classifier's classes. An ultrametric tree is a tree with a so-called ultrametric distance metric such that all leaves are at the same distance from the root. Unfortunately, extensive numerical experiments indicate that the standard practice of training neural networks via stochastic gradient descent with random starting points often drives down the hierarchical loss nearly as much when minimizing the standard cross-entropy loss as when trying to minimize the hierarchical loss directly. Thus, this hierarchical loss is unreliable as an objective for plain, randomly started stochastic gradient descent to minimize; the main value of the hierarchical loss may be merely as a meaningful metric of success of a classifier.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1709.01062v2",
          "authors": [
            "Cinna Wu",
            "Mark Tygert",
            "Yann LeCun"
          ]
        },
        {
          "title": "Which Encoding is the Best for Text Classification in Chinese, English, Japanese and Korean?",
          "year": 2017,
          "citations": 0,
          "abstract": "This article offers an empirical study on the different ways of encoding Chinese, Japanese, Korean (CJK) and English languages for text classification. Different encoding levels are studied, including UTF-8 bytes, characters, words, romanized characters and romanized words. For all encoding levels, whenever applicable, we provide comparisons with linear models, fastText and convolutional networks. For convolutional networks, we compare between encoding mechanisms using character glyph images, one-hot (or one-of-n) encoding, and embedding. In total there are 473 models, using 14 large-scale text classification datasets in 4 languages including Chinese, English, Japanese and Korean. Some conclusions from these results include that byte-level one-hot encoding based on UTF-8 consistently produces competitive results for convolutional networks, that word-level n-grams linear models are competitive even without perfect word segmentation, and that fastText provides the best result using character-level n-gram encoding but can overfit when the features are overly rich.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1708.02657v2",
          "authors": [
            "Xiang Zhang",
            "Yann LeCun"
          ]
        },
        {
          "title": "Adversarially Regularized Autoencoders",
          "year": 2017,
          "citations": 0,
          "abstract": "Deep latent variable models, trained using variational autoencoders or generative adversarial networks, are now a key technique for representation learning of continuous structures. However, applying similar methods to discrete structures, such as text sequences or discretized images, has proven to be more challenging. In this work, we propose a flexible method for training deep latent variable models of discrete structures. Our approach is based on the recently-proposed Wasserstein autoencoder (WAE) which formalizes the adversarial autoencoder (AAE) as an optimal transport problem. We first extend this framework to model discrete sequences, and then further explore different learned priors targeting a controllable representation. This adversarially regularized autoencoder (ARAE) allows us to generate natural textual outputs as well as perform manipulations in the latent space to induce change in the output space. Finally we show that the latent representation can be trained to perform unaligned textual style transfer, giving improvements both in automatic/human evaluation compared to existing methods.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1706.04223v3",
          "authors": [
            "Jake Zhao",
            "Yoon Kim",
            "Kelly Zhang",
            "Alexander M. Rush",
            "Yann LeCun"
          ]
        },
        {
          "title": "Model-Based Planning with Discrete and Continuous Actions",
          "year": 2017,
          "citations": 0,
          "abstract": "Action planning using learned and differentiable forward models of the world is a general approach which has a number of desirable properties, including improved sample complexity over model-free RL methods, reuse of learned models across different tasks, and the ability to perform efficient gradient-based optimization in continuous action spaces. However, this approach does not apply straightforwardly when the action space is discrete. In this work, we show that it is in fact possible to effectively perform planning via backprop in discrete action spaces, using a simple paramaterization of the actions vectors on the simplex combined with input noise when training the forward model. Our experiments show that this approach can match or outperform model-free RL and discrete planning methods on gridworld navigation tasks in terms of performance and/or planning time while using limited environment interactions, and can additionally be used to perform model-based control in a challenging new task where the action space combines discrete and continuous actions. We furthermore propose a policy distillation approach which yields a fast policy network which can be used at inference time, removing the need for an iterative planning procedure.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1705.07177v2",
          "authors": [
            "Mikael Henaff",
            "William F. Whitney",
            "Yann LeCun"
          ]
        },
        {
          "title": "Predicting Deeper into the Future of Semantic Segmentation",
          "year": 2017,
          "citations": 0,
          "abstract": "The ability to predict and therefore to anticipate the future is an important attribute of intelligence. It is also of utmost importance in real-time systems, e.g. in robotics or autonomous driving, which depend on visual scene understanding for decision making. While prediction of the raw RGB pixel values in future video frames has been studied in previous work, here we introduce the novel task of predicting semantic segmentations of future frames. Given a sequence of video frames, our goal is to predict segmentation maps of not yet observed video frames that lie up to a second or further in the future. We develop an autoregressive convolutional neural network that learns to iteratively generate multiple frames. Our results on the Cityscapes dataset show that directly predicting future segmentations is substantially better than predicting and then segmenting future RGB frames. Prediction results up to half a second in the future are visually convincing and are much more accurate than those of a baseline based on warping semantic segmentations using optical flow.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1703.07684v3",
          "authors": [
            "Pauline Luc",
            "Natalia Neverova",
            "Camille Couprie",
            "Jakob Verbeek",
            "Yann LeCun"
          ]
        },
        {
          "title": "Tunable Efficient Unitary Neural Networks (EUNN) and their application to RNNs",
          "year": 2016,
          "citations": 0,
          "abstract": "Using unitary (instead of general) matrices in artificial neural networks (ANNs) is a promising way to solve the gradient explosion/vanishing problem, as well as to enable ANNs to learn long-term correlations in the data. This approach appears particularly promising for Recurrent Neural Networks (RNNs). In this work, we present a new architecture for implementing an Efficient Unitary Neural Network (EUNNs); its main advantages can be summarized as follows. Firstly, the representation capacity of the unitary space in an EUNN is fully tunable, ranging from a subspace of SU(N) to the entire unitary space. Secondly, the computational complexity for training an EUNN is merely $\\mathcal{O}(1)$ per parameter. Finally, we test the performance of EUNNs on the standard copying task, the pixel-permuted MNIST digit recognition benchmark as well as the Speech Prediction Test (TIMIT). We find that our architecture significantly outperforms both other state-of-the-art unitary RNNs and the LSTM architecture, in terms of the final performance and/or the wall-clock training speed. EUNNs are thus promising alternatives to RNNs and LSTMs for a wide variety of applications.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1612.05231v3",
          "authors": [
            "Li Jing",
            "Yichen Shen",
            "Tena Dubček",
            "John Peurifoy",
            "Scott Skirlo",
            "Yann LeCun",
            "Max Tegmark",
            "Marin Soljačić"
          ]
        },
        {
          "title": "Tracking the World State with Recurrent Entity Networks",
          "year": 2016,
          "citations": 0,
          "abstract": "We introduce a new model, the Recurrent Entity Network (EntNet). It is equipped with a dynamic long-term memory which allows it to maintain and update a representation of the state of the world as it receives new data. For language understanding tasks, it can reason on-the-fly as it reads text, not just when it is required to answer a question or respond as is the case for a Memory Network (Sukhbaatar et al., 2015). Like a Neural Turing Machine or Differentiable Neural Computer (Graves et al., 2014; 2016) it maintains a fixed size memory and can learn to perform location and content-based read and write operations. However, unlike those models it has a simple parallel architecture in which several memory locations can be updated simultaneously. The EntNet sets a new state-of-the-art on the bAbI tasks, and is the first method to solve all the tasks in the 10k training examples setting. We also demonstrate that it can solve a reasoning task which requires a large number of supporting facts, which other methods are not able to solve, and can generalize past its training horizon. It can also be practically used on large scale datasets such as Children's Book Test, where it obtains competitive performance, reading the story in a single pass.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1612.03969v3",
          "authors": [
            "Mikael Henaff",
            "Jason Weston",
            "Arthur Szlam",
            "Antoine Bordes",
            "Yann LeCun"
          ]
        },
        {
          "title": "Geometric deep learning: going beyond Euclidean data",
          "year": 2016,
          "citations": 0,
          "abstract": "Many scientific fields study data with an underlying structure that is a non-Euclidean space. Some examples include social networks in computational social sciences, sensor networks in communications, functional networks in brain imaging, regulatory networks in genetics, and meshed surfaces in computer graphics. In many applications, such geometric data are large and complex (in the case of social networks, on the scale of billions), and are natural targets for machine learning techniques. In particular, we would like to use deep neural networks, which have recently proven to be powerful tools for a broad range of problems from computer vision, natural language processing, and audio analysis. However, these tools have been most successful on data with an underlying Euclidean or grid-like structure, and in cases where the invariances of these structures are built into networks used to model them. Geometric deep learning is an umbrella term for emerging techniques attempting to generalize (structured) deep neural models to non-Euclidean domains such as graphs and manifolds. The purpose of this paper is to overview different examples of geometric deep learning problems and present available solutions, key difficulties, applications, and future research directions in this nascent field.",
          "venue": null,
          "doi": "10.1109/MSP.2017.2693418",
          "url": "https://arxiv.org/abs/1611.08097v2",
          "authors": [
            "Michael M. Bronstein",
            "Joan Bruna",
            "Yann LeCun",
            "Arthur Szlam",
            "Pierre Vandergheynst"
          ]
        },
        {
          "title": "Eigenvalues of the Hessian in Deep Learning: Singularity and Beyond",
          "year": 2016,
          "citations": 0,
          "abstract": "We look at the eigenvalues of the Hessian of a loss function before and after training. The eigenvalue distribution is seen to be composed of two parts, the bulk which is concentrated around zero, and the edges which are scattered away from zero. We present empirical evidence for the bulk indicating how over-parametrized the system is, and for the edges that depend on the input data.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1611.07476v2",
          "authors": [
            "Levent Sagun",
            "Leon Bottou",
            "Yann LeCun"
          ]
        },
        {
          "title": "Disentangling factors of variation in deep representations using adversarial training",
          "year": 2016,
          "citations": 0,
          "abstract": "We introduce a conditional generative model for learning to disentangle the hidden factors of variation within a set of labeled observations, and separate them into complementary codes. One code summarizes the specified factors of variation associated with the labels. The other summarizes the remaining unspecified variability. During training, the only available source of supervision comes from our ability to distinguish among different observations belonging to the same class. Examples of such observations include images of a set of labeled objects captured at different viewpoints, or recordings of set of speakers dictating multiple phrases. In both instances, the intra-class diversity is the source of the unspecified factors of variation: each object is observed at multiple viewpoints, and each speaker dictates multiple phrases. Learning to disentangle the specified factors from the unspecified ones becomes easier when strong supervision is possible. Suppose that during training, we have access to pairs of images, where each pair shows two different objects captured from the same viewpoint. This source of alignment allows us to solve our task using existing methods. However, labels for the unspecified factors are usually unavailable in realistic scenarios where data acquisition is not strictly controlled. We address the problem of disentanglement in this more general setting by combining deep convolutional autoencoders with a form of adversarial training. Both factors of variation are implicitly captured in the organization of the learned embedding space, and can be used for solving single-image analogies. Experimental results on synthetic and real datasets show that the proposed method is capable of generalizing to unseen classes and intra-class variabilities.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1611.03383v1",
          "authors": [
            "Michael Mathieu",
            "Junbo Zhao",
            "Pablo Sprechmann",
            "Aditya Ramesh",
            "Yann LeCun"
          ]
        },
        {
          "title": "Entropy-SGD: Biasing Gradient Descent Into Wide Valleys",
          "year": 2016,
          "citations": 0,
          "abstract": "This paper proposes a new optimization algorithm called Entropy-SGD for training deep neural networks that is motivated by the local geometry of the energy landscape. Local extrema with low generalization error have a large proportion of almost-zero eigenvalues in the Hessian with very few positive or negative eigenvalues. We leverage upon this observation to construct a local-entropy-based objective function that favors well-generalizable solutions lying in large flat regions of the energy landscape, while avoiding poorly-generalizable solutions located in the sharp valleys. Conceptually, our algorithm resembles two nested loops of SGD where we use Langevin dynamics in the inner loop to compute the gradient of the local entropy before each update of the weights. We show that the new objective has a smoother energy landscape and show improved generalization over SGD using uniform stability, under certain assumptions. Our experiments on convolutional and recurrent networks demonstrate that Entropy-SGD compares favorably to state-of-the-art techniques in terms of generalization error and training time.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1611.01838v5",
          "authors": [
            "Pratik Chaudhari",
            "Anna Choromanska",
            "Stefano Soatto",
            "Yann LeCun",
            "Carlo Baldassi",
            "Christian Borgs",
            "Jennifer Chayes",
            "Levent Sagun",
            "Riccardo Zecchina"
          ]
        },
        {
          "title": "Energy-based Generative Adversarial Network",
          "year": 2016,
          "citations": 0,
          "abstract": "We introduce the \"Energy-based Generative Adversarial Network\" model (EBGAN) which views the discriminator as an energy function that attributes low energies to the regions near the data manifold and higher energies to other regions. Similar to the probabilistic GANs, a generator is seen as being trained to produce contrastive samples with minimal energies, while the discriminator is trained to assign high energies to these generated samples. Viewing the discriminator as an energy function allows to use a wide variety of architectures and loss functionals in addition to the usual binary classifier with logistic output. Among them, we show one instantiation of EBGAN framework as using an auto-encoder architecture, with the energy being the reconstruction error, in place of the discriminator. We show that this form of EBGAN exhibits more stable behavior than regular GANs during training. We also show that a single-scale architecture can be trained to generate high-resolution images.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1609.03126v4",
          "authors": [
            "Junbo Zhao",
            "Michael Mathieu",
            "Yann LeCun"
          ]
        },
        {
          "title": "Fast Incremental Learning for Off-Road Robot Navigation",
          "year": 2016,
          "citations": 0,
          "abstract": "A promising approach to autonomous driving is machine learning. In such systems, training datasets are created that capture the sensory input to a vehicle as well as the desired response. A disadvantage of using a learned navigation system is that the learning process itself may require a huge number of training examples and a large amount of computing. To avoid the need to collect a large training set of driving examples, we describe a system that takes advantage of the huge number of training examples provided by ImageNet, but is able to adapt quickly using a small training set for the specific driving environment.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1606.08057v1",
          "authors": [
            "Artem Provodin",
            "Liila Torabi",
            "Beat Flepp",
            "Yann LeCun",
            "Michael Sergio",
            "L. D. Jackel",
            "Urs Muller",
            "Jure Zbontar"
          ]
        },
        {
          "title": "Very Deep Convolutional Networks for Text Classification",
          "year": 2016,
          "citations": 0,
          "abstract": "The dominant approach for many NLP tasks are recurrent neural networks, in particular LSTMs, and convolutional neural networks. However, these architectures are rather shallow in comparison to the deep convolutional networks which have pushed the state-of-the-art in computer vision. We present a new architecture (VDCNN) for text processing which operates directly at the character level and uses only small convolutions and pooling operations. We are able to show that the performance of this model increases with depth: using up to 29 convolutional layers, we report improvements over the state-of-the-art on several public text classification tasks. To the best of our knowledge, this is the first time that very deep convolutional nets have been applied to text processing.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1606.01781v2",
          "authors": [
            "Alexis Conneau",
            "Holger Schwenk",
            "Loïc Barrault",
            "Yann Lecun"
          ]
        },
        {
          "title": "What is the Best Feature Learning Procedure in Hierarchical Recognition Architectures?",
          "year": 2016,
          "citations": 0,
          "abstract": "(This paper was written in November 2011 and never published. It is posted on arXiv.org in its original form in June 2016). Many recent object recognition systems have proposed using a two phase training procedure to learn sparse convolutional feature hierarchies: unsupervised pre-training followed by supervised fine-tuning. Recent results suggest that these methods provide little improvement over purely supervised systems when the appropriate nonlinearities are included. This paper presents an empirical exploration of the space of learning procedures for sparse convolutional networks to assess which method produces the best performance. In our study, we introduce an augmentation of the Predictive Sparse Decomposition method that includes a discriminative term (DPSD). We also introduce a new single phase supervised learning procedure that places an L1 penalty on the output state of each layer of the network. This forces the network to produce sparse codes without the expensive pre-training phase. Using DPSD with a new, complex predictor that incorporates lateral inhibition, combined with multi-scale feature pooling, and supervised refinement, the system achieves a 70.6\\% recognition rate on Caltech-101. With the addition of convolutional training, a 77\\% recognition was obtained on the CIfAR-10 dataset.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1606.01535v1",
          "authors": [
            "Kevin Jarrett",
            "Koray Kvukcuoglu",
            "Karol Gregor",
            "Yann LeCun"
          ]
        },
        {
          "title": "Phase 3: DCL System Using Deep Learning Approaches for Land-based or Ship-based Real-Time Recognition and Localization of Marine Mammals - Bioacoustic Applicaitons",
          "year": 2016,
          "citations": 0,
          "abstract": "Goals of this research phase is to investigate advanced detection and classification pardims useful for data-mining passive large passive acoustic archives. Technical objectives are to develop and refine a High Performance Computing, Acoustic Data Accelerator (HPC-ADA) along with MATLAB based software based on time series acoustic signal Detection cLassification using Machine learning Algorithms, called DeLMA. Data scientists and biologists integrate to use the HPC-ADA and DeLMA technologies to explore data using newly developed techniques aimed at inspection of data extracted at large spatial and temporal scales.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1605.00983v2",
          "authors": [
            "Peter J. Dugan",
            "Christopher W. Clark",
            "Yann André LeCun",
            "Sofie M. Van Parijs"
          ]
        },
        {
          "title": "Phase 4: DCL System Using Deep Learning Approaches for Land-Based or Ship-Based Real-Time Recognition and Localization of Marine Mammals - Distributed Processing and Big Data Applications",
          "year": 2016,
          "citations": 0,
          "abstract": "While the animal bioacoustics community at large is collecting huge amounts of acoustic data at an unprecedented pace, processing these data is problematic. Currently in bioacoustics, there is no effective way to achieve high performance computing using commericial off the shelf (COTS) or government off the shelf (GOTS) tools. Although several advances have been made in the open source and commercial software community, these offerings either support specific applications that do not integrate well with data formats in bioacoustics or they are too general. Furthermore, complex algorithms that use deep learning strategies require special considerations, such as very large libraiers of exemplars (whale sounds) readily available for algorithm training and testing. Detection-classification for passive acoustics is a data-mining strategy and our goals are aligned with best practices that appeal to the general data mining and machine learning communities where the problem of processing large data is common. Therefore, the objective of this work is to advance the state-of-the art for data-mining large passive acoustic datasets as they pertain to bioacoustics. With this basic deficiency recognized at the forefront, portions of the grant were dedicated to fostering deep-learning by way of international competitions (kaggle.com) meant to attract deep-learning solutions. The focus of this early work was targeted to make significant progress in addressing big data systems and advanced algorithms over the duration of the grant from 2012 to 2015. This early work provided simulataneous advances in systems-algorithms research while supporting various collaborations and projects.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1605.00982v2",
          "authors": [
            "Peter J. Dugan",
            "Christopher W. Clark",
            "Yann André LeCun",
            "Sofie M. Van Parijs"
          ]
        },
        {
          "title": "Phase 2: DCL System Using Deep Learning Approaches for Land-based or Ship-based Real-Time Recognition and Localization of Marine Mammals - Machine Learning Detection Algorithms",
          "year": 2016,
          "citations": 0,
          "abstract": "Overarching goals for this work aim to advance the state of the art for detection, classification and localization (DCL) in the field of bioacoustics. This goal is primarily achieved by building a generic framework for detection-classification (DC) using a fast, efficient and scalable architecture, demonstrating the capabilities of this system using on a variety of low-frequency mid-frequency cetacean sounds. Two primary goals are to develop transferable technologies for detection and classification in, one: the area of advanced algorithms, such as deep learning and other methods; and two: advanced systems, capable of real-time and archival processing. For each key area, we will focus on producing publications from this work and providing tools and software to the community where/when possible. Currently massive amounts of acoustic data are being collected by various institutions, corporations and national defense agencies. The long-term goal is to provide technical capability to analyze the data using automatic algorithms for (DC) based on machine intelligence. The goal of the automation is to provide effective and efficient mechanisms by which to process large acoustic datasets for understanding the bioacoustic behaviors of marine mammals. This capability will provide insights into the potential ecological impacts and influences of anthropogenic ocean sounds. This work focuses on building technologies using a maturity model based on DARPA 6.1 and 6.2 processes, for basic and applied research, respectively.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1605.00972v2",
          "authors": [
            "Peter J. Dugan",
            "Christopher W. Clark",
            "Yann André LeCun",
            "Sofie M. Van Parijs"
          ]
        },
        {
          "title": "Phase 1: DCL System Research Using Advanced Approaches for Land-based or Ship-based Real-Time Recognition and Localization of Marine Mammals - HPC System Implementation",
          "year": 2016,
          "citations": 0,
          "abstract": "We aim to investigate advancing the state of the art of detection, classification and localization (DCL) in the field of bioacoustics. The two primary goals are to develop transferable technologies for detection and classification in: (1) the area of advanced algorithms, such as deep learning and other methods; and (2) advanced systems, capable of real-time and archival and processing. This project will focus on long-term, continuous datasets to provide automatic recognition, minimizing human time to annotate the signals. Effort will begin by focusing on several years of multi-channel acoustic data collected in the Stellwagen Bank National Marine Sanctuary (SBNMS) between 2006 and 2010. Our efforts will incorporate existing technologies in the bioacoustics signal processing community, advanced high performance computing (HPC) systems, and new approaches aimed at automatically detecting-classifying and measuring features for species-specific marine mammal sounds within passive acoustic data.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1605.00971v2",
          "authors": [
            "Peter J. Dugan",
            "Christopher W. Clark",
            "Yann André LeCun",
            "Sofie M. Van Parijs"
          ]
        },
        {
          "title": "Recurrent Orthogonal Networks and Long-Memory Tasks",
          "year": 2016,
          "citations": 0,
          "abstract": "Although RNNs have been shown to be powerful tools for processing sequential data, finding architectures or optimization strategies that allow them to model very long term dependencies is still an active area of research. In this work, we carefully analyze two synthetic datasets originally outlined in (Hochreiter and Schmidhuber, 1997) which are used to evaluate the ability of RNNs to store information over many time steps. We explicitly construct RNN solutions to these problems, and using these constructions, illuminate both the problems themselves and the way in which RNNs store different types of information in their hidden states. These constructions furthermore explain the success of recent methods that specify unitary initializations or constraints on the transition matrices.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1602.06662v2",
          "authors": [
            "Mikael Henaff",
            "Arthur Szlam",
            "Yann LeCun"
          ]
        },
        {
          "title": "Universal halting times in optimization and machine learning",
          "year": 2015,
          "citations": 0,
          "abstract": "The authors present empirical distributions for the halting time (measured by the number of iterations to reach a given accuracy) of optimization algorithms applied to two random systems: spin glasses and deep learning. Given an algorithm, which we take to be both the optimization routine and the form of the random landscape, the fluctuations of the halting time follow a distribution that, after centering and scaling, remains unchanged even when the distribution on the landscape is changed. We observe two qualitative classes: A Gumbel-like distribution that appears in Google searches, human decision times, the QR eigenvalue algorithm and spin glasses, and a Gaussian-like distribution that appears in conjugate gradient method, deep network with MNIST input data and deep network with random input data. This empirical evidence suggests presence of a class of distributions for which the halting time is independent of the underlying distribution under some conditions.",
          "venue": null,
          "doi": "10.1090/qam/1483",
          "url": "https://arxiv.org/abs/1511.06444v3",
          "authors": [
            "Levent Sagun",
            "Thomas Trogdon",
            "Yann LeCun"
          ]
        },
        {
          "title": "Super-Resolution with Deep Convolutional Sufficient Statistics",
          "year": 2015,
          "citations": 0,
          "abstract": "Inverse problems in image and audio, and super-resolution in particular, can be seen as high-dimensional structured prediction problems, where the goal is to characterize the conditional distribution of a high-resolution output given its low-resolution corrupted observation. When the scaling ratio is small, point estimates achieve impressive performance, but soon they suffer from the regression-to-the-mean problem, result of their inability to capture the multi-modality of this conditional distribution. Modeling high-dimensional image and audio distributions is a hard task, requiring both the ability to model complex geometrical structures and textured regions. In this paper, we propose to use as conditional model a Gibbs distribution, where its sufficient statistics are given by deep convolutional neural networks. The features computed by the network are stable to local deformation, and have reduced variance when the input is a stationary texture. These properties imply that the resulting sufficient statistics minimize the uncertainty of the target signals given the degraded observations, while being highly informative. The filters of the CNN are initialized by multiscale complex wavelets, and then we propose an algorithm to fine-tune them by estimating the gradient of the conditional log-likelihood, which bears some similarities with Generative Adversarial Networks. We evaluate experimentally the proposed approach in the image super-resolution task, but the approach is general and could be used in other challenging ill-posed problems such as audio bandwidth extension.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1511.05666v4",
          "authors": [
            "Joan Bruna",
            "Pablo Sprechmann",
            "Yann LeCun"
          ]
        },
        {
          "title": "Deep multi-scale video prediction beyond mean square error",
          "year": 2015,
          "citations": 0,
          "abstract": "Learning to predict future images from a video sequence involves the construction of an internal representation that models the image evolution accurately, and therefore, to some degree, its content and dynamics. This is why pixel-space video prediction may be viewed as a promising avenue for unsupervised feature learning. In addition, while optical flow has been a very studied problem in computer vision for a long time, future frame prediction is rarely approached. Still, many vision applications could benefit from the knowledge of the next frames of videos, that does not require the complexity of tracking every pixel trajectories. In this work, we train a convolutional network to generate future frames given an input sequence. To deal with the inherently blurry predictions obtained from the standard Mean Squared Error (MSE) loss function, we propose three different and complementary feature learning strategies: a multi-scale architecture, an adversarial training method, and an image gradient difference loss function. We compare our predictions to different published results based on recurrent neural networks on the UCF101 dataset",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1511.05440v6",
          "authors": [
            "Michael Mathieu",
            "Camille Couprie",
            "Yann LeCun"
          ]
        },
        {
          "title": "Binary embeddings with structured hashed projections",
          "year": 2015,
          "citations": 0,
          "abstract": "We consider the hashing mechanism for constructing binary embeddings, that involves pseudo-random projections followed by nonlinear (sign function) mappings. The pseudo-random projection is described by a matrix, where not all entries are independent random variables but instead a fixed \"budget of randomness\" is distributed across the matrix. Such matrices can be efficiently stored in sub-quadratic or even linear space, provide reduction in randomness usage (i.e. number of required random values), and very often lead to computational speed ups. We prove several theoretical results showing that projections via various structured matrices followed by nonlinear mappings accurately preserve the angular distance between input high-dimensional vectors. To the best of our knowledge, these results are the first that give theoretical ground for the use of general structured matrices in the nonlinear setting. In particular, they generalize previous extensions of the Johnson-Lindenstrauss lemma and prove the plausibility of the approach that was so far only heuristically confirmed for some special structured matrices. Consequently, we show that many structured matrices can be used as an efficient information compression mechanism. Our findings build a better understanding of certain deep architectures, which contain randomly weighted and untrained layers, and yet achieve high performance on different learning tasks. We empirically verify our theoretical findings and show the dependence of learning via structured hashed projections on the performance of neural network as well as nearest neighbor classifier.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1511.05212v5",
          "authors": [
            "Anna Choromanska",
            "Krzysztof Choromanski",
            "Mariusz Bojarski",
            "Tony Jebara",
            "Sanjiv Kumar",
            "Yann LeCun"
          ]
        },
        {
          "title": "Universum Prescription: Regularization using Unlabeled Data",
          "year": 2015,
          "citations": 0,
          "abstract": "This paper shows that simply prescribing \"none of the above\" labels to unlabeled data has a beneficial regularization effect to supervised learning. We call it universum prescription by the fact that the prescribed labels cannot be one of the supervised labels. In spite of its simplicity, universum prescription obtained competitive results in training deep convolutional networks for CIFAR-10, CIFAR-100, STL-10 and ImageNet datasets. A qualitative justification of these approaches using Rademacher complexity is presented. The effect of a regularization parameter -- probability of sampling from unlabeled data -- is also studied empirically.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1511.03719v7",
          "authors": [
            "Xiang Zhang",
            "Yann LeCun"
          ]
        },
        {
          "title": "Stereo Matching by Training a Convolutional Neural Network to Compare Image Patches",
          "year": 2015,
          "citations": 0,
          "abstract": "We present a method for extracting depth information from a rectified image pair. Our approach focuses on the first stage of many stereo algorithms: the matching cost computation. We approach the problem by learning a similarity measure on small image patches using a convolutional neural network. Training is carried out in a supervised manner by constructing a binary classification data set with examples of similar and dissimilar pairs of patches. We examine two network architectures for this task: one tuned for speed, the other for accuracy. The output of the convolutional neural network is used to initialize the stereo matching cost. A series of post-processing steps follow: cross-based cost aggregation, semiglobal matching, a left-right consistency check, subpixel enhancement, a median filter, and a bilateral filter. We evaluate our method on the KITTI 2012, KITTI 2015, and Middlebury stereo data sets and show that it outperforms other approaches on all three data sets.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1510.05970v2",
          "authors": [
            "Jure Žbontar",
            "Yann LeCun"
          ]
        },
        {
          "title": "Very Deep Multilingual Convolutional Neural Networks for LVCSR",
          "year": 2015,
          "citations": 0,
          "abstract": "Convolutional neural networks (CNNs) are a standard component of many current state-of-the-art Large Vocabulary Continuous Speech Recognition (LVCSR) systems. However, CNNs in LVCSR have not kept pace with recent advances in other domains where deeper neural networks provide superior performance. In this paper we propose a number of architectural advances in CNNs for LVCSR. First, we introduce a very deep convolutional network architecture with up to 14 weight layers. There are multiple convolutional layers before each pooling layer, with small 3x3 kernels, inspired by the VGG Imagenet 2014 architecture. Then, we introduce multilingual CNNs with multiple untied layers. Finally, we introduce multi-scale input features aimed at exploiting more context at negligible computational cost. We evaluate the improvements first on a Babel task for low resource speech recognition, obtaining an absolute 5.77% WER improvement over the baseline PLP DNN by training our CNN on the combined data of six different languages. We then evaluate the very deep CNNs on the Hub5'00 benchmark (using the 262 hours of SWB-1 training data) achieving a word error rate of 11.8% after cross-entropy training, a 1.4% WER improvement (10.6% relative) over the best published CNN result so far.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1509.08967v2",
          "authors": [
            "Tom Sercu",
            "Christian Puhrsch",
            "Brian Kingsbury",
            "Yann LeCun"
          ]
        },
        {
          "title": "High Performance Computer Acoustic Data Accelerator: A New System for Exploring Marine Mammal Acoustics for Big Data Applications",
          "year": 2015,
          "citations": 0,
          "abstract": "This paper presents a new software model designed for distributed sonic signal detection runtime using machine learning algorithms called DeLMA. A new algorithm--Acoustic Data-mining Accelerator (ADA)--is also presented. ADA is a robust yet scalable solution for efficiently processing big sound archives using distributing computing technologies. Together, DeLMA and the ADA algorithm provide a powerful tool currently being used by the Bioacoustics Research Program (BRP) at the Cornell Lab of Ornithology, Cornell University. This paper provides a high level technical overview of the system, and discusses various aspects of the design. Basic runtime performance and project summary are presented. The DeLMA-ADA baseline performance comparing desktop serial configuration to a 64 core distributed HPC system shows as much as a 44 times faster increase in runtime execution. Performance tests using 48 cores on the HPC shows a 9x to 12x efficiency over a 4 core desktop solution. Project summary results for 19 east coast deployments show that the DeLMA-ADA solution has processed over three million channel hours of sound to date.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1509.03591v1",
          "authors": [
            "Peter Dugan",
            "John Zollweg",
            "Marian Popescu",
            "Denise Risch",
            "Herve Glotin",
            "Yann LeCun",
            "and Christopher Clark"
          ]
        },
        {
          "title": "Character-level Convolutional Networks for Text Classification",
          "year": 2015,
          "citations": 0,
          "abstract": "This article offers an empirical exploration on the use of character-level convolutional networks (ConvNets) for text classification. We constructed several large-scale datasets to show that character-level convolutional networks could achieve state-of-the-art or competitive results. Comparisons are offered against traditional models such as bag of words, n-grams and their TFIDF variants, and deep learning models such as word-based ConvNets and recurrent neural networks.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1509.01626v3",
          "authors": [
            "Xiang Zhang",
            "Junbo Zhao",
            "Yann LeCun"
          ]
        },
        {
          "title": "Deep Convolutional Networks on Graph-Structured Data",
          "year": 2015,
          "citations": 0,
          "abstract": "Deep Learning's recent successes have mostly relied on Convolutional Networks, which exploit fundamental statistical properties of images, sounds and video data: the local stationarity and multi-scale compositional structure, that allows expressing long range interactions in terms of shorter, localized interactions. However, there exist other important examples, such as text documents or bioinformatic data, that may lack some or all of these strong statistical regularities.   In this paper we consider the general question of how to construct deep architectures with small learning complexity on general non-Euclidean domains, which are typically unknown and need to be estimated from the data. In particular, we develop an extension of Spectral Networks which incorporates a Graph Estimation procedure, that we test on large-scale classification problems, matching or improving over Dropout Networks with far less parameters to estimate.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1506.05163v1",
          "authors": [
            "Mikael Henaff",
            "Joan Bruna",
            "Yann LeCun"
          ]
        },
        {
          "title": "Learning to Linearize Under Uncertainty",
          "year": 2015,
          "citations": 0,
          "abstract": "Training deep feature hierarchies to solve supervised learning tasks has achieved state of the art performance on many problems in computer vision. However, a principled way in which to train such hierarchies in the unsupervised setting has remained elusive. In this work we suggest a new architecture and loss for training deep feature hierarchies that linearize the transformations observed in unlabeled natural video sequences. This is done by training a generative model to predict video frames. We also address the problem of inherent uncertainty in prediction by introducing latent variables that are non-deterministic functions of the input into the network architecture.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1506.03011v2",
          "authors": [
            "Ross Goroshin",
            "Michael Mathieu",
            "Yann LeCun"
          ]
        },
        {
          "title": "Stacked What-Where Auto-encoders",
          "year": 2015,
          "citations": 0,
          "abstract": "We present a novel architecture, the \"stacked what-where auto-encoders\" (SWWAE), which integrates discriminative and generative pathways and provides a unified approach to supervised, semi-supervised and unsupervised learning without relying on sampling during training. An instantiation of SWWAE uses a convolutional net (Convnet) (LeCun et al. (1998)) to encode the input, and employs a deconvolutional net (Deconvnet) (Zeiler et al. (2010)) to produce the reconstruction. The objective function includes reconstruction terms that induce the hidden states in the Deconvnet to be similar to those of the Convnet. Each pooling layer produces two sets of variables: the \"what\" which are fed to the next layer, and its complementary variable \"where\" that are fed to the corresponding layer in the generative decoder.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1506.02351v8",
          "authors": [
            "Junbo Zhao",
            "Michael Mathieu",
            "Ross Goroshin",
            "Yann LeCun"
          ]
        },
        {
          "title": "Unsupervised Feature Learning from Temporal Data",
          "year": 2015,
          "citations": 0,
          "abstract": "Current state-of-the-art classification and detection algorithms rely on supervised training. In this work we study unsupervised feature learning in the context of temporally coherent video data. We focus on feature learning from unlabeled video data, using the assumption that adjacent video frames contain semantically similar information. This assumption is exploited to train a convolutional pooling auto-encoder regularized by slowness and sparsity. We establish a connection between slow feature learning to metric learning and show that the trained encoder can be used to define a more temporally and semantically coherent metric.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1504.02518v2",
          "authors": [
            "Ross Goroshin",
            "Joan Bruna",
            "Jonathan Tompson",
            "David Eigen",
            "Yann LeCun"
          ]
        },
        {
          "title": "A mathematical motivation for complex-valued convolutional networks",
          "year": 2015,
          "citations": 0,
          "abstract": "A complex-valued convolutional network (convnet) implements the repeated application of the following composition of three operations, recursively applying the composition to an input vector of nonnegative real numbers: (1) convolution with complex-valued vectors followed by (2) taking the absolute value of every entry of the resulting vectors followed by (3) local averaging. For processing real-valued random vectors, complex-valued convnets can be viewed as \"data-driven multiscale windowed power spectra,\" \"data-driven multiscale windowed absolute spectra,\" \"data-driven multiwavelet absolute values,\" or (in their most general configuration) \"data-driven nonlinear multiwavelet packets.\" Indeed, complex-valued convnets can calculate multiscale windowed spectra when the convnet filters are windowed complex-valued exponentials. Standard real-valued convnets, using rectified linear units (ReLUs), sigmoidal (for example, logistic or tanh) nonlinearities, max. pooling, etc., do not obviously exhibit the same exact correspondence with data-driven wavelets (whereas for complex-valued convnets, the correspondence is much more than just a vague analogy). Courtesy of the exact correspondence, the remarkably rich and rigorous body of mathematical analysis for wavelets applies directly to (complex-valued) convnets.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1503.03438v3",
          "authors": [
            "Joan Bruna",
            "Soumith Chintala",
            "Yann LeCun",
            "Serkan Piantino",
            "Arthur Szlam",
            "Mark Tygert"
          ]
        },
        {
          "title": "Text Understanding from Scratch",
          "year": 2015,
          "citations": 0,
          "abstract": "This article demontrates that we can apply deep learning to text understanding from character-level inputs all the way up to abstract text concepts, using temporal convolutional networks (ConvNets). We apply ConvNets to various large-scale datasets, including ontology classification, sentiment analysis, and text categorization. We show that temporal ConvNets can achieve astonishing performance without the knowledge of words, phrases, sentences and any other syntactic or semantic structures with regards to a human language. Evidence shows that our models can work for both English and Chinese.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1502.01710v5",
          "authors": [
            "Xiang Zhang",
            "Yann LeCun"
          ]
        },
        {
          "title": "Fast Convolutional Nets With fbfft: A GPU Performance Evaluation",
          "year": 2014,
          "citations": 0,
          "abstract": "We examine the performance profile of Convolutional Neural Network training on the current generation of NVIDIA Graphics Processing Units. We introduce two new Fast Fourier Transform convolution implementations: one based on NVIDIA's cuFFT library, and another based on a Facebook authored FFT implementation, fbfft, that provides significant speedups over cuFFT (over 1.5x) for whole CNNs. Both of these convolution implementations are available in open source, and are faster than NVIDIA's cuDNN implementation for many common convolutional layers (up to 23.5x for some synthetic kernel configurations). We discuss different performance regimes of convolutions, comparing areas where straightforward time domain convolutions outperform Fourier frequency domain convolutions. Details on algorithmic applications of NVIDIA GPU hardware specifics in the implementation of fbfft are also provided.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1412.7580v3",
          "authors": [
            "Nicolas Vasilache",
            "Jeff Johnson",
            "Michael Mathieu",
            "Soumith Chintala",
            "Serkan Piantino",
            "Yann LeCun"
          ]
        },
        {
          "title": "Audio Source Separation with Discriminative Scattering Networks",
          "year": 2014,
          "citations": 0,
          "abstract": "In this report we describe an ongoing line of research for solving single-channel source separation problems. Many monaural signal decomposition techniques proposed in the literature operate on a feature space consisting of a time-frequency representation of the input data. A challenge faced by these approaches is to effectively exploit the temporal dependencies of the signals at scales larger than the duration of a time-frame. In this work we propose to tackle this problem by modeling the signals using a time-frequency representation with multiple temporal resolutions. The proposed representation consists of a pyramid of wavelet scattering operators, which generalizes Constant Q Transforms (CQT) with extra layers of convolution and complex modulus. We first show that learning standard models with this multi-resolution setting improves source separation results over fixed-resolution methods. As study case, we use Non-Negative Matrix Factorizations (NMF) that has been widely considered in many audio application. Then, we investigate the inclusion of the proposed multi-resolution setting into a discriminative training regime. We discuss several alternatives using different deep neural network architectures.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1412.7022v3",
          "authors": [
            "Pablo Sprechmann",
            "Joan Bruna",
            "Yann LeCun"
          ]
        },
        {
          "title": "Deep learning with Elastic Averaging SGD",
          "year": 2014,
          "citations": 0,
          "abstract": "We study the problem of stochastic optimization for deep learning in the parallel computing environment under communication constraints. A new algorithm is proposed in this setting where the communication and coordination of work among concurrent processes (local workers), is based on an elastic force which links the parameters they compute with a center variable stored by the parameter server (master). The algorithm enables the local workers to perform more exploration, i.e. the algorithm allows the local variables to fluctuate further from the center variable by reducing the amount of communication between local workers and the master. We empirically demonstrate that in the deep learning setting, due to the existence of many local optima, allowing more exploration can lead to the improved performance. We propose synchronous and asynchronous variants of the new algorithm. We provide the stability analysis of the asynchronous variant in the round-robin scheme and compare it with the more common parallelized method ADMM. We show that the stability of EASGD is guaranteed when a simple stability condition is satisfied, which is not the case for ADMM. We additionally propose the momentum-based version of our algorithm that can be applied in both synchronous and asynchronous settings. Asynchronous variant of the algorithm is applied to train convolutional neural networks for image classification on the CIFAR and ImageNet datasets. Experiments demonstrate that the new algorithm accelerates the training of deep architectures compared to DOWNPOUR and other common baseline approaches and furthermore is very communication efficient.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1412.6651v8",
          "authors": [
            "Sixin Zhang",
            "Anna Choromanska",
            "Yann LeCun"
          ]
        },
        {
          "title": "Explorations on high dimensional landscapes",
          "year": 2014,
          "citations": 0,
          "abstract": "Finding minima of a real valued non-convex function over a high dimensional space is a major challenge in science. We provide evidence that some such functions that are defined on high dimensional domains have a narrow band of values whose pre-image contains the bulk of its critical points. This is in contrast with the low dimensional picture in which this band is wide. Our simulations agree with the previous theoretical work on spin glasses that proves the existence of such a band when the dimension of the domain tends to infinity. Furthermore our experiments on teacher-student networks with the MNIST dataset establish a similar phenomenon in deep networks. We finally observe that both the gradient descent and the stochastic gradient descent methods can reach this level within the same number of steps.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1412.6615v4",
          "authors": [
            "Levent Sagun",
            "V. Ugur Guney",
            "Gerard Ben Arous",
            "Yann LeCun"
          ]
        },
        {
          "title": "Unsupervised Learning of Spatiotemporally Coherent Metrics",
          "year": 2014,
          "citations": 0,
          "abstract": "Current state-of-the-art classification and detection algorithms rely on supervised training. In this work we study unsupervised feature learning in the context of temporally coherent video data. We focus on feature learning from unlabeled video data, using the assumption that adjacent video frames contain semantically similar information. This assumption is exploited to train a convolutional pooling auto-encoder regularized by slowness and sparsity. We establish a connection between slow feature learning to metric learning and show that the trained encoder can be used to define a more temporally and semantically coherent metric.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1412.6056v6",
          "authors": [
            "Ross Goroshin",
            "Joan Bruna",
            "Jonathan Tompson",
            "David Eigen",
            "Yann LeCun"
          ]
        },
        {
          "title": "The Loss Surfaces of Multilayer Networks",
          "year": 2014,
          "citations": 0,
          "abstract": "We study the connection between the highly non-convex loss function of a simple model of the fully-connected feed-forward neural network and the Hamiltonian of the spherical spin-glass model under the assumptions of: i) variable independence, ii) redundancy in network parametrization, and iii) uniformity. These assumptions enable us to explain the complexity of the fully decoupled neural network through the prism of the results from random matrix theory. We show that for large-size decoupled networks the lowest critical values of the random loss function form a layered structure and they are located in a well-defined band lower-bounded by the global minimum. The number of local minima outside that band diminishes exponentially with the size of the network. We empirically verify that the mathematical model exhibits similar behavior as the computer simulations, despite the presence of high dependencies in real networks. We conjecture that both simulated annealing and SGD converge to the band of low critical points, and that all critical points found there are local minima of high quality measured by the test error. This emphasizes a major difference between large- and small-size networks where for the latter poor quality local minima have non-zero probability of being recovered. Finally, we prove that recovering the global minimum becomes harder as the network size increases and that it is in practice irrelevant as global minimum often leads to overfitting.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1412.0233v3",
          "authors": [
            "Anna Choromanska",
            "Mikael Henaff",
            "Michael Mathieu",
            "Gérard Ben Arous",
            "Yann LeCun"
          ]
        },
        {
          "title": "Efficient Object Localization Using Convolutional Networks",
          "year": 2014,
          "citations": 0,
          "abstract": "Recent state-of-the-art performance on human-body pose estimation has been achieved with Deep Convolutional Networks (ConvNets). Traditional ConvNet architectures include pooling and sub-sampling layers which reduce computational requirements, introduce invariance and prevent over-training. These benefits of pooling come at the cost of reduced localization accuracy. We introduce a novel architecture which includes an efficient `position refinement' model that is trained to estimate the joint offset location within a small region of the image. This refinement model is jointly trained in cascade with a state-of-the-art ConvNet model to achieve improved accuracy in human joint location estimation. We show that the variance of our detector approaches the variance of human annotations on the FLIC dataset and outperforms all existing approaches on the MPII-human-pose dataset.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1411.4280v3",
          "authors": [
            "Jonathan Tompson",
            "Ross Goroshin",
            "Arjun Jain",
            "Yann LeCun",
            "Christopher Bregler"
          ]
        },
        {
          "title": "Differentially- and non-differentially-private random decision trees",
          "year": 2014,
          "citations": 0,
          "abstract": "We consider supervised learning with random decision trees, where the tree construction is completely random. The method is popularly used and works well in practice despite the simplicity of the setting, but its statistical mechanism is not yet well-understood. In this paper we provide strong theoretical guarantees regarding learning with random decision trees. We analyze and compare three different variants of the algorithm that have minimal memory requirements: majority voting, threshold averaging and probabilistic averaging. The random structure of the tree enables us to adapt these methods to a differentially-private setting thus we also propose differentially-private versions of all three schemes. We give upper-bounds on the generalization error and mathematically explain how the accuracy depends on the number of random decision trees. Furthermore, we prove that only logarithmic (in the size of the dataset) number of independently selected random decision trees suffice to correctly classify most of the data, even when differential-privacy guarantees must be maintained. We empirically show that majority voting and threshold averaging give the best accuracy, also for conservative users requiring high privacy guarantees. Furthermore, we demonstrate that a simple majority voting rule is an especially good candidate for the differentially-private classifier since it is much less sensitive to the choice of forest parameters than other methods.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1410.6973v2",
          "authors": [
            "Mariusz Bojarski",
            "Anna Choromanska",
            "Krzysztof Choromanski",
            "Yann LeCun"
          ]
        },
        {
          "title": "MoDeep: A Deep Learning Framework Using Motion Features for Human Pose Estimation",
          "year": 2014,
          "citations": 0,
          "abstract": "In this work, we propose a novel and efficient method for articulated human pose estimation in videos using a convolutional network architecture, which incorporates both color and motion features. We propose a new human body pose dataset, FLIC-motion, that extends the FLIC dataset with additional motion features. We apply our architecture to this dataset and report significantly better performance than current state-of-the-art pose detection systems.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1409.7963v1",
          "authors": [
            "Arjun Jain",
            "Jonathan Tompson",
            "Yann LeCun",
            "Christoph Bregler"
          ]
        },
        {
          "title": "Computing the Stereo Matching Cost with a Convolutional Neural Network",
          "year": 2014,
          "citations": 0,
          "abstract": "We present a method for extracting depth information from a rectified image pair. We train a convolutional neural network to predict how well two image patches match and use it to compute the stereo matching cost. The cost is refined by cross-based cost aggregation and semiglobal matching, followed by a left-right consistency check to eliminate errors in the occluded regions. Our stereo method achieves an error rate of 2.61 % on the KITTI stereo dataset and is currently (August 2014) the top performing method on this dataset.",
          "venue": null,
          "doi": "10.1109/CVPR.2015.7298767",
          "url": "https://arxiv.org/abs/1409.4326v2",
          "authors": [
            "Jure Žbontar",
            "Yann LeCun"
          ]
        },
        {
          "title": "Joint Training of a Convolutional Network and a Graphical Model for Human Pose Estimation",
          "year": 2014,
          "citations": 0,
          "abstract": "This paper proposes a new hybrid architecture that consists of a deep Convolutional Network and a Markov Random Field. We show how this architecture is successfully applied to the challenging problem of articulated human pose estimation in monocular images. The architecture can exploit structural domain constraints such as geometric relationships between body joint locations. We show that joint training of these two model paradigms improves performance and allows us to significantly outperform existing state-of-the-art techniques.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1406.2984v2",
          "authors": [
            "Jonathan Tompson",
            "Arjun Jain",
            "Yann LeCun",
            "Christoph Bregler"
          ]
        },
        {
          "title": "Fast Approximation of Rotations and Hessians matrices",
          "year": 2014,
          "citations": 0,
          "abstract": "A new method to represent and approximate rotation matrices is introduced. The method represents approximations of a rotation matrix $Q$ with linearithmic complexity, i.e. with $\\frac{1}{2}n\\lg(n)$ rotations over pairs of coordinates, arranged in an FFT-like fashion. The approximation is \"learned\" using gradient descent. It allows to represent symmetric matrices $H$ as $QDQ^T$ where $D$ is a diagonal matrix. It can be used to approximate covariance matrix of Gaussian models in order to speed up inference, or to estimate and track the inverse Hessian of an objective function by relating changes in parameters to changes in gradient along the trajectory followed by the optimization procedure. Experiments were conducted to approximate synthetic matrices, covariance matrices of real data, and Hessian matrices of objective functions involved in machine learning problems.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1404.7195v1",
          "authors": [
            "Michael Mathieu",
            "Yann LeCun"
          ]
        },
        {
          "title": "Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation",
          "year": 2014,
          "citations": 0,
          "abstract": "We present techniques for speeding up the test-time evaluation of large convolutional networks, designed for object recognition tasks. These models deliver impressive accuracy but each image evaluation requires millions of floating point operations, making their deployment on smartphones and Internet-scale clusters problematic. The computation is dominated by the convolution operations in the lower layers of the model. We exploit the linear structure present within the convolutional filters to derive approximations that significantly reduce the required computation. Using large state-of-the-art models, we demonstrate we demonstrate speedups of convolutional layers on both CPU and GPU by a factor of 2x, while keeping the accuracy within 1% of the original model.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1404.0736v2",
          "authors": [
            "Remi Denton",
            "Wojciech Zaremba",
            "Joan Bruna",
            "Yann LeCun",
            "Rob Fergus"
          ]
        },
        {
          "title": "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks",
          "year": 2013,
          "citations": 0,
          "abstract": "We present an integrated framework for using Convolutional Networks for classification, localization and detection. We show how a multiscale and sliding window approach can be efficiently implemented within a ConvNet. We also introduce a novel deep learning approach to localization by learning to predict object boundaries. Bounding boxes are then accumulated rather than suppressed in order to increase detection confidence. We show that different tasks can be learned simultaneously using a single shared network. This integrated framework is the winner of the localization task of the ImageNet Large Scale Visual Recognition Challenge 2013 (ILSVRC2013) and obtained very competitive results for the detection and classifications tasks. In post-competition work, we establish a new state of the art for the detection task. Finally, we release a feature extractor from our best model called OverFeat.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1312.6229v4",
          "authors": [
            "Pierre Sermanet",
            "David Eigen",
            "Xiang Zhang",
            "Michael Mathieu",
            "Rob Fergus",
            "Yann LeCun"
          ]
        },
        {
          "title": "Spectral Networks and Locally Connected Networks on Graphs",
          "year": 2013,
          "citations": 0,
          "abstract": "Convolutional Neural Networks are extremely efficient architectures in image and audio recognition tasks, thanks to their ability to exploit the local translational invariance of signal classes over their domain. In this paper we consider possible generalizations of CNNs to signals defined on more general domains without the action of a translation group. In particular, we propose two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian. We show through experiments that for low-dimensional graphs it is possible to learn convolutional layers with a number of parameters independent of the input size, resulting in efficient deep architectures.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1312.6203v3",
          "authors": [
            "Joan Bruna",
            "Wojciech Zaremba",
            "Arthur Szlam",
            "Yann LeCun"
          ]
        },
        {
          "title": "Fast Training of Convolutional Networks through FFTs",
          "year": 2013,
          "citations": 0,
          "abstract": "Convolutional networks are one of the most widely employed architectures in computer vision and machine learning. In order to leverage their ability to learn complex functions, large amounts of data are required for training. Training a large convolutional network to produce state-of-the-art results can take weeks, even when using modern GPUs. Producing labels using a trained network can also be costly when dealing with web-scale datasets. In this work, we present a simple algorithm which accelerates training and inference by a significant factor, and can yield improvements of over an order of magnitude compared to existing state-of-the-art implementations. This is done by computing convolutions as pointwise products in the Fourier domain while reusing the same transformed feature map many times. The algorithm is implemented on a GPU architecture and addresses a number of related challenges.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1312.5851v5",
          "authors": [
            "Michael Mathieu",
            "Mikael Henaff",
            "Yann LeCun"
          ]
        },
        {
          "title": "Understanding Deep Architectures using a Recursive Convolutional Network",
          "year": 2013,
          "citations": 0,
          "abstract": "A key challenge in designing convolutional network models is sizing them appropriately. Many factors are involved in these decisions, including number of layers, feature maps, kernel sizes, etc. Complicating this further is the fact that each of these influence not only the numbers and dimensions of the activation units, but also the total number of parameters. In this paper we focus on assessing the independent contributions of three of these linked variables: The numbers of layers, feature maps, and parameters. To accomplish this, we employ a recursive convolutional network whose weights are tied between layers; this allows us to vary each of the three factors in a controlled setting. We find that while increasing the numbers of layers and parameters each have clear benefit, the number of feature maps (and hence dimensionality of the representation) appears ancillary, and finds most of its benefit through the introduction of more weights. Our results (i) empirically confirm the notion that adding layers alone increases computational power, within the context of convolutional layers, and (ii) suggest that precise sizing of convolutional feature map dimensions is itself of little concern; more attention should be paid to the number of parameters in these layers instead.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1312.1847v2",
          "authors": [
            "David Eigen",
            "Jason Rolfe",
            "Rob Fergus",
            "Yann LeCun"
          ]
        },
        {
          "title": "Signal Recovery from Pooling Representations",
          "year": 2013,
          "citations": 0,
          "abstract": "In this work we compute lower Lipschitz bounds of $\\ell_p$ pooling operators for $p=1, 2, \\infty$ as well as $\\ell_p$ pooling operators preceded by half-rectification layers. These give sufficient conditions for the design of invertible neural network layers. Numerical experiments on MNIST and image patches confirm that pooling layers can be inverted with phase recovery algorithms. Moreover, the regularity of the inverse pooling, controlled by the lower Lipschitz constant, is empirically verified with a nearest neighbor regression.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1311.4025v3",
          "authors": [
            "Joan Bruna",
            "Arthur Szlam",
            "Yann LeCun"
          ]
        },
        {
          "title": "Discriminative Recurrent Sparse Auto-Encoders",
          "year": 2013,
          "citations": 0,
          "abstract": "We present the discriminative recurrent sparse auto-encoder model, comprising a recurrent encoder of rectified linear units, unrolled for a fixed number of iterations, and connected to two linear decoders that reconstruct the input and predict its supervised classification. Training via backpropagation-through-time initially minimizes an unsupervised sparse reconstruction error; the loss function is then augmented with a discriminative term on the supervised classification. The depth implicit in the temporally-unrolled form allows the system to exhibit all the power of deep networks, while substantially reducing the number of trainable parameters.   From an initially unstructured network the hidden units differentiate into categorical-units, each of which represents an input prototype with a well-defined class; and part-units representing deformations of these prototypes. The learned organization of the recurrent encoder is hierarchical: part-units are driven directly by the input, whereas the activity of categorical-units builds up over time through interactions with the part-units. Even using a small number of hidden units per layer, discriminative recurrent sparse auto-encoders achieve excellent performance on MNIST.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1301.3775v4",
          "authors": [
            "Jason Tyler Rolfe",
            "Yann LeCun"
          ]
        },
        {
          "title": "Adaptive learning rates and parallelization for stochastic, sparse, non-smooth gradients",
          "year": 2013,
          "citations": 0,
          "abstract": "Recent work has established an empirically successful framework for adapting learning rates for stochastic gradient descent (SGD). This effectively removes all needs for tuning, while automatically reducing learning rates over time on stationary problems, and permitting learning rates to grow appropriately in non-stationary tasks. Here, we extend the idea in three directions, addressing proper minibatch parallelization, including reweighted updates for sparse or orthogonal gradients, improving robustness on non-smooth loss functions, in the process replacing the diagonal Hessian estimation procedure that may not always be available by a robust finite-difference approximation. The final algorithm integrates all these components, has linear complexity and is hyper-parameter free.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1301.3764v2",
          "authors": [
            "Tom Schaul",
            "Yann LeCun"
          ]
        },
        {
          "title": "Saturating Auto-Encoders",
          "year": 2013,
          "citations": 0,
          "abstract": "We introduce a simple new regularizer for auto-encoders whose hidden-unit activation functions contain at least one zero-gradient (saturated) region. This regularizer explicitly encourages activations in the saturated region(s) of the corresponding activation function. We call these Saturating Auto-Encoders (SATAE). We show that the saturation regularizer explicitly limits the SATAE's ability to reconstruct inputs which are not near the data manifold. Furthermore, we show that a wide variety of features can be learned when different activation functions are used. Finally, connections are established with the Contractive and Sparse Auto-Encoders.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1301.3577v3",
          "authors": [
            "Rostislav Goroshin",
            "Yann LeCun"
          ]
        },
        {
          "title": "Indoor Semantic Segmentation using depth information",
          "year": 2013,
          "citations": 0,
          "abstract": "This work addresses multi-class segmentation of indoor scenes with RGB-D inputs. While this area of research has gained much attention recently, most works still rely on hand-crafted features. In contrast, we apply a multiscale convolutional network to learn features directly from the images and the depth information. We obtain state-of-the-art on the NYU-v2 depth dataset with an accuracy of 64.5%. We illustrate the labeling of indoor scenes in videos sequences that could be processed in real-time using appropriate hardware such as an FPGA.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1301.3572v2",
          "authors": [
            "Camille Couprie",
            "Clément Farabet",
            "Laurent Najman",
            "Yann LeCun"
          ]
        },
        {
          "title": "Learning Stable Group Invariant Representations with Convolutional Networks",
          "year": 2013,
          "citations": 0,
          "abstract": "Transformation groups, such as translations or rotations, effectively express part of the variability observed in many recognition problems. The group structure enables the construction of invariant signal representations with appealing mathematical properties, where convolutions, together with pooling operators, bring stability to additive and geometric perturbations of the input. Whereas physical transformation groups are ubiquitous in image and audio applications, they do not account for all the variability of complex signal classes.   We show that the invariance properties built by deep convolutional networks can be cast as a form of stable group invariance. The network wiring architecture determines the invariance group, while the trainable filter coefficients characterize the group action. We give explanatory examples which illustrate how the network architecture controls the resulting invariance group. We also explore the principle by which additional convolutional layers induce a group factorization enabling more abstract, powerful invariant representations.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1301.3537v1",
          "authors": [
            "Joan Bruna",
            "Arthur Szlam",
            "Yann LeCun"
          ]
        },
        {
          "title": "Pushing Stochastic Gradient towards Second-Order Methods -- Backpropagation Learning with Transformations in Nonlinearities",
          "year": 2013,
          "citations": 0,
          "abstract": "Recently, we proposed to transform the outputs of each hidden neuron in a multi-layer perceptron network to have zero output and zero slope on average, and use separate shortcut connections to model the linear dependencies instead. We continue the work by firstly introducing a third transformation to normalize the scale of the outputs of each hidden neuron, and secondly by analyzing the connections to second order optimization methods. We show that the transformations make a simple stochastic gradient behave closer to second-order optimization methods and thus speed up learning. This is shown both in theory and with experiments. The experiments on the third transformation show that while it further increases the speed of learning, it can also hurt performance by converging to a worse local optimum, where both the inputs and outputs of many hidden neurons are close to zero.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1301.3476v3",
          "authors": [
            "Tommi Vatanen",
            "Tapani Raiko",
            "Harri Valpola",
            "Yann LeCun"
          ]
        },
        {
          "title": "Causal graph-based video segmentation",
          "year": 2013,
          "citations": 0,
          "abstract": "Numerous approaches in image processing and computer vision are making use of super-pixels as a pre-processing step. Among the different methods producing such over-segmentation of an image, the graph-based approach of Felzenszwalb and Huttenlocher is broadly employed. One of its interesting properties is that the regions are computed in a greedy manner in quasi-linear time. The algorithm may be trivially extended to video segmentation by considering a video as a 3D volume, however, this can not be the case for causal segmentation, when subsequent frames are unknown. We propose an efficient video segmentation approach that computes temporally consistent pixels in a causal manner, filling the need for causal and real time applications.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1301.1671v1",
          "authors": [
            "Camille Couprie",
            "Clément Farabet",
            "Yann LeCun"
          ]
        },
        {
          "title": "Pedestrian Detection with Unsupervised Multi-Stage Feature Learning",
          "year": 2012,
          "citations": 0,
          "abstract": "Pedestrian detection is a problem of considerable practical interest. Adding to the list of successful applications of deep learning methods to vision, we report state-of-the-art and competitive results on all major pedestrian datasets with a convolutional network model. The model uses a few new twists, such as multi-stage features, connections that skip layers to integrate global shape information with local distinctive motif information, and an unsupervised method based on convolutional sparse coding to pre-train the filters at each stage.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1212.0142v2",
          "authors": [
            "Pierre Sermanet",
            "Koray Kavukcuoglu",
            "Soumith Chintala",
            "Yann LeCun"
          ]
        },
        {
          "title": "No More Pesky Learning Rates",
          "year": 2012,
          "citations": 0,
          "abstract": "The performance of stochastic gradient descent (SGD) depends critically on how learning rates are tuned and decreased over time. We propose a method to automatically adjust multiple learning rates so as to minimize the expected error at any one time. The method relies on local gradient variations across samples. In our approach, learning rates can increase as well as decrease, making it suitable for non-stationary problems. Using a number of convex and non-convex learning tasks, we show that the resulting algorithm matches the performance of SGD or other adaptive approaches with their best settings obtained through systematic search, and effectively removes the need for learning rate tuning.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1206.1106v2",
          "authors": [
            "Tom Schaul",
            "Sixin Zhang",
            "Yann LeCun"
          ]
        },
        {
          "title": "Convolutional Neural Networks Applied to House Numbers Digit Classification",
          "year": 2012,
          "citations": 0,
          "abstract": "We classify digits of real-world house numbers using convolutional neural networks (ConvNets). ConvNets are hierarchical feature learning neural networks whose structure is biologically inspired. Unlike many popular vision approaches that are hand-designed, ConvNets can automatically learn a unique set of features optimized for a given task. We augmented the traditional ConvNet architecture by learning multi-stage features and by using Lp pooling and establish a new state-of-the-art of 94.85% accuracy on the SVHN dataset (45.2% error improvement). Furthermore, we analyze the benefits of different pooling methods and multi-stage features in ConvNets. The source code and a tutorial are available at eblearn.sf.net.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1204.3968v1",
          "authors": [
            "Pierre Sermanet",
            "Soumith Chintala",
            "Yann LeCun"
          ]
        },
        {
          "title": "Fast approximations to structured sparse coding and applications to object classification",
          "year": 2012,
          "citations": 0,
          "abstract": "We describe a method for fast approximation of sparse coding. The input space is subdivided by a binary decision tree, and we simultaneously learn a dictionary and assignment of allowed dictionary elements for each leaf of the tree. We store a lookup table with the assignments and the pseudoinverses for each node, allowing for very fast inference. We give an algorithm for learning the tree, the dictionary and the dictionary element assignment, and In the process of describing this algorithm, we discuss the more general problem of learning the groups in group structured sparse modelling. We show that our method creates good sparse representations by using it in the object recognition framework of \\cite{lazebnik06,yang-cvpr-09}. Implementing our own fast version of the SIFT descriptor the whole system runs at 20 frames per second on $321 \\times 481$ sized images on a laptop with a quad-core cpu, while sacrificing very little accuracy on the Caltech 101 and 15 scenes benchmarks.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1202.6384v1",
          "authors": [
            "Arthur Szlam",
            "Karol Gregor",
            "Yann LeCun"
          ]
        },
        {
          "title": "Scene Parsing with Multiscale Feature Learning, Purity Trees, and Optimal Covers",
          "year": 2012,
          "citations": 0,
          "abstract": "Scene parsing, or semantic segmentation, consists in labeling each pixel in an image with the category of the object it belongs to. It is a challenging task that involves the simultaneous detection, segmentation and recognition of all the objects in the image.   The scene parsing method proposed here starts by computing a tree of segments from a graph of pixel dissimilarities. Simultaneously, a set of dense feature vectors is computed which encodes regions of multiple sizes centered on each pixel. The feature extractor is a multiscale convolutional network trained from raw pixels. The feature vectors associated with the segments covered by each node in the tree are aggregated and fed to a classifier which produces an estimate of the distribution of object categories contained in the segment. A subset of tree nodes that cover the image are then selected so as to maximize the average \"purity\" of the class distributions, hence maximizing the overall likelihood that each segment will contain a single object. The convolutional network feature extractor is trained end-to-end from raw pixels, alleviating the need for engineered features. After training, the system is parameter free.   The system yields record accuracies on the Stanford Background Dataset (8 classes), the Sift Flow Dataset (33 classes) and the Barcelona Dataset (170 classes) while being an order of magnitude faster than competing approaches, producing a 320 \\times 240 image labeling in less than 1 second.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1202.2160v2",
          "authors": [
            "Clément Farabet",
            "Camille Couprie",
            "Laurent Najman",
            "Yann LeCun"
          ]
        },
        {
          "title": "Learning Representations by Maximizing Compression",
          "year": 2011,
          "citations": 0,
          "abstract": "We give an algorithm that learns a representation of data through compression. The algorithm 1) predicts bits sequentially from those previously seen and 2) has a structure and a number of computations similar to an autoencoder. The likelihood under the model can be calculated exactly, and arithmetic coding can be used directly for compression. When training on digits the algorithm learns filters similar to those of restricted boltzman machines and denoising autoencoders. Independent samples can be drawn from the model by a single sweep through the pixels. The algorithm has a good compression performance when compared to other methods that work under random ordering of pixels.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1108.1169v1",
          "authors": [
            "Karol Gregor",
            "Yann LeCun"
          ]
        },
        {
          "title": "Efficient Learning of Sparse Invariant Representations",
          "year": 2011,
          "citations": 0,
          "abstract": "We propose a simple and efficient algorithm for learning sparse invariant representations from unlabeled data with fast inference. When trained on short movies sequences, the learned features are selective to a range of orientations and spatial frequencies, but robust to a wide range of positions, similar to complex cells in the primary visual cortex. We give a hierarchical version of the algorithm, and give guarantees of fast convergence under certain conditions.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1105.5307v1",
          "authors": [
            "Karol Gregor",
            "Yann LeCun"
          ]
        },
        {
          "title": "Fast Inference in Sparse Coding Algorithms with Applications to Object Recognition",
          "year": 2010,
          "citations": 0,
          "abstract": "Adaptive sparse coding methods learn a possibly overcomplete set of basis functions, such that natural image patches can be reconstructed by linearly combining a small subset of these bases. The applicability of these methods to visual object recognition tasks has been limited because of the prohibitive cost of the optimization algorithms required to compute the sparse representation. In this work we propose a simple and efficient algorithm to learn basis functions. After training, this model also provides a fast and smooth approximator to the optimal representation, achieving even better accuracy than exact sparse coding algorithms on visual object recognition tasks.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1010.3467v1",
          "authors": [
            "Koray Kavukcuoglu",
            "Marc'Aurelio Ranzato",
            "Yann LeCun"
          ]
        },
        {
          "title": "Convolutional Matching Pursuit and Dictionary Training",
          "year": 2010,
          "citations": 0,
          "abstract": "Matching pursuit and K-SVD is demonstrated in the translation invariant setting",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1010.0422v1",
          "authors": [
            "Arthur Szlam",
            "Koray Kavukcuoglu",
            "Yann LeCun"
          ]
        },
        {
          "title": "Emergence of Complex-Like Cells in a Temporal Product Network with Local Receptive Fields",
          "year": 2010,
          "citations": 0,
          "abstract": "We introduce a new neural architecture and an unsupervised algorithm for learning invariant representations from temporal sequence of images. The system uses two groups of complex cells whose outputs are combined multiplicatively: one that represents the content of the image, constrained to be constant over several consecutive frames, and one that represents the precise location of features, which is allowed to vary over time but constrained to be sparse. The architecture uses an encoder to extract features, and a decoder to reconstruct the input from the features. The method was applied to patches extracted from consecutive movie frames and produces orientation and frequency selective units analogous to the complex cells in V1. An extension of the method is proposed to train a network composed of units with local receptive field spread over a large image of arbitrary size. A layer of complex cells, subject to sparsity constraints, pool feature units over overlapping local neighborhoods, which causes the feature units to organize themselves into pinwheel patterns of orientation-selective receptive fields, similar to those observed in the mammalian visual cortex. A feed-forward encoder efficiently computes the feature representation of full images.",
          "venue": null,
          "doi": null,
          "url": "https://arxiv.org/abs/1006.0448v1",
          "authors": [
            "Karo Gregor",
            "Yann LeCun"
          ]
        }
      ],
      "top_coauthors": [
        {
          "name": "Randall Balestriero",
          "collaborations": 21
        },
        {
          "name": "Ravid Shwartz-Ziv",
          "collaborations": 17
        },
        {
          "name": "Yubei Chen",
          "collaborations": 12
        },
        {
          "name": "Joan Bruna",
          "collaborations": 11
        },
        {
          "name": "Adrien Bardes",
          "collaborations": 10
        },
        {
          "name": "Michael Mathieu",
          "collaborations": 10
        },
        {
          "name": "Quentin Garrido",
          "collaborations": 9
        },
        {
          "name": "Arthur Szlam",
          "collaborations": 9
        },
        {
          "name": "Shengbang Tong",
          "collaborations": 8
        },
        {
          "name": "Nicolas Ballas",
          "collaborations": 8
        }
      ]
    },
    "semantic_scholar": {
      "name": "Yann LeCun",
      "source": "semantic_scholar",
      "source_id": "1688882",
      "affiliation": "Facebook",
      "orcid": null,
      "homepage": null,
      "interests": [],
      "metrics": {
        "citations": 259193,
        "citations_recent": 0,
        "h_index": 137,
        "h_index_recent": 0,
        "i10_index": 0,
        "publication_count": 405
      },
      "citations_per_year": {},
      "publications_per_year": {
        "2024": 2,
        "2023": 22,
        "2022": 32,
        "2021": 15,
        "2020": 3,
        "2019": 8,
        "2018": 13,
        "2017": 15,
        "2016": 19,
        "2015": 22,
        "2014": 18,
        "2013": 24,
        "2012": 22,
        "2011": 12,
        "2010": 20,
        "2009": 15,
        "2008": 11,
        "2007": 17,
        "2006": 10,
        "2005": 6,
        "2004": 2,
        "2003": 1,
        "2002": 2,
        "2001": 3,
        "2000": 2,
        "1999": 4,
        "1998": 12,
        "1997": 5,
        "1996": 2,
        "1995": 4,
        "1994": 10,
        "1993": 8,
        "1992": 10,
        "1991": 7,
        "1990": 8,
        "1989": 7,
        "1988": 4,
        "1987": 3,
        "1986": 1,
        "1985": 1,
        "1977": 1
      },
      "first_publication_year": 1977,
      "last_publication_year": 2024,
      "years_active": 47,
      "publications": [
        {
          "title": "FAST INCREMENTAL LEARNING FOR AUTONOMOUS GROUND NAVIGATION",
          "year": 2024,
          "citations": 0,
          "abstract": "\n ABSTRACT \n A promising approach to autonomous driving is machine learning. In machine \n learning systems, training datasets are created that capture the sensory input \n to a vehicle as well as the desired response. One disadvantage of using a \n learned navigation system is that the learning process itself may require both a \n huge number of training examples and a large amount of computing. To avoid the \n need to collect a large training set of driving examples, we describe a system \n that takes advantage of the immense number of training examples provided by \n ImageNet, but at the same time is able to adapt quickly using a small training \n set for the driving environment. \n",
          "venue": "SAE technical paper series",
          "doi": "10.4271/2024-01-3556",
          "url": "https://www.semanticscholar.org/paper/4c4d882c3e54612946d289fd159da8de98fb3200",
          "authors": [
            "Artem Provodin",
            "L. Torabi",
            "Urs Muller",
            "B. Flepp",
            "Michael Sergio",
            "Jure Zbontar",
            "Yann LeCun",
            "L. Jackel"
          ]
        },
        {
          "title": "Learning and Leveraging World Models in Visual Representation Learning",
          "year": 2024,
          "citations": 48,
          "abstract": "Joint-Embedding Predictive Architecture (JEPA) has emerged as a promising self-supervised approach that learns by leveraging a world model. While previously limited to predicting missing parts of an input, we explore how to generalize the JEPA prediction task to a broader set of corruptions. We introduce Image World Models, an approach that goes beyond masked image modeling and learns to predict the effect of global photometric transformations in latent space. We study the recipe of learning performant IWMs and show that it relies on three key aspects: conditioning, prediction difficulty, and capacity. Additionally, we show that the predictive world model learned by IWM can be adapted through finetuning to solve diverse tasks; a fine-tuned IWM world model matches or surpasses the performance of previous self-supervised methods. Finally, we show that learning with an IWM allows one to control the abstraction level of the learned representations, learning invariant representations such as contrastive methods, or equivariant representations such as masked image modelling.",
          "venue": "arXiv.org",
          "doi": "10.48550/arXiv.2403.00504",
          "url": "https://www.semanticscholar.org/paper/4d1eadaa9a04e86aef2278ae13eb9fce644c9fc5",
          "authors": [
            "Q. Garrido",
            "Mahmoud Assran",
            "Nicolas Ballas",
            "Adrien Bardes",
            "Laurent Najman",
            "Yann LeCun"
          ]
        },
        {
          "title": "The SSL Interplay: Augmentations, Inductive Bias, and Generalization",
          "year": 2023,
          "citations": 41,
          "abstract": "Self-supervised learning (SSL) has emerged as a powerful framework to learn representations from raw data without supervision. Yet in practice, engineers face issues such as instability in tuning optimizers and collapse of representations during training. Such challenges motivate the need for a theory to shed light on the complex interplay between the choice of data augmentation, network architecture, and training algorithm. We study such an interplay with a precise analysis of generalization performance on both pretraining and downstream tasks in a theory friendly setup, and highlight several insights for SSL practitioners that arise from our theory.",
          "venue": "International Conference on Machine Learning",
          "doi": "10.48550/arXiv.2302.02774",
          "url": "https://www.semanticscholar.org/paper/034081ba8bd12b9466414fce3e885451a92b075a",
          "authors": [
            "Vivien A. Cabannes",
            "B. Kiani",
            "Randall Balestriero",
            "Yann LeCun",
            "A. Bietti"
          ]
        },
        {
          "title": "Minimalistic Unsupervised Representation Learning with the Sparse Manifold Transform",
          "year": 2023,
          "citations": 5,
          "abstract": null,
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/0380271e23c5a3348f9f8ad1906b692b22f8b75e",
          "authors": [
            "Yubei Chen",
            "Zeyu Yun",
            "Yi Ma",
            "B. Olshausen",
            "Yann LeCun"
          ]
        },
        {
          "title": "Self-supervised learning of Split Invariant Equivariant representations",
          "year": 2023,
          "citations": 39,
          "abstract": "Recent progress has been made towards learning invariant or equivariant representations with self-supervised learning. While invariant methods are evaluated on large scale datasets, equivariant ones are evaluated in smaller, more controlled, settings. We aim at bridging the gap between the two in order to learn more diverse representations that are suitable for a wide range of tasks. We start by introducing a dataset called 3DIEBench, consisting of renderings from 3D models over 55 classes and more than 2.5 million images where we have full control on the transformations applied to the objects. We further introduce a predictor architecture based on hypernetworks to learn equivariant representations with no possible collapse to invariance. We introduce SIE (Split Invariant-Equivariant) which combines the hypernetwork-based predictor with representations split in two parts, one invariant, the other equivariant, to learn richer representations. We demonstrate significant performance gains over existing methods on equivariance related tasks from both a qualitative and quantitative point of view. We further analyze our introduced predictor and show how it steers the learned latent space. We hope that both our introduced dataset and approach will enable learning richer representations without supervision in more complex scenarios. Code and data are available at https://github.com/facebookresearch/SIE.",
          "venue": "International Conference on Machine Learning",
          "doi": "10.48550/arXiv.2302.10283",
          "url": "https://www.semanticscholar.org/paper/10923e416d15ab36161f4ab9ad40aa15bb91f541",
          "authors": [
            "Q. Garrido",
            "Laurent Najman",
            "Yann LeCun"
          ]
        },
        {
          "title": "Fast and Exact Enumeration of Deep Networks Partitions Regions",
          "year": 2023,
          "citations": 5,
          "abstract": "One fruitful formulation of Deep Networks (DNs) enabling their theoretical study and providing practical guidelines to practitioners relies on Piecewise Affine Splines. In that realm, a DN’s input-mapping is expressed as per-region affine map-ping where those regions are implicitly determined by the model’s architecture and form a partition of their input space. That partition –which is involved in all the results spanned from this line of research– has so far only been computed on 2/3-dimensional slices of the DN’s input space or estimated by random sampling. In this paper, we provide the first parallel algorithm that does exact enumeration of the DN’s partition regions. The proposed algorithm enables one to finally assess the closeness of the commonly employed approximations methods, e.g. based on random sampling of the DN input space. One of our key finding is that if one is only interested in regions with \"large\" volume, then uniform sampling of the space is highly efficient, but that if one is also interested in discovering the \"small\" regions of the partition, then uniform sampling is exponentially costly with the DN’s input space dimension. On the other hand, our proposed method has complexity scaling linearly with input dimension and the number of regions.",
          "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
          "doi": "10.1109/icassp49357.2023.10095698",
          "url": "https://www.semanticscholar.org/paper/132606b0fc37bd2a9f50d3199f29b8b2defbcb93",
          "authors": [
            "Randall Balestriero",
            "Yann LeCun"
          ]
        },
        {
          "title": "Active Self-Supervised Learning: A Few Low-Cost Relationships Are All You Need",
          "year": 2023,
          "citations": 14,
          "abstract": "Self-Supervised Learning (SSL) has emerged as the solution of choice to learn transferable representations from unlabeled data. However, SSL requires to build samples that are known to be semantically akin, i.e. positive views. Requiring such knowledge is the main limitation of SSL and is often tackled by ad-hoc strategies e.g. applying known data-augmentations to the same input. In this work, we formalize and generalize this principle through Positive Active Learning (PAL) where an oracle queries semantic relationships between samples. PAL achieves three main objectives. First, it unveils a theoretically grounded learning framework beyond SSL, based on similarity graphs, that can be extended to tackle supervised and semi-supervised learning depending on the employed oracle. Second, it provides a consistent algorithm to embed a priori knowledge, e.g. some observed labels, into any SSL losses without any change in the training pipeline. Third, it provides a proper active learning framework yielding low-cost solutions to annotate datasets, arguably bringing the gap between theory and practice of active learning that is based on simple-to-answer-by-non-experts queries of semantic relationships between inputs.",
          "venue": "IEEE International Conference on Computer Vision",
          "doi": "10.1109/ICCV51070.2023.01491",
          "url": "https://www.semanticscholar.org/paper/138fa5f64fe54376022998fe553b6156a93ff19e",
          "authors": [
            "Vivien A. Cabannes",
            "L. Bottou",
            "Yann LeCun",
            "Randall Balestriero"
          ]
        },
        {
          "title": "An Information-Theoretic Perspective on Variance-Invariance-Covariance Regularization",
          "year": 2023,
          "citations": 26,
          "abstract": "Variance-Invariance-Covariance Regularization (VICReg) is a self-supervised learning (SSL) method that has shown promising results on a variety of tasks. However, the fundamental mechanisms underlying VICReg remain unexplored. In this paper, we present an information-theoretic perspective on the VICReg objective. We begin by deriving information-theoretic quantities for deterministic networks as an alternative to unrealistic stochastic network assumptions. We then relate the optimization of the VICReg objective to mutual information optimization, highlighting underlying assumptions and facilitating a constructive comparison with other SSL algorithms and derive a generalization bound for VICReg, revealing its inherent advantages for downstream tasks. Building on these results, we introduce a family of SSL methods derived from information-theoretic principles that outperform existing SSL techniques.",
          "venue": "arXiv.org",
          "doi": "10.48550/arXiv.2303.00633",
          "url": "https://www.semanticscholar.org/paper/1ea4f4dcedbbe6d10aad30c3cb02fe2b0572b090",
          "authors": [
            "Ravid Shwartz-Ziv",
            "Randall Balestriero",
            "Kenji Kawaguchi",
            "Tim G. J. Rudner",
            "Yann LeCun"
          ]
        },
        {
          "title": "Augmented Language Models: a Survey",
          "year": 2023,
          "citations": 467,
          "abstract": "This survey reviews works in which language models (LMs) are augmented with reasoning skills and the ability to use tools. The former is defined as decomposing a potentially complex task into simpler subtasks while the latter consists in calling external modules such as a code interpreter. LMs can leverage these augmentations separately or in combination via heuristics, or learn to do so from demonstrations. While adhering to a standard missing tokens prediction objective, such augmented LMs can use various, possibly non-parametric external modules to expand their context processing ability, thus departing from the pure language modeling paradigm. We therefore refer to them as Augmented Language Models (ALMs). The missing token objective allows ALMs to learn to reason, use tools, and even act, while still performing standard natural language tasks and even outperforming most regular LMs on several benchmarks. In this work, after reviewing current advance in ALMs, we conclude that this new research direction has the potential to address common limitations of traditional LMs such as interpretability, consistency, and scalability issues.",
          "venue": "Trans. Mach. Learn. Res.",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/2029349c55c1dba3493c5b3bd25152f18ba21ae2",
          "authors": [
            "G. Mialon",
            "Roberto Dessì",
            "M. Lomeli",
            "Christoforos Nalmpantis",
            "Ramakanth Pasunuru",
            "R. Raileanu",
            "Baptiste Rozière",
            "Timo Schick",
            "Jane Dwivedi-Yu",
            "Asli Celikyilmaz",
            "Edouard Grave",
            "Yann LeCun",
            "Thomas Scialom"
          ]
        },
        {
          "title": "Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning",
          "year": 2023,
          "citations": 120,
          "abstract": "Representation learning on text-attributed graphs (TAGs) has become a critical research problem in recent years. A typical example of a TAG is a paper citation graph, where the text of each paper serves as node attributes. Initial graph neural network (GNN) pipelines handled these text attributes by transforming them into shallow or hand-crafted features, such as skip-gram or bag-of-words features. Recent efforts have focused on enhancing these pipelines with language models (LMs), which typically demand intricate designs and substantial computational resources. With the advent of powerful large language models (LLMs) such as GPT or Llama2, which demonstrate an ability to reason and to utilize general knowledge, there is a growing need for techniques which combine the textual modelling abilities of LLMs with the structural learning capabilities of GNNs. Hence, in this work, we focus on leveraging LLMs to capture textual information as features, which can be used to boost GNN performance on downstream tasks. A key innovation is our use of explanations as features: we prompt an LLM to perform zero-shot classification, request textual explanations for its decision-making process, and design an LLM-to-LM interpreter to translate these explanations into informative features for downstream GNNs. Our experiments demonstrate that our method achieves state-of-the-art results on well-established TAG datasets, including Cora, PubMed, ogbn-arxiv, as well as our newly introduced dataset, tape-arxiv23. Furthermore, our method significantly speeds up training, achieving a 2.88 times improvement over the closest baseline on ogbn-arxiv. Lastly, we believe the versatility of the proposed method extends beyond TAGs and holds the potential to enhance other tasks involving graph-text data. Our codes and datasets are available at: https://github.com/XiaoxinHe/TAPE.",
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/2d2b05f0969568ac3fd3c2cca5df04c4136c5416",
          "authors": [
            "Xiaoxin He",
            "X. Bresson",
            "T. Laurent",
            "Adam Perold",
            "Yann LeCun",
            "Bryan Hooi"
          ]
        },
        {
          "title": "MC-JEPA: A Joint-Embedding Predictive Architecture for Self-Supervised Learning of Motion and Content Features",
          "year": 2023,
          "citations": 36,
          "abstract": "Self-supervised learning of visual representations has been focusing on learning content features, which do not capture object motion or location, and focus on identifying and differentiating objects in images and videos. On the other hand, optical flow estimation is a task that does not involve understanding the content of the images on which it is estimated. We unify the two approaches and introduce MC-JEPA, a joint-embedding predictive architecture and self-supervised learning approach to jointly learn optical flow and content features within a shared encoder, demonstrating that the two associated objectives; the optical flow estimation objective and the self-supervised learning objective; benefit from each other and thus learn content features that incorporate motion information. The proposed approach achieves performance on-par with existing unsupervised optical flow benchmarks, as well as with common self-supervised learning approaches on downstream tasks such as semantic segmentation of images and videos.",
          "venue": "arXiv.org",
          "doi": "10.48550/arXiv.2307.12698",
          "url": "https://www.semanticscholar.org/paper/3c1e43b7d3f5fd42a06c65e3aafe6d8f4a606d5c",
          "authors": [
            "Adrien Bardes",
            "J. Ponce",
            "Yann LeCun"
          ]
        },
        {
          "title": "EMP-SSL: Towards Self-Supervised Learning in One Training Epoch",
          "year": 2023,
          "citations": 29,
          "abstract": "Recently, self-supervised learning (SSL) has achieved tremendous success in learning image representation. Despite the empirical success, most self-supervised learning methods are rather\"inefficient\"learners, typically taking hundreds of training epochs to fully converge. In this work, we show that the key towards efficient self-supervised learning is to increase the number of crops from each image instance. Leveraging one of the state-of-the-art SSL method, we introduce a simplistic form of self-supervised learning method called Extreme-Multi-Patch Self-Supervised-Learning (EMP-SSL) that does not rely on many heuristic techniques for SSL such as weight sharing between the branches, feature-wise normalization, output quantization, and stop gradient, etc, and reduces the training epochs by two orders of magnitude. We show that the proposed method is able to converge to 85.1% on CIFAR-10, 58.5% on CIFAR-100, 38.1% on Tiny ImageNet and 58.5% on ImageNet-100 in just one epoch. Furthermore, the proposed method achieves 91.5% on CIFAR-10, 70.1% on CIFAR-100, 51.5% on Tiny ImageNet and 78.9% on ImageNet-100 with linear probing in less than ten training epochs. In addition, we show that EMP-SSL shows significantly better transferability to out-of-domain datasets compared to baseline SSL methods. We will release the code in https://github.com/tsb0601/EMP-SSL.",
          "venue": "arXiv.org",
          "doi": "10.48550/arXiv.2304.03977",
          "url": "https://www.semanticscholar.org/paper/5367ca1c122a0806549e484fb488a977b4334777",
          "authors": [
            "Shengbang Tong",
            "Yubei Chen",
            "Y. Ma",
            "Yann LeCun"
          ]
        },
        {
          "title": "Self-Supervised Learning with Lie Symmetries for Partial Differential Equations",
          "year": 2023,
          "citations": 28,
          "abstract": "Machine learning for differential equations paves the way for computationally efficient alternatives to numerical solvers, with potentially broad impacts in science and engineering. Though current algorithms typically require simulated training data tailored to a given setting, one may instead wish to learn useful information from heterogeneous sources, or from real dynamical systems observations that are messy or incomplete. In this work, we learn general-purpose representations of PDEs from heterogeneous data by implementing joint embedding methods for self-supervised learning (SSL), a framework for unsupervised representation learning that has had notable success in computer vision. Our representation outperforms baseline approaches to invariant tasks, such as regressing the coefficients of a PDE, while also improving the time-stepping performance of neural solvers. We hope that our proposed methodology will prove useful in the eventual development of general-purpose foundation models for PDEs. Code: https://github.com/facebookresearch/SSLForPDEs.",
          "venue": "Neural Information Processing Systems",
          "doi": "10.48550/arXiv.2307.05432",
          "url": "https://www.semanticscholar.org/paper/5dc01119b2e4911b0c1ae61233e36efe78588aed",
          "authors": [
            "G. Mialon",
            "Q. Garrido",
            "Hannah Lawrence",
            "Danyal Rehman",
            "Yann LeCun",
            "B. Kiani"
          ]
        },
        {
          "title": "Adapting Grounded Visual Question Answering Models to Low Resource Languages",
          "year": 2023,
          "citations": 4,
          "abstract": "While huge progress has been made on a variety of vision and language tasks in recent years, most major advances have been restricted to the English language due to the scarcity of relevant training and evaluation datasets in other languages. A popular approach to address this gap, has been to utilize machine-translated multi-modal datasets or multi-lingual text-only datasets for pre-training. This approach not only fails to exploit existing pre-trained state-of-the-art English multi-modal models, but also is not a viable solution for low-resource languages where translation quality is not as reliable. Therefore, we propose xMDETR, a multi-lingual grounded vision-language model based on the state-of-the-art model MDETR, by adapting it to new languages without machine-translated data, while also keeping most of the pre-trained weights frozen. xMDETR leverages mono-lingual pre-trained MDETR to achieve results competitive to state of the art on xGQA, a standard multilingual VQA benchmark. It is also interpretable, providing bounding boxes for key phrases in the multi-lingual questions. Our method utilizes several architectural as well as data-driven techniques such as training a new embedding space with a Masked Language Modeling (MLM) objective, code-switching, and adapters for efficient and modular training. We also explore contrastive losses to enforce the bridging of multi-modal and multi-lingual representations on multi-lingual multi-modal data, when available. We evaluate xMDETR on xGQA in both zero-shot and few-shot settings, improving results on Portuguese, Indonesian and Bengali, while remaining competitive on other languages.",
          "venue": "2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)",
          "doi": "10.1109/CVPRW59228.2023.00258",
          "url": "https://www.semanticscholar.org/paper/6be0cf37d8b05c1b8fb4235217895b3bf1b6c368",
          "authors": [
            "Y. Wang",
            "Jonas Pfeiffer",
            "Nicolas Carion",
            "Yann LeCun",
            "Aishwarya Kamath"
          ]
        },
        {
          "title": "A Cookbook of Self-Supervised Learning",
          "year": 2023,
          "citations": 348,
          "abstract": "Self-supervised learning, dubbed the dark matter of intelligence, is a promising path to advance machine learning. Yet, much like cooking, training SSL methods is a delicate art with a high barrier to entry. While many components are familiar, successfully training a SSL method involves a dizzying set of choices from the pretext tasks to training hyper-parameters. Our goal is to lower the barrier to entry into SSL research by laying the foundations and latest SSL recipes in the style of a cookbook. We hope to empower the curious researcher to navigate the terrain of methods, understand the role of the various knobs, and gain the know-how required to explore how delicious SSL can be.",
          "venue": "arXiv.org",
          "doi": "10.48550/arXiv.2304.12210",
          "url": "https://www.semanticscholar.org/paper/6bfafb32b423c3f0456a10984814f89046def489",
          "authors": [
            "Randall Balestriero",
            "Mark Ibrahim",
            "Vlad Sobal",
            "Ari S. Morcos",
            "Shashank Shekhar",
            "T. Goldstein",
            "Florian Bordes",
            "Adrien Bardes",
            "G. Mialon",
            "Yuandong Tian",
            "Avi Schwarzschild",
            "A. Wilson",
            "Jonas Geiping",
            "Q. Garrido",
            "Pierre Fernandez",
            "Amir Bar",
            "H. Pirsiavash",
            "Yann LeCun",
            "Micah Goldblum"
          ]
        },
        {
          "title": "URLOST: Unsupervised Representation Learning without Stationarity or Topology",
          "year": 2023,
          "citations": 1,
          "abstract": "Unsupervised representation learning has seen tremendous progress. However, it is constrained by its reliance on domain specific stationarity and topology, a limitation not found in biological intelligence systems. For instance, unlike computer vision, human vision can process visual signals sampled from highly irregular and non-stationary sensors. We introduce a novel framework that learns from high-dimensional data without prior knowledge of stationarity and topology. Our model, abbreviated as URLOST, combines a learnable self-organizing layer, spectral clustering, and a masked autoencoder (MAE). We evaluate its effectiveness on three diverse data modalities including simulated biological vision data, neural recordings from the primary visual cortex, and gene expressions. Compared to state-of-the-art unsupervised learning methods like SimCLR and MAE, our model excels at learning meaningful representations across diverse modalities without knowing their stationarity or topology. It also outperforms other methods that are not dependent on these factors, setting a new benchmark in the field. We position this work as a step toward unsupervised learning methods capable of generalizing across diverse high-dimensional data modalities.",
          "venue": "International Conference on Learning Representations",
          "doi": "10.48550/arXiv.2310.04496",
          "url": "https://www.semanticscholar.org/paper/782d400ba7aac6ccb2d4b6d3cadbf4b7c2600d50",
          "authors": [
            "Zeyu Yun",
            "Juexiao Zhang",
            "B. Olshausen",
            "Yann LeCun",
            "Yubei Chen"
          ]
        },
        {
          "title": "Introduction to latent variable energy-based models: a path toward autonomous machine intelligence",
          "year": 2023,
          "citations": 41,
          "abstract": "Current automated systems have crucial limitations that need to be addressed before artificial intelligence can reach human-like levels and bring new technological revolutions. Among others, our societies still lack level-5 self-driving cars, domestic robots, and virtual assistants that learn reliable world models, reason, and plan complex action sequences. In these notes, we summarize the main ideas behind the architecture of autonomous intelligence of the future proposed by Yann LeCun. In particular, we introduce energy-based and latent variable models and combine their advantages in the building block of LeCun’s proposal, that is, in the hierarchical joint-embedding predictive architecture.",
          "venue": "Journal of Statistical Mechanics: Theory and Experiment",
          "doi": "10.1088/1742-5468/ad292b",
          "url": "https://www.semanticscholar.org/paper/9502c180be0ebc92fcf2085ea90c3cb45280a6bc",
          "authors": [
            "Anna Dawid",
            "Yann LeCun"
          ]
        },
        {
          "title": "To Compress or Not to Compress—Self-Supervised Learning and Information Theory: A Review",
          "year": 2023,
          "citations": 95,
          "abstract": "Deep neural networks excel in supervised learning tasks but are constrained by the need for extensive labeled data. Self-supervised learning emerges as a promising alternative, allowing models to learn without explicit labels. Information theory has shaped deep neural networks, particularly the information bottleneck principle. This principle optimizes the trade-off between compression and preserving relevant information, providing a foundation for efficient network design in supervised contexts. However, its precise role and adaptation in self-supervised learning remain unclear. In this work, we scrutinize various self-supervised learning approaches from an information-theoretic perspective, introducing a unified framework that encapsulates the self-supervised information-theoretic learning problem. This framework includes multiple encoders and decoders, suggesting that all existing work on self-supervised learning can be seen as specific instances. We aim to unify these approaches to understand their underlying principles better and address the main challenge: many works present different frameworks with differing theories that may seem contradictory. By weaving existing research into a cohesive narrative, we delve into contemporary self-supervised methodologies, spotlight potential research areas, and highlight inherent challenges. Moreover, we discuss how to estimate information-theoretic quantities and their associated empirical problems. Overall, this paper provides a comprehensive review of the intersection of information theory, self-supervised learning, and deep neural networks, aiming for a better understanding through our proposed unified approach.",
          "venue": "Entropy",
          "doi": "10.3390/e26030252",
          "url": "https://www.semanticscholar.org/paper/97b1f4980fc173e59ff3a3bdaf1b9a13965fb32e",
          "authors": [
            "Ravid Shwartz-Ziv",
            "Yann LeCun"
          ]
        },
        {
          "title": "Blockwise Self-Supervised Learning at Scale",
          "year": 2023,
          "citations": 21,
          "abstract": "Current state-of-the-art deep networks are all powered by backpropagation. In this paper, we explore alternatives to full backpropagation in the form of blockwise learning rules, leveraging the latest developments in self-supervised learning. We show that a blockwise pretraining procedure consisting of training independently the 4 main blocks of layers of a ResNet-50 with Barlow Twins' loss function at each block performs almost as well as end-to-end backpropagation on ImageNet: a linear probe trained on top of our blockwise pretrained model obtains a top-1 classification accuracy of 70.48%, only 1.1% below the accuracy of an end-to-end pretrained network (71.57% accuracy). We perform extensive experiments to understand the impact of different components within our method and explore a variety of adaptations of self-supervised learning to the blockwise paradigm, building an exhaustive understanding of the critical avenues for scaling local learning rules to large networks, with implications ranging from hardware design to neuroscience.",
          "venue": "Trans. Mach. Learn. Res.",
          "doi": "10.48550/arXiv.2302.01647",
          "url": "https://www.semanticscholar.org/paper/a09a197325be3fb2e865692b164e8827042201d1",
          "authors": [
            "Shoaib Ahmed Siddiqui",
            "David Krueger",
            "Yann LeCun",
            "Stéphane Deny"
          ]
        },
        {
          "title": "Reverse Engineering Self-Supervised Learning",
          "year": 2023,
          "citations": 43,
          "abstract": "Self-supervised learning (SSL) is a powerful tool in machine learning, but understanding the learned representations and their underlying mechanisms remains a challenge. This paper presents an in-depth empirical analysis of SSL-trained representations, encompassing diverse models, architectures, and hyperparameters. Our study reveals an intriguing aspect of the SSL training process: it inherently facilitates the clustering of samples with respect to semantic labels, which is surprisingly driven by the SSL objective's regularization term. This clustering process not only enhances downstream classification but also compresses the data information. Furthermore, we establish that SSL-trained representations align more closely with semantic classes rather than random classes. Remarkably, we show that learned representations align with semantic classes across various hierarchical levels, and this alignment increases during training and when moving deeper into the network. Our findings provide valuable insights into SSL's representation learning mechanisms and their impact on performance across different sets of classes.",
          "venue": "Neural Information Processing Systems",
          "doi": "10.48550/arXiv.2305.15614",
          "url": "https://www.semanticscholar.org/paper/a2b8ff257658b8291deb9e40ec1c164c8fefeb06",
          "authors": [
            "Ido Ben-Shaul",
            "Ravid Shwartz-Ziv",
            "Tomer Galanti",
            "S. Dekel",
            "Yann LeCun"
          ]
        },
        {
          "title": "Variance-Covariance Regularization Improves Representation Learning",
          "year": 2023,
          "citations": 8,
          "abstract": "Transfer learning plays a key role in advancing machine learning models, yet conventional supervised pretraining often undermines feature transferability by prioritizing features that minimize the pretraining loss. In this work, we adapt a self-supervised learning regularization technique from the VICReg method to supervised learning contexts, introducing Variance-Covariance Regularization (VCReg). This adaptation encourages the network to learn high-variance, low-covariance representations, promoting learning more diverse features. We outline best practices for an efficient implementation of our framework, including applying it to the intermediate representations. Through extensive empirical evaluation, we demonstrate that our method significantly enhances transfer learning for images and videos, achieving state-of-the-art performance across numerous tasks and datasets. VCReg also improves performance in scenarios like long-tail learning and hierarchical classification. Additionally, we show its effectiveness may stem from its success in addressing challenges like gradient starvation and neural collapse. In summary, VCReg offers a universally applicable regularization framework that significantly advances transfer learning and highlights the connection between gradient starvation, neural collapse, and feature transferability.",
          "venue": "arXiv.org",
          "doi": "10.48550/arXiv.2306.13292",
          "url": "https://www.semanticscholar.org/paper/c6990a1e568f5458240643688ee797b6450c9f1f",
          "authors": [
            "Jiachen Zhu",
            "Ravid Shwartz-Ziv",
            "Yubei Chen",
            "Yann LeCun"
          ]
        },
        {
          "title": "Stochastic positional embeddings improve masked image modeling",
          "year": 2023,
          "citations": 5,
          "abstract": "Masked Image Modeling (MIM) is a promising self-supervised learning approach that enables learning from unlabeled images. Despite its recent success, learning good representations through MIM remains challenging because it requires predicting the right semantic content in accurate locations. For example, given an incomplete picture of a dog, we can guess that there is a tail, but we cannot determine its exact location. In this work, we propose to incorporate location uncertainty into MIM by using stochastic positional embeddings (StoP). Specifically, we condition the model on stochastic masked token positions drawn from a Gaussian distribution. StoP reduces overfitting to location features and guides the model toward learning features that are more robust to location uncertainties. Quantitatively, StoP improves downstream MIM performance on a variety of downstream tasks, including $+1.7\\%$ on ImageNet linear probing using ViT-B, and $+2.5\\%$ for ViT-H using $1\\%$ of the data.",
          "venue": "International Conference on Machine Learning",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/da136b4651e035c2bafd0bfd34433faf7af2619e",
          "authors": [
            "Amir Bar",
            "Florian Bordes",
            "Assaf Shocher",
            "Mahmoud Assran",
            "Pascal Vincent",
            "Nicolas Ballas",
            "Trevor Darrell",
            "A. Globerson",
            "Yann LeCun"
          ]
        },
        {
          "title": "Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture",
          "year": 2023,
          "citations": 517,
          "abstract": "This paper demonstrates an approach for learning highly semantic image representations without relying on hand-crafted data-augmentations. We introduce the Image-based Joint-Embedding Predictive Architecture (I-JEPA), a non-generative approach for self-supervised learning from images. The idea behind I-JEPA is simple: from a single context block, predict the representations of various target blocks in the same image. A core design choice to guide I-JEPA towards producing semantic representations is the masking strategy; specifically, it is crucial to (a) sample target blocks with sufficiently large scale (semantic), and to (b) use a sufficiently informative (spatially distributed) context block. Empirically, when combined with Vision Transformers, we find I-JEPA to be highly scalable. For instance, we train a ViT-Huge/14 on ImageNet using 16 A100 GPUs in under 72 hours to achieve strong downstream performance across a wide range of tasks, from linear classification to object counting and depth prediction.",
          "venue": "Computer Vision and Pattern Recognition",
          "doi": "10.1109/CVPR52729.2023.01499",
          "url": "https://www.semanticscholar.org/paper/ee57e4d7a125f4ca8916284a857c3760d7d378d3",
          "authors": [
            "Mahmoud Assran",
            "Quentin Duval",
            "Ishan Misra",
            "Piotr Bojanowski",
            "Pascal Vincent",
            "Michael G. Rabbat",
            "Yann LeCun",
            "Nicolas Ballas"
          ]
        },
        {
          "title": "Language, common sense, and the Winograd schema challenge",
          "year": 2023,
          "citations": 25,
          "abstract": null,
          "venue": "Artificial Intelligence",
          "doi": "10.1016/j.artint.2023.104031",
          "url": "https://www.semanticscholar.org/paper/f875c2de4a3ccee670cc76a81b1dfd111bd40f64",
          "authors": [
            "Jacob Browning",
            "Yann LeCun"
          ]
        },
        {
          "title": "Separating the World and Ego Models for Self-Driving",
          "year": 2022,
          "citations": 5,
          "abstract": "Training self-driving systems to be robust to the long-tail of driving scenarios is a critical problem. Model-based approaches leverage simulation to emulate a wide range of scenarios without putting users at risk in the real world. One promising path to faithful simulation is to train a forward model of the world to predict the future states of both the environment and the ego-vehicle given past states and a sequence of actions. In this paper, we argue that it is beneficial to model the state of the ego-vehicle, which often has simple, predictable and deterministic behavior, separately from the rest of the environment, which is much more complex and highly multimodal. We propose to model the ego-vehicle using a simple and differentiable kinematic model, while training a stochastic convolutional forward model on raster representations of the state to predict the behavior of the rest of the environment. We explore several configurations of such decoupled models, and evaluate their performance both with Model Predictive Control (MPC) and direct policy learning. We test our methods on the task of highway driving and demonstrate lower crash rates and better stability. The code is available at https://github.com/vladisai/pytorch-PPUU/tree/ICLR2022.",
          "venue": "arXiv.org",
          "doi": "10.48550/arXiv.2204.07184",
          "url": "https://www.semanticscholar.org/paper/06103ec8b82b705d674df3432bbaa5dcfffcceb0",
          "authors": [
            "Vlad Sobal",
            "A. Canziani",
            "Nicolas Carion",
            "Kyunghyun Cho",
            "Yann LeCun"
          ]
        },
        {
          "title": "Bag of Image Patch Embedding Behind the Success of Self-Supervised Learning",
          "year": 2022,
          "citations": 8,
          "abstract": "Self-supervised learning (SSL) has recently achieved tremendous empirical advancements in learning image representation. However, our understanding of the principle behind learning such a representation is still limited. This work shows that joint-embedding SSL approaches primarily learn a representation of image patches, which reflects their co-occurrence. Such a connection to co-occurrence modeling can be established formally, and it supplements the prevailing invariance perspective. We empirically show that learning a representation for fixed-scale patches and aggregating local patch representations as the image representation achieves similar or even better results than the baseline methods. We denote this process as BagSSL. Even with 32x32 patch representation, BagSSL achieves 62% top-1 linear probing accuracy on ImageNet. On the other hand, with a multi-scale pretrained model, we show that the whole image embedding is approximately the average of local patch embeddings. While the SSL representation is relatively invariant at the global scale, we show that locality is preserved when we zoom into local patch-level representation. Further, we show that patch representation aggregation can improve various SOTA baseline methods by a large margin. The patch representation is considerably easier to understand, and this work makes a step to demystify self-supervised representation learning.",
          "venue": "Trans. Mach. Learn. Res.",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/0bbb60fd0fe2e0ffefacb16fc2c527cb2f01a71e",
          "authors": [
            "Yubei Chen",
            "Adrien Bardes",
            "Zengyi Li",
            "Yann LeCun"
          ]
        },
        {
          "title": "VoLTA: Vision-Language Transformer with Weakly-Supervised Local-Feature Alignment",
          "year": 2022,
          "citations": 26,
          "abstract": "Vision-language pre-training (VLP) has recently proven highly effective for various uni- and multi-modal downstream applications. However, most existing end-to-end VLP methods use high-resolution image-text box data to perform well on fine-grained region-level tasks, such as object detection, segmentation, and referring expression comprehension. Unfortunately, such high-resolution images with accurate bounding box annotations are expensive to collect and use for supervision at scale. In this work, we propose VoLTA (Vision-Language Transformer with weakly-supervised local-feature Alignment), a new VLP paradigm that only utilizes image-caption data but achieves fine-grained region-level image understanding, eliminating the use of expensive box annotations. VoLTA adopts graph optimal transport-based weakly-supervised alignment on local image patches and text tokens to germinate an explicit, self-normalized, and interpretable low-level matching criterion. In addition, VoLTA pushes multi-modal fusion deep into the uni-modal backbones during pre-training and removes fusion-specific transformer layers, further reducing memory requirements. Extensive experiments on a wide range of vision- and vision-language downstream tasks demonstrate the effectiveness of VoLTA on fine-grained applications without compromising the coarse-grained downstream performance, often outperforming methods using significantly more caption and box annotations.",
          "venue": "Trans. Mach. Learn. Res.",
          "doi": "10.48550/arXiv.2210.04135",
          "url": "https://www.semanticscholar.org/paper/0ee11b28a9ce49d3030cab11f1178fa5abae9c3b",
          "authors": [
            "Shraman Pramanick",
            "Li Jing",
            "Sayan Nag",
            "Jiachen Zhu",
            "Hardik Shah",
            "Yann LeCun",
            "Ramalingam Chellappa"
          ]
        },
        {
          "title": "On the duality between contrastive and non-contrastive self-supervised learning",
          "year": 2022,
          "citations": 106,
          "abstract": "Recent approaches in self-supervised learning of image representations can be categorized into different families of methods and, in particular, can be divided into contrastive and non-contrastive approaches. While differences between the two families have been thoroughly discussed to motivate new approaches, we focus more on the theoretical similarities between them. By designing contrastive and covariance based non-contrastive criteria that can be related algebraically and shown to be equivalent under limited assumptions, we show how close those families can be. We further study popular methods and introduce variations of them, allowing us to relate this theoretical result to current practices and show the influence (or lack thereof) of design choices on downstream performance. Motivated by our equivalence result, we investigate the low performance of SimCLR and show how it can match VICReg's with careful hyperparameter tuning, improving significantly over known baselines. We also challenge the popular assumption that non-contrastive methods need large output dimensions. Our theoretical and quantitative results suggest that the numerical gaps between contrastive and non-contrastive methods in certain regimes can be closed given better network design choices and hyperparameter tuning. The evidence shows that unifying different SOTA methods is an important direction to build a better understanding of self-supervised learning.",
          "venue": "International Conference on Learning Representations",
          "doi": "10.48550/arXiv.2206.02574",
          "url": "https://www.semanticscholar.org/paper/11c16254f7b61687b5d9b7637de032461a6ebb5f",
          "authors": [
            "Q. Garrido",
            "Yubei Chen",
            "Adrien Bardes",
            "Laurent Najman",
            "Yann LeCun"
          ]
        },
        {
          "title": "RankMe: Assessing the downstream performance of pretrained self-supervised representations by their rank",
          "year": 2022,
          "citations": 108,
          "abstract": "Joint-Embedding Self Supervised Learning (JE-SSL) has seen a rapid development, with the emergence of many method variations but only few principled guidelines that would help practitioners to successfully deploy them. The main reason for that pitfall comes from JE-SSL's core principle of not employing any input reconstruction therefore lacking visual cues of unsuccessful training. Adding non informative loss values to that, it becomes difficult to deploy SSL on a new dataset for which no labels can help to judge the quality of the learned representation. In this study, we develop a simple unsupervised criterion that is indicative of the quality of the learned JE-SSL representations: their effective rank. Albeit simple and computationally friendly, this method -- coined RankMe -- allows one to assess the performance of JE-SSL representations, even on different downstream datasets, without requiring any labels. A further benefit of RankMe is that it does not have any training or hyper-parameters to tune. Through thorough empirical experiments involving hundreds of training episodes, we demonstrate how RankMe can be used for hyperparameter selection with nearly no reduction in final performance compared to the current selection method that involve a dataset's labels. We hope that RankMe will facilitate the deployment of JE-SSL towards domains that do not have the opportunity to rely on labels for representations' quality assessment.",
          "venue": "International Conference on Machine Learning",
          "doi": "10.48550/arXiv.2210.02885",
          "url": "https://www.semanticscholar.org/paper/127ebdb7b87fe5c8c8ff1bb9173584b75eec8f47",
          "authors": [
            "Q. Garrido",
            "Randall Balestriero",
            "Laurent Najman",
            "Yann LeCun"
          ]
        },
        {
          "title": "Pre-Train Your Loss: Easy Bayesian Transfer Learning with Informative Priors",
          "year": 2022,
          "citations": 46,
          "abstract": "Deep learning is increasingly moving towards a transfer learning paradigm whereby large foundation models are fine-tuned on downstream tasks, starting from an initialization learned on the source task. But an initialization contains relatively little information about the source task. Instead, we show that we can learn highly informative posteriors from the source task, through supervised or self-supervised approaches, which then serve as the basis for priors that modify the whole loss surface on the downstream task. This simple modular approach enables significant performance gains and more data-efficient learning on a variety of downstream classification and segmentation tasks, serving as a drop-in replacement for standard pre-training strategies. These highly informative priors also can be saved for future use, similar to pre-trained weights, and stand in contrast to the zero-mean isotropic uninformative priors that are typically used in Bayesian deep learning.",
          "venue": "Neural Information Processing Systems",
          "doi": "10.48550/arXiv.2205.10279",
          "url": "https://www.semanticscholar.org/paper/1e9fbd0e9d047c192d7e2a75f0034400c5c403c7",
          "authors": [
            "Ravid Shwartz-Ziv",
            "Micah Goldblum",
            "Hossein Souri",
            "Sanyam Kapoor",
            "Chen Zhu",
            "Yann LeCun",
            "A. Wilson"
          ]
        },
        {
          "title": "Open Research Online Knowledge Graph Construction with a façade: a uniﬁed method to access heterogeneous data sources on the Web",
          "year": 2022,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/346ff941ebbccdbada17a22aa074f609bf7afd28",
          "authors": [
            "Yann LeCun"
          ]
        },
        {
          "title": "Neural Manifold Clustering and Embedding",
          "year": 2022,
          "citations": 48,
          "abstract": "Given a union of non-linear manifolds, non-linear subspace clustering or manifold clustering aims to cluster data points based on manifold structures and also learn to parameterize each manifold as a linear subspace in a feature space. Deep neural networks have the potential to achieve this goal under highly non-linear settings given their large capacity and flexibility. We argue that achieving manifold clustering with neural networks requires two essential ingredients: a domain-specific constraint that ensures the identification of the manifolds, and a learning algorithm for embedding each manifold to a linear subspace in the feature space. This work shows that many constraints can be implemented by data augmentation. For subspace feature learning, Maximum Coding Rate Reduction (MCR$^2$) objective can be used. Putting them together yields {\\em Neural Manifold Clustering and Embedding} (NMCE), a novel method for general purpose manifold clustering, which significantly outperforms autoencoder-based deep subspace clustering. Further, on more challenging natural image datasets, NMCE can also outperform other algorithms specifically designed for clustering. Qualitatively, we demonstrate that NMCE learns a meaningful and interpretable feature space. As the formulation of NMCE is closely related to several important Self-supervised learning (SSL) methods, we believe this work can help us build a deeper understanding on SSL representation learning.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/3834edf530c639257555d41a3c67e128a22aefc0",
          "authors": [
            "Zengyi Li",
            "Yubei Chen",
            "Yann LeCun",
            "F. Sommer"
          ]
        },
        {
          "title": "A Data-Augmentation Is Worth A Thousand Samples: Exact Quantification From Analytical Augmented Sample Moments",
          "year": 2022,
          "citations": 20,
          "abstract": "Data-Augmentation (DA) is known to improve performance across tasks and datasets. We propose a method to theoretically analyze the effect of DA and study questions such as: how many augmented samples are needed to correctly estimate the information encoded by that DA? How does the augmentation policy impact the final parameters of a model? We derive several quantities in close-form, such as the expectation and variance of an image, loss, and model's output under a given DA distribution. Those derivations open new avenues to quantify the benefits and limitations of DA. For example, we show that common DAs require tens of thousands of samples for the loss at hand to be correctly estimated and for the model training to converge. We show that for a training loss to be stable under DA sampling, the model's saliency map (gradient of the loss with respect to the model's input) must align with the smallest eigenvector of the sample variance under the considered DA augmentation, hinting at a possible explanation on why models tend to shift their focus from edges to textures.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/3f07b6b6d1fc6020cef1f92c053810f46b46ac5e",
          "authors": [
            "Randall Balestriero",
            "Ishan Misra",
            "Yann LeCun"
          ]
        },
        {
          "title": "Toward Next-Generation Artificial Intelligence: Catalyzing the NeuroAI Revolution",
          "year": 2022,
          "citations": 53,
          "abstract": null,
          "venue": "arXiv.org",
          "doi": "10.48550/arXiv.2210.08340",
          "url": "https://www.semanticscholar.org/paper/497e2d07c1dbf84913110c02cd2990eaea57a7cb",
          "authors": [
            "A. Zador",
            "B. Richards",
            "Bence Olveczky",
            "Sean Escola",
            "Y. Bengio",
            "K. Boahen",
            "M. Botvinick",
            "D. Chklovskii",
            "A. Churchland",
            "C. Clopath",
            "J. DiCarlo",
            "S. Ganguli",
            "J. Hawkins",
            "Konrad Koerding",
            "A. Koulakov",
            "Yann LeCun",
            "T. Lillicrap",
            "A. Marblestone",
            "B. Olshausen",
            "A. Pouget",
            "Cristina Savin",
            "T. Sejnowski",
            "Eero P. Simoncelli",
            "S. Solla",
            "David Sussillo",
            "A. Tolias",
            "Doris Y. Tsao"
          ]
        },
        {
          "title": "Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone",
          "year": 2022,
          "citations": 144,
          "abstract": "Vision-language (VL) pre-training has recently received considerable attention. However, most existing end-to-end pre-training approaches either only aim to tackle VL tasks such as image-text retrieval, visual question answering (VQA) and image captioning that test high-level understanding of images, or only target region-level understanding for tasks such as phrase grounding and object detection. We present FIBER (Fusion-In-the-Backbone-based transformER), a new VL model architecture that can seamlessly handle both these types of tasks. Instead of having dedicated transformer layers for fusion after the uni-modal backbones, FIBER pushes multimodal fusion deep into the model by inserting cross-attention into the image and text backbones, bringing gains in terms of memory and performance. In addition, unlike previous work that is either only pre-trained on image-text data or on fine-grained data with box-level annotations, we present a two-stage pre-training strategy that uses both these kinds of data efficiently: (i) coarse-grained pre-training based on image-text data; followed by (ii) fine-grained pre-training based on image-text-box data. We conduct comprehensive experiments on a wide range of VL tasks, ranging from VQA, image captioning, and retrieval, to phrase grounding, referring expression comprehension, and object detection. Using deep multimodal fusion coupled with the two-stage pre-training, FIBER provides consistent performance improvements over strong baselines across all tasks, often outperforming methods using magnitudes more data. Code is available at https://github.com/microsoft/FIBER.",
          "venue": "Neural Information Processing Systems",
          "doi": "10.48550/arXiv.2206.07643",
          "url": "https://www.semanticscholar.org/paper/4c559d29e19f1226353f52ffe9f8068db1cef943",
          "authors": [
            "Zi-Yi Dou",
            "Aishwarya Kamath",
            "Zhe Gan",
            "Pengchuan Zhang",
            "Jianfeng Wang",
            "Linjie Li",
            "Zicheng Liu",
            "Ce Liu",
            "Yann LeCun",
            "Nanyun Peng",
            "Jianfeng Gao",
            "Lijuan Wang"
          ]
        },
        {
          "title": "A Generalization of ViT/MLP-Mixer to Graphs",
          "year": 2022,
          "citations": 117,
          "abstract": "Graph Neural Networks (GNNs) have shown great potential in the field of graph representation learning. Standard GNNs define a local message-passing mechanism which propagates information over the whole graph domain by stacking multiple layers. This paradigm suffers from two major limitations, over-squashing and poor long-range dependencies, that can be solved using global attention but significantly increases the computational cost to quadratic complexity. In this work, we propose an alternative approach to overcome these structural limitations by leveraging the ViT/MLP-Mixer architectures introduced in computer vision. We introduce a new class of GNNs, called Graph ViT/MLP-Mixer, that holds three key properties. First, they capture long-range dependency and mitigate the issue of over-squashing as demonstrated on Long Range Graph Benchmark and TreeNeighbourMatch datasets. Second, they offer better speed and memory efficiency with a complexity linear to the number of nodes and edges, surpassing the related Graph Transformer and expressive GNN models. Third, they show high expressivity in terms of graph isomorphism as they can distinguish at least 3-WL non-isomorphic graphs. We test our architecture on 4 simulated datasets and 7 real-world benchmarks, and show highly competitive results on all of them. The source code is available for reproducibility at: \\url{https://github.com/XiaoxinHe/Graph-ViT-MLPMixer}.",
          "venue": "International Conference on Machine Learning",
          "doi": "10.48550/arXiv.2212.13350",
          "url": "https://www.semanticscholar.org/paper/517802b9381246dff16756fe5299fa62bb29e228",
          "authors": [
            "Xiaoxin He",
            "Bryan Hooi",
            "T. Laurent",
            "Adam Perold",
            "Yann LeCun",
            "X. Bresson"
          ]
        },
        {
          "title": "Minimalistic Unsupervised Learning with the Sparse Manifold Transform",
          "year": 2022,
          "citations": 8,
          "abstract": "We describe a minimalistic and interpretable method for unsupervised learning, without resorting to data augmentation, hyperparameter tuning, or other engineering designs, that achieves performance close to the SOTA SSL methods. Our approach leverages the sparse manifold transform, which unifies sparse coding, manifold learning, and slow feature analysis. With a one-layer deterministic sparse manifold transform, one can achieve 99.3% KNN top-1 accuracy on MNIST, 81.1% KNN top-1 accuracy on CIFAR-10 and 53.2% on CIFAR-100. With a simple gray-scale augmentation, the model gets 83.2% KNN top-1 accuracy on CIFAR-10 and 57% on CIFAR-100. These results significantly close the gap between simplistic\"white-box\"methods and the SOTA methods. Additionally, we provide visualization to explain how an unsupervised representation transform is formed. The proposed method is closely connected to latent-embedding self-supervised methods and can be treated as the simplest form of VICReg. Though there remains a small performance gap between our simple constructive model and SOTA methods, the evidence points to this as a promising direction for achieving a principled and white-box approach to unsupervised learning.",
          "venue": "arXiv.org",
          "doi": "10.48550/arXiv.2209.15261",
          "url": "https://www.semanticscholar.org/paper/537166437212aac4b4297121e0ba4b7e545d4e54",
          "authors": [
            "Yubei Chen",
            "Zeyu Yun",
            "Y. Ma",
            "B. Olshausen",
            "Yann LeCun"
          ]
        },
        {
          "title": "Catalyzing next-generation Artificial Intelligence through NeuroAI",
          "year": 2022,
          "citations": 239,
          "abstract": "One of the ambitions of computational neuroscience is that we will continue to make improvements in the field of artificial intelligence that will be informed by advances in our understanding of how the brains of various species evolved to process information. To that end, here the authors propose an expanded version of the Turing test that involves embodied sensorimotor interactions with the world as a new framework for accelerating progress in artificial intelligence. Neuroscience has long been an essential driver of progress in artificial intelligence (AI). We propose that to accelerate progress in AI, we must invest in fundamental research in NeuroAI. A core component of this is the embodied Turing test, which challenges AI animal models to interact with the sensorimotor world at skill levels akin to their living counterparts. The embodied Turing test shifts the focus from those capabilities like game playing and language that are especially well-developed or uniquely human to those capabilities – inherited from over 500 million years of evolution – that are shared with all animals. Building models that can pass the embodied Turing test will provide a roadmap for the next generation of AI.",
          "venue": "Nature Communications",
          "doi": "10.1038/s41467-023-37180-x",
          "url": "https://www.semanticscholar.org/paper/5cba4b2a4d0b74c8aad0c94b6f468f6c86ee3db9",
          "authors": [
            "A. Zador",
            "Sean Escola",
            "B. Richards",
            "B. Ölveczky",
            "Y. Bengio",
            "K. Boahen",
            "M. Botvinick",
            "D. Chklovskii",
            "A. Churchland",
            "C. Clopath",
            "J. DiCarlo",
            "Surya",
            "Ganguli",
            "J. Hawkins",
            "Konrad Paul Kording",
            "A. Koulakov",
            "Yann LeCun",
            "T. Lillicrap",
            "Adam",
            "Marblestone",
            "B. Olshausen",
            "A. Pouget",
            "Cristina Savin",
            "T. Sejnowski",
            "Eero P. Simoncelli",
            "S. Solla",
            "David Sussillo",
            "A. Tolias",
            "D. Tsao"
          ]
        },
        {
          "title": "Unsupervised Learning of Structured Representations via Closed-Loop Transcription",
          "year": 2022,
          "citations": 9,
          "abstract": "This paper proposes an unsupervised method for learning a unified representation that serves both discriminative and generative purposes. While most existing unsupervised learning approaches focus on a representation for only one of these two goals, we show that a unified representation can enjoy the mutual benefits of having both. Such a representation is attainable by generalizing the recently proposed \\textit{closed-loop transcription} framework, known as CTRL, to the unsupervised setting. This entails solving a constrained maximin game over a rate reduction objective that expands features of all samples while compressing features of augmentations of each sample. Through this process, we see discriminative low-dimensional structures emerge in the resulting representations. Under comparable experimental conditions and network complexities, we demonstrate that these structured representations enable classification performance close to state-of-the-art unsupervised discriminative representations, and conditionally generated image quality significantly higher than that of state-of-the-art unsupervised generative models. Source code can be found at https://github.com/Delay-Xili/uCTRL.",
          "venue": "CPAL",
          "doi": "10.48550/arXiv.2210.16782",
          "url": "https://www.semanticscholar.org/paper/5e071a75a6906434daffe24f612fd291db4e1496",
          "authors": [
            "Shengbang Tong",
            "Xili Dai",
            "Yubei Chen",
            "Mingyang Li",
            "Zengyi Li",
            "Brent Yi",
            "Yann LeCun",
            "Y. Ma"
          ]
        },
        {
          "title": "Police: Provably Optimal Linear Constraint Enforcement For Deep Neural Networks",
          "year": 2022,
          "citations": 17,
          "abstract": "Deep Neural Networks (DNNs) outshine alternative function approximators in many settings thanks to their modularity in composing any desired differentiable operator. The formed parametrized functional is then tuned to solve a task at hand from simple gradient descent. This modularity comes at the cost of making strict enforcement of constraints on DNNs, e.g. from a priori knowledge of the task, or from desired physical properties, an open challenge. In this paper we propose the first provable affine constraint enforcement method for DNNs that only requires minimal changes into a given DNN’s forward-pass, that is computationally friendly, and that leaves the optimization of the DNN’s parameter to be unconstrained, i.e. standard gradient-based method can be employed. Our method does not require any sampling and provably ensures that the DNN fulfills the affine constraint on a given input space’s region at any point during training, and testing. We coin this method POLICE, standing for Provably Optimal LInear Constraint Enforcement. Github: https://github.com/RandallBalestriero/POLICE",
          "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
          "doi": "10.1109/ICASSP49357.2023.10096520",
          "url": "https://www.semanticscholar.org/paper/6f0aca58e13339fe78ee04b948253999a7cf85a3",
          "authors": [
            "Randall Balestriero",
            "Yann LeCun"
          ]
        },
        {
          "title": "A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27",
          "year": 2022,
          "citations": 525,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/775f42ed458b8c5b0f2094ea4ff5b64c557b1a34",
          "authors": [
            "Yann LeCun",
            "Courant"
          ]
        },
        {
          "title": "A Data-Augmentation Is Worth A Thousand Samples: Analytical Moments And Sampling-Free Training",
          "year": 2022,
          "citations": 17,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/825257577638307bd13487888fb91cc1ae11501b",
          "authors": [
            "Randall Balestriero",
            "Ishan Misra",
            "Yann LeCun"
          ]
        },
        {
          "title": "TiCo: Transformation Invariance and Covariance Contrast for Self-Supervised Visual Representation Learning",
          "year": 2022,
          "citations": 25,
          "abstract": "We present Transformation Invariance and Covariance Contrast (TiCo) for self-supervised visual representation learning. Similar to other recent self-supervised learning methods, our method is based on maximizing the agreement among embeddings of different distorted versions of the same image, which pushes the encoder to produce transformation invariant representations. To avoid the trivial solution where the encoder generates constant vectors, we regularize the covariance matrix of the embeddings from different images by penalizing low rank solutions. By jointly minimizing the transformation invariance loss and covariance contrast loss, we get an encoder that is able to produce useful representations for downstream tasks. We analyze our method and show that it can be viewed as a variant of MoCo with an implicit memory bank of unlimited size at no extra memory cost. This makes our method perform better than alternative methods when using small batch sizes. TiCo can also be seen as a modification of Barlow Twins. By connecting the contrastive and redundancy-reduction methods together, TiCo gives us new insights into how joint embedding methods work.",
          "venue": "arXiv.org",
          "doi": "10.48550/arXiv.2206.10698",
          "url": "https://www.semanticscholar.org/paper/9539f3b6ccabf66cf54acdafd8b95421b9c2b683",
          "authors": [
            "Jiachen Zhu",
            "R. M. Moraes",
            "Serkan Karakulak",
            "Vlad Sobol",
            "A. Canziani",
            "Yann LeCun"
          ]
        },
        {
          "title": "Variance Covariance Regularization Enforces Pairwise Independence in Self-Supervised Representations",
          "year": 2022,
          "citations": 10,
          "abstract": "Self-Supervised Learning (SSL) methods such as VICReg, Barlow Twins or W-MSE avoid collapse of their joint embedding architectures by constraining or regularizing the covariance matrix of their projector's output. This study highlights important properties of such strategy, which we coin Variance-Covariance regularization (VCReg). More precisely, we show that {\\em VCReg combined to a MLP projector enforces pairwise independence between the features of the learned representation}. This result emerges by bridging VCReg applied on the projector's output to kernel independence criteria applied on the projector's input. We empirically validate our findings where (i) we put in evidence which projector's characteristics favor pairwise independence, (ii) we demonstrate pairwise independence to be beneficial for out-of-domain generalization, (iii) we demonstrate that the scope of VCReg goes beyond SSL by using it to solve Independent Component Analysis. This provides the first theoretical motivation and explanation of MLP projectors in SSL.",
          "venue": "arXiv.org",
          "doi": "10.48550/arXiv.2209.14905",
          "url": "https://www.semanticscholar.org/paper/95c729ce4469ba0513380759b82d3a50d648bd9b",
          "authors": [
            "G. Mialon",
            "Randall Balestriero",
            "Yann LeCun"
          ]
        },
        {
          "title": "Light-weight probing of unsupervised representations for Reinforcement Learning",
          "year": 2022,
          "citations": 20,
          "abstract": "Unsupervised visual representation learning offers the opportunity to leverage large corpora of unlabeled trajectories to form useful visual representations, which can benefit the training of reinforcement learning (RL) algorithms. However, evaluating the fitness of such representations requires training RL algorithms which is computationally intensive and has high variance outcomes. Inspired by the vision community, we study whether linear probing can be a proxy evaluation task for the quality of unsupervised RL representation. Specifically, we probe for the observed reward in a given state and the action of an expert in a given state, both of which are generally applicable to many RL domains. Through rigorous experimentation, we show that the probing tasks are strongly rank correlated with the downstream RL performance on the Atari100k Benchmark, while having lower variance and up to 600x lower computational cost. This provides a more efficient method for exploring the space of pretraining algorithms and identifying promising pretraining recipes without the need to run RL evaluations for every setting. Leveraging this framework, we further improve existing self-supervised learning (SSL) recipes for RL, highlighting the importance of the forward model, the size of the visual backbone, and the precise formulation of the unsupervised objective.",
          "venue": "RLJ",
          "doi": "10.48550/arXiv.2208.12345",
          "url": "https://www.semanticscholar.org/paper/b62f6f765f033c1f023c4a424a20571564e61d97",
          "authors": [
            "Wancong Zhang",
            "Anthony GX-Chen",
            "Vlad Sobal",
            "Yann LeCun",
            "Nicolas Carion"
          ]
        },
        {
          "title": "What Do We Maximize in Self-Supervised Learning?",
          "year": 2022,
          "citations": 22,
          "abstract": "In this paper, we examine self-supervised learning methods, particularly VICReg, to provide an information-theoretical understanding of their construction. As a first step, we demonstrate how information-theoretic quantities can be obtained for a deterministic network, offering a possible alternative to prior work that relies on stochastic models. This enables us to demonstrate how VICReg can be (re)discovered from first principles and its assumptions about data distribution. Furthermore, we empirically demonstrate the validity of our assumptions, confirming our novel understanding of VICReg. Finally, we believe that the derivation and insights we obtain can be generalized to many other SSL methods, opening new avenues for theoretical and practical understanding of SSL and transfer learning.",
          "venue": "arXiv.org",
          "doi": "10.48550/arXiv.2207.10081",
          "url": "https://www.semanticscholar.org/paper/b83fc5d7de2cc6a5ce6e44b8a1dd9169eec62720",
          "authors": [
            "Ravid Shwartz-Ziv",
            "Randall Balestriero",
            "Yann LeCun"
          ]
        },
        {
          "title": "Contrastive and Non-Contrastive Self-Supervised Learning Recover Global and Local Spectral Embedding Methods",
          "year": 2022,
          "citations": 152,
          "abstract": "Self-Supervised Learning (SSL) surmises that inputs and pairwise positive relationships are enough to learn meaningful representations. Although SSL has recently reached a milestone: outperforming supervised methods in many modalities\\dots the theoretical foundations are limited, method-specific, and fail to provide principled design guidelines to practitioners. In this paper, we propose a unifying framework under the helm of spectral manifold learning to address those limitations. Through the course of this study, we will rigorously demonstrate that VICReg, SimCLR, BarlowTwins et al. correspond to eponymous spectral methods such as Laplacian Eigenmaps, Multidimensional Scaling et al. This unification will then allow us to obtain (i) the closed-form optimal representation for each method, (ii) the closed-form optimal network parameters in the linear regime for each method, (iii) the impact of the pairwise relations used during training on each of those quantities and on downstream task performances, and most importantly, (iv) the first theoretical bridge between contrastive and non-contrastive methods towards global and local spectral embedding methods respectively, hinting at the benefits and limitations of each. For example, (i) if the pairwise relation is aligned with the downstream task, any SSL method can be employed successfully and will recover the supervised method, but in the low data regime, VICReg's invariance hyper-parameter should be high; (ii) if the pairwise relation is misaligned with the downstream task, VICReg with small invariance hyper-parameter should be preferred over SimCLR or BarlowTwins.",
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/b845c9d7f3fa05f56e7394f273c0c7536ee0e671",
          "authors": [
            "Randall Balestriero",
            "Yann LeCun"
          ]
        },
        {
          "title": "VICRegL: Self-Supervised Learning of Local Visual Features",
          "year": 2022,
          "citations": 148,
          "abstract": "Most recent self-supervised methods for learning image representations focus on either producing a global feature with invariance properties, or producing a set of local features. The former works best for classification tasks while the latter is best for detection and segmentation tasks. This paper explores the fundamental trade-off between learning local and global features. A new method called VICRegL is proposed that learns good global and local features simultaneously, yielding excellent performance on detection and segmentation tasks while maintaining good performance on classification tasks. Concretely, two identical branches of a standard convolutional net architecture are fed two differently distorted versions of the same image. The VICReg criterion is applied to pairs of global feature vectors. Simultaneously, the VICReg criterion is applied to pairs of local feature vectors occurring before the last pooling layer. Two local feature vectors are attracted to each other if their l2-distance is below a threshold or if their relative locations are consistent with a known geometric transformation between the two input images. We demonstrate strong performance on linear classification and segmentation transfer tasks. Code and pretrained models are publicly available at: https://github.com/facebookresearch/VICRegL",
          "venue": "Neural Information Processing Systems",
          "doi": "10.48550/arXiv.2210.01571",
          "url": "https://www.semanticscholar.org/paper/b8d4beeb8df994db12688226cf2a619f1d633b72",
          "authors": [
            "Adrien Bardes",
            "J. Ponce",
            "Yann LeCun"
          ]
        },
        {
          "title": "Intra-Instance VICReg: Bag of Self-Supervised Image Patch Embedding",
          "year": 2022,
          "citations": 17,
          "abstract": null,
          "venue": "arXiv.org",
          "doi": "10.48550/arXiv.2206.08954",
          "url": "https://www.semanticscholar.org/paper/cf209f6cfa987e7b9320c24a8e9cb70bf39f31a7",
          "authors": [
            "Yubei Chen",
            "Adrien Bardes",
            "Zengyi Li",
            "Yann LeCun"
          ]
        },
        {
          "title": "Extracting structural folding pattern of chromatin using chromatin condensation data",
          "year": 2022,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/d36dcc52d9d8bc1a4b43469977653cebce579dd8",
          "authors": [
            "Samira Mali",
            "N. L. V. Berkum",
            "Louise Williams",
            "Maxim Imakaev",
            "T. Ragoczy",
            "A. Telling",
            "N. A. Kinney",
            "I. Sharakhov",
            "A. Onufriev",
            "Jia Deng",
            "Wei Dong",
            "R. Socher",
            "Lijuan Li",
            "Kaixia Li",
            "Yann LeCun",
            "B. Boser",
            "J. Denker",
            "D. Henderson",
            "R. Howard",
            "W. Hubbard"
          ]
        },
        {
          "title": "projUNN: efficient method for training deep networks with unitary matrices",
          "year": 2022,
          "citations": 34,
          "abstract": "In learning with recurrent or very deep feed-forward networks, employing unitary matrices in each layer can be very effective at maintaining long-range stability. However, restricting network parameters to be unitary typically comes at the cost of expensive parameterizations or increased training runtime. We propose instead an efficient method based on rank-$k$ updates -- or their rank-$k$ approximation -- that maintains performance at a nearly optimal training runtime. We introduce two variants of this method, named Direct (projUNN-D) and Tangent (projUNN-T) projected Unitary Neural Networks, that can parameterize full $N$-dimensional unitary or orthogonal matrices with a training runtime scaling as $O(kN^2)$. Our method either projects low-rank gradients onto the closest unitary matrix (projUNN-T) or transports unitary matrices in the direction of the low-rank gradient (projUNN-D). Even in the fastest setting ($k=1$), projUNN is able to train a model's unitary parameters to reach comparable performances against baseline implementations. In recurrent neural network settings, projUNN closely matches or exceeds benchmarked results from prior unitary neural networks. Finally, we preliminarily explore projUNN in training orthogonal convolutional neural networks, which are currently unable to outperform state of the art models but can potentially enhance stability and robustness at large depth.",
          "venue": "Neural Information Processing Systems",
          "doi": "10.48550/arXiv.2203.05483",
          "url": "https://www.semanticscholar.org/paper/d43f665fad45256659dce9e9d2c2a05a6383e5b6",
          "authors": [
            "B. Kiani",
            "Randall Balestriero",
            "Yann LeCun",
            "S. Lloyd"
          ]
        },
        {
          "title": "The Effects of Regularization and Data Augmentation are Class Dependent",
          "year": 2022,
          "citations": 109,
          "abstract": "Regularization is a fundamental technique to prevent over-fitting and to improve generalization performances by constraining a model's complexity. Current Deep Networks heavily rely on regularizers such as Data-Augmentation (DA) or weight-decay, and employ structural risk minimization, i.e. cross-validation, to select the optimal regularization hyper-parameters. In this study, we demonstrate that techniques such as DA or weight decay produce a model with a reduced complexity that is unfair across classes. The optimal amount of DA or weight decay found from cross-validation leads to disastrous model performances on some classes e.g. on Imagenet with a resnet50, the\"barn spider\"classification test accuracy falls from $68\\%$ to $46\\%$ only by introducing random crop DA during training. Even more surprising, such performance drop also appears when introducing uninformative regularization techniques such as weight decay. Those results demonstrate that our search for ever increasing generalization performance -- averaged over all classes and samples -- has left us with models and regularizers that silently sacrifice performances on some classes. This scenario can become dangerous when deploying a model on downstream tasks e.g. an Imagenet pre-trained resnet50 deployed on INaturalist sees its performances fall from $70\\%$ to $30\\%$ on class \\#8889 when introducing random crop DA during the Imagenet pre-training phase. Those results demonstrate that designing novel regularizers without class-dependent bias remains an open research question.",
          "venue": "Neural Information Processing Systems",
          "doi": "10.48550/arXiv.2204.03632",
          "url": "https://www.semanticscholar.org/paper/dcda4897113ed03c920e2e94a90ee33e09781759",
          "authors": [
            "Randall Balestriero",
            "L. Bottou",
            "Yann LeCun"
          ]
        },
        {
          "title": "Masked Siamese ConvNets",
          "year": 2022,
          "citations": 37,
          "abstract": "Self-supervised learning has shown superior performances over supervised methods on various vision benchmarks. The siamese network, which encourages embeddings to be invariant to distortions, is one of the most successful self-supervised visual representation learning approaches. Among all the augmentation methods, masking is the most general and straightforward method that has the potential to be applied to all kinds of input and requires the least amount of domain knowledge. However, masked siamese networks require particular inductive bias and practically only work well with Vision Transformers. This work empirically studies the problems behind masked siamese networks with ConvNets. We propose several empirical designs to overcome these problems gradually. Our method performs competitively on low-shot image classification and outperforms previous methods on object detection benchmarks. We discuss several remaining issues and hope this work can provide useful data points for future general-purpose self-supervised learning.",
          "venue": "arXiv.org",
          "doi": "10.48550/arXiv.2206.07700",
          "url": "https://www.semanticscholar.org/paper/df1af149a7b9aaa2ef0bb05adf639e9ae6b56249",
          "authors": [
            "L. Jing",
            "Jiachen Zhu",
            "Yann LeCun"
          ]
        },
        {
          "title": "Joint Embedding Self-Supervised Learning in the Kernel Regime",
          "year": 2022,
          "citations": 15,
          "abstract": "The fundamental goal of self-supervised learning (SSL) is to produce useful representations of data without access to any labels for classifying the data. Modern methods in SSL, which form representations based on known or constructed relationships between samples, have been particularly effective at this task. Here, we aim to extend this framework to incorporate algorithms based on kernel methods where embeddings are constructed by linear maps acting on the feature space of a kernel. In this kernel regime, we derive methods to find the optimal form of the output representations for contrastive and non-contrastive loss functions. This procedure produces a new representation space with an inner product denoted as the induced kernel which generally correlates points which are related by an augmentation in kernel space and de-correlates points otherwise. We analyze our kernel model on small datasets to identify common features of self-supervised learning algorithms and gain theoretical insights into their performance on downstream tasks.",
          "venue": "arXiv.org",
          "doi": "10.48550/arXiv.2209.14884",
          "url": "https://www.semanticscholar.org/paper/ebcccb72117b4641df9b88bac5b51dc5d2cead27",
          "authors": [
            "B. Kiani",
            "Randall Balestriero",
            "Yubei Chen",
            "S. Lloyd",
            "Yann LeCun"
          ]
        },
        {
          "title": "Joint Embedding Predictive Architectures Focus on Slow Features",
          "year": 2022,
          "citations": 12,
          "abstract": "Many common methods for learning a world model for pixel-based environments use generative architectures trained with pixel-level reconstruction objectives. Recently proposed Joint Embedding Predictive Architectures (JEPA) offer a reconstruction-free alternative. In this work, we analyze performance of JEPA trained with VICReg and SimCLR objectives in the fully offline setting without access to rewards, and compare the results to the performance of the generative architecture. We test the methods in a simple environment with a moving dot with various background distractors, and probe learned representations for the dot's location. We find that JEPA methods perform on par or better than reconstruction when distractor noise changes every time step, but fail when the noise is fixed. Furthermore, we provide a theoretical explanation for the poor performance of JEPA-based methods with fixed noise, highlighting an important limitation.",
          "venue": "arXiv.org",
          "doi": "10.48550/arXiv.2211.10831",
          "url": "https://www.semanticscholar.org/paper/ed009b7423dcfec47708fb5817ec4955e4265757",
          "authors": [
            "Vlad Sobal",
            "V JyothirS",
            "Siddhartha Jalagam",
            "Nicolas Carion",
            "Kyunghyun Cho",
            "Yann LeCun"
          ]
        },
        {
          "title": "Deep learning, reinforcement learning, and world models",
          "year": 2022,
          "citations": 375,
          "abstract": null,
          "venue": "Neural Networks",
          "doi": "10.1016/j.neunet.2022.03.037",
          "url": "https://www.semanticscholar.org/paper/effa7077e6580a8ab22c30d3c876744b4e51cd6e",
          "authors": [
            "Yu Matsuo",
            "Yann LeCun",
            "M. Sahani",
            "Doina Precup",
            "David Silver",
            "Masashi Sugiyama",
            "E. Uchibe",
            "J. Morimoto"
          ]
        },
        {
          "title": "VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning",
          "year": 2021,
          "citations": 1073,
          "abstract": "Recent self-supervised methods for image representation learning are based on maximizing the agreement between embedding vectors from different views of the same image. A trivial solution is obtained when the encoder outputs constant vectors. This collapse problem is often avoided through implicit biases in the learning architecture, that often lack a clear justification or interpretation. In this paper, we introduce VICReg (Variance-Invariance-Covariance Regularization), a method that explicitly avoids the collapse problem with a simple regularization term on the variance of the embeddings along each dimension individually. VICReg combines the variance term with a decorrelation mechanism based on redundancy reduction and covariance regularization, and achieves results on par with the state of the art on several downstream tasks. In addition, we show that incorporating our new variance term into other methods helps stabilize the training and leads to performance improvements.",
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/0d0cf5f64c052aa7edc5bb638203616a620557f6",
          "authors": [
            "Adrien Bardes",
            "J. Ponce",
            "Yann LeCun"
          ]
        },
        {
          "title": "Compact and Optimal Deep Learning with Recurrent Parameter Generators",
          "year": 2021,
          "citations": 5,
          "abstract": "Deep learning has achieved tremendous success by training increasingly large models, which are then compressed for practical deployment. We propose a drastically different approach to compact and optimal deep learning: We decouple the Degrees of freedom (DoF) and the actual number of parameters of a model, optimize a small DoF with predefined random linear constraints for a large model of an arbitrary architecture, in one-stage end-to-end learning.Specifically, we create a recurrent parameter generator (RPG), which repeatedly fetches parameters from a ring and unpacks them onto a large model with random permutation and sign flipping to promote parameter decorrelation. We show that gradient descent can automatically find the best model under constraints with in fact faster convergence.Our extensive experimentation reveals a log-linear relationship between model DoF and accuracy. Our RPG demonstrates remarkable DoF reduction, and can be further pruned and quantized for additional run-time performance gain. For example, in terms of top-1 accuracy on ImageNet, RPG achieves 96% of ResNet18’s performance with only 18% DoF (the equivalent of one convolutional layer) and 52% of ResNet34’s performance with only 0.25% DoF! Our work shows significant potential of constrained neural opti-mization in compact and optimal deep learning.",
          "venue": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
          "doi": "10.1109/WACV56688.2023.00389",
          "url": "https://www.semanticscholar.org/paper/15dc19495e95703f96989bd66135eb3bc4057976",
          "authors": [
            "Jiayun Wang",
            "Yubei Chen",
            "Stella X. Yu",
            "Brian Cheung",
            "Yann LeCun"
          ]
        },
        {
          "title": "Understanding Dimensional Collapse in Contrastive Self-supervised Learning",
          "year": 2021,
          "citations": 412,
          "abstract": "Self-supervised visual representation learning aims to learn useful representations without relying on human annotations. Joint embedding approach bases on maximizing the agreement between embedding vectors from different views of the same image. Various methods have been proposed to solve the collapsing problem where all embedding vectors collapse to a trivial constant solution. Among these methods, contrastive learning prevents collapse via negative sample pairs. It has been shown that non-contrastive methods suffer from a lesser collapse problem of a different nature: dimensional collapse, whereby the embedding vectors end up spanning a lower-dimensional subspace instead of the entire available embedding space. Here, we show that dimensional collapse also happens in contrastive learning. In this paper, we shed light on the dynamics at play in contrastive learning that leads to dimensional collapse. Inspired by our theory, we propose a novel contrastive learning method, called DirectCLR, which directly optimizes the representation space without relying on an explicit trainable projector. Experiments show that DirectCLR outperforms SimCLR with a trainable linear projector on ImageNet.",
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/28c17db217f2d7af12482a087d197851f0a97db0",
          "authors": [
            "Li Jing",
            "Pascal Vincent",
            "Yann LeCun",
            "Yuandong Tian"
          ]
        },
        {
          "title": "Recurrent Parameter Generators",
          "year": 2021,
          "citations": 3,
          "abstract": null,
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/310215110bb72f8dfce8be73a904ea1c4968739f",
          "authors": [
            "Jiayun Wang",
            "Yubei Chen",
            "Stella X. Yu",
            "Brian Cheung",
            "Yann LeCun"
          ]
        },
        {
          "title": "Decoupled Contrastive Learning",
          "year": 2021,
          "citations": 219,
          "abstract": "Contrastive learning (CL) is one of the most successful paradigms for self-supervised learning (SSL). In a principled way, it considers two augmented\"views\"of the same image as positive to be pulled closer, and all other images as negative to be pushed further apart. However, behind the impressive success of CL-based techniques, their formulation often relies on heavy-computation settings, including large sample batches, extensive training epochs, etc. We are thus motivated to tackle these issues and establish a simple, efficient, yet competitive baseline of contrastive learning. Specifically, we identify, from theoretical and empirical studies, a noticeable negative-positive-coupling (NPC) effect in the widely used InfoNCE loss, leading to unsuitable learning efficiency concerning the batch size. By removing the NPC effect, we propose decoupled contrastive learning (DCL) loss, which removes the positive term from the denominator and significantly improves the learning efficiency. DCL achieves competitive performance with less sensitivity to sub-optimal hyperparameters, requiring neither large batches in SimCLR, momentum encoding in MoCo, or large epochs. We demonstrate with various benchmarks while manifesting robustness as much less sensitive to suboptimal hyperparameters. Notably, SimCLR with DCL achieves 68.2% ImageNet-1K top-1 accuracy using batch size 256 within 200 epochs pre-training, outperforming its SimCLR baseline by 6.4%. Further, DCL can be combined with the SOTA contrastive learning method, NNCLR, to achieve 72.3% ImageNet-1K top-1 accuracy with 512 batch size in 400 epochs, which represents a new SOTA in contrastive learning. We believe DCL provides a valuable baseline for future contrastive SSL studies.",
          "venue": "European Conference on Computer Vision",
          "doi": "10.1007/978-3-031-19809-0_38",
          "url": "https://www.semanticscholar.org/paper/40b68df4635298c32725891bc46ee0201dac56c1",
          "authors": [
            "Chun-Hsiao Yeh",
            "Cheng-Yao Hong",
            "Yen-Chi Hsu",
            "Tyng-Luh Liu",
            "Yubei Chen",
            "Yann LeCun"
          ]
        },
        {
          "title": "Sparse Coding with Multi-Layer Decoders using Variance Regularization",
          "year": 2021,
          "citations": 13,
          "abstract": "Sparse representations of images are useful in many computer vision applications. Sparse coding with an $l_1$ penalty and a learned linear dictionary requires regularization of the dictionary to prevent a collapse in the $l_1$ norms of the codes. Typically, this regularization entails bounding the Euclidean norms of the dictionary's elements. In this work, we propose a novel sparse coding protocol which prevents a collapse in the codes without the need to regularize the decoder. Our method regularizes the codes directly so that each latent code component has variance greater than a fixed threshold over a set of sparse representations for a given set of inputs. Furthermore, we explore ways to effectively train sparse coding systems with multi-layer decoders since they can model more complex relationships than linear dictionaries. In our experiments with MNIST and natural image patches, we show that decoders learned with our approach have interpretable features both in the linear and multi-layer case. Moreover, we show that sparse autoencoders with multi-layer decoders trained using our variance regularization method produce higher quality reconstructions with sparser representations when compared to autoencoders with linear dictionaries. Additionally, sparse representations obtained with our variance regularization approach are useful in the downstream tasks of denoising and classification in the low-data regime.",
          "venue": "Trans. Mach. Learn. Res.",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/6e08acdb27e83a26ef7e67539a11e9cb3588e822",
          "authors": [
            "Katrina Evtimova",
            "Yann LeCun"
          ]
        },
        {
          "title": "MDETR - Modulated Detection for End-to-End Multi-Modal Understanding",
          "year": 2021,
          "citations": 1023,
          "abstract": "Multi-modal reasoning systems rely on a pre-trained object detector to extract regions of interest from the image. However, this crucial module is typically used as a black box, trained independently of the downstream task and on a fixed vocabulary of objects and attributes. This makes it challenging for such systems to capture the long tail of visual concepts expressed in free form text. In this paper we propose MDETR, an end-to-end modulated detector that detects objects in an image conditioned on a raw text query, like a caption or a question. We use a transformer-based architecture to reason jointly over text and image by fusing the two modalities at an early stage of the model. We pre-train the network on 1.3M text-image pairs, mined from pre-existing multi-modal datasets having explicit alignment between phrases in text and objects in the image. We then fine-tune on several downstream tasks such as phrase grounding, referring expression comprehension and segmentation, achieving state-of-the-art results on popular benchmarks. We also investigate the utility of our model as an object detector on a given label set when fine-tuned in a few-shot setting. We show that our pre-training approach provides a way to handle the long tail of object categories which have very few labelled instances. Our approach can be easily extended for visual question answering, achieving competitive performance on GQA and CLEVR. The code and models are available at https://github.com/ashkamath/mdetr.",
          "venue": "IEEE International Conference on Computer Vision",
          "doi": "10.1109/ICCV48922.2021.00180",
          "url": "https://www.semanticscholar.org/paper/7ba9c013988eaff5cd186d73704af329d027872d",
          "authors": [
            "Aishwarya Kamath",
            "Mannat Singh",
            "Yann LeCun",
            "Ishan Misra",
            "Gabriel Synnaeve",
            "Nicolas Carion"
          ]
        },
        {
          "title": "Transformer visualization via dictionary learning: contextualized embedding as a linear superposition of transformer factors",
          "year": 2021,
          "citations": 101,
          "abstract": "Transformer networks have revolutionized NLP representation learning since they were introduced. Though a great effort has been made to explain the representation in transformers, it is widely recognized that our understanding is not sufficient. One important reason is that there lack enough visualization tools for detailed analysis. In this paper, we propose to use dictionary learning to open up these ‘black boxes’ as linear superpositions of transformer factors. Through visualization, we demonstrate the hierarchical semantic structures captured by the transformer factors, e.g., word-level polysemy disambiguation, sentence-level pattern formation, and long-range dependency. While some of these patterns confirm the conventional prior linguistic knowledge, the rest are relatively unexpected, which may provide new insights. We hope this visualization tool can bring further knowledge and a better understanding of how transformer networks work. The code is available at: https://github.com/zeyuyun1/TransformerVis.",
          "venue": "Workshop on Knowledge Extraction and Integration for Deep Learning Architectures; Deep Learning Inside Out",
          "doi": "10.18653/V1/2021.DEELIO-1.1",
          "url": "https://www.semanticscholar.org/paper/7cc88a1a904e8bb6edc1123c0800d1c5a0ea435d",
          "authors": [
            "Zeyu Yun",
            "Yubei Chen",
            "B. Olshausen",
            "Yann LeCun"
          ]
        },
        {
          "title": "Inspirational Adversarial Image Generation",
          "year": 2021,
          "citations": 3,
          "abstract": "The task of image generation started receiving some attention from artists and designers, providing inspiration for new creations. However, exploiting the results of deep generative models such as Generative Adversarial Networks can be long and tedious given the lack of existing tools. In this work, we propose a simple strategy to inspire creators with new generations learned from a dataset of their choice, while providing some control over the output. We design a simple optimization method to find the optimal latent parameters corresponding to the closest generation to any input inspirational image. Specifically, we allow the generation given an inspirational image of the user’s choosing by performing several optimization steps to recover optimal parameters from the model’s latent space. We tested several exploration methods from classical gradient descents to gradient-free optimizers. Many gradient-free optimizers just need comparisons (better/worse than another image), so they can even be used without numerical criterion nor inspirational image, only with human preferences. Thus, by iterating on one’s preferences we can make robust facial composite or fashion generation algorithms. Our results on four datasets of faces, fashion images, and textures show that satisfactory images are effectively retrieved in most cases.",
          "venue": "IEEE Transactions on Image Processing",
          "doi": "10.1109/TIP.2021.3065845",
          "url": "https://www.semanticscholar.org/paper/836e4a8b665f46729e55e7674b4d8b0df6c1d091",
          "authors": [
            "Baptiste Rozière",
            "M. Rivière",
            "O. Teytaud",
            "J. Rapin",
            "Yann LeCun",
            "C. Couprie"
          ]
        },
        {
          "title": "Deep learning for AI",
          "year": 2021,
          "citations": 560,
          "abstract": "How can neural networks learn the rich internal representations required for difficult tasks such as recognizing objects or understanding language?",
          "venue": "Communications of the ACM",
          "doi": "10.1145/3448250",
          "url": "https://www.semanticscholar.org/paper/87d5b61f5b6fdb0a57fc66b5c5bb428c398eaa86",
          "authors": [
            "Yoshua Bengio",
            "Yann LeCun",
            "Geoffrey E. Hinton"
          ]
        },
        {
          "title": "Barlow Twins: Self-Supervised Learning via Redundancy Reduction",
          "year": 2021,
          "citations": 2674,
          "abstract": "Self-supervised learning (SSL) is rapidly closing the gap with supervised methods on large computer vision benchmarks. A successful approach to SSL is to learn embeddings which are invariant to distortions of the input sample. However, a recurring issue with this approach is the existence of trivial constant solutions. Most current methods avoid such solutions by careful implementation details. We propose an objective function that naturally avoids collapse by measuring the cross-correlation matrix between the outputs of two identical networks fed with distorted versions of a sample, and making it as close to the identity matrix as possible. This causes the embedding vectors of distorted versions of a sample to be similar, while minimizing the redundancy between the components of these vectors. The method is called Barlow Twins, owing to neuroscientist H. Barlow's redundancy-reduction principle applied to a pair of identical networks. Barlow Twins does not require large batches nor asymmetry between the network twins such as a predictor network, gradient stopping, or a moving average on the weight updates. Intriguingly it benefits from very high-dimensional output vectors. Barlow Twins outperforms previous methods on ImageNet for semi-supervised classification in the low-data regime, and is on par with current state of the art for ImageNet classification with a linear classifier head, and for transfer tasks of classification and object detection.",
          "venue": "International Conference on Machine Learning",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/8a9d84d86ac0d76e63914802f9738325c3bece9c",
          "authors": [
            "Jure Zbontar",
            "Li Jing",
            "Ishan Misra",
            "Yann LeCun",
            "Stéphane Deny"
          ]
        },
        {
          "title": "Neural Potts Model",
          "year": 2021,
          "citations": 8,
          "abstract": "We propose the Neural Potts Model objective as an amortized optimization problem. The objective enables training a single model with shared parameters to explicitly model energy landscapes across multiple protein families. Given a protein sequence as input, the model is trained to predict a pairwise coupling matrix for a Potts model energy function describing the local evolutionary landscape of the sequence. Couplings can be predicted for novel sequences. A controlled ablation experiment assessing unsupervised contact prediction on sets of related protein families finds a gain from amortization for low-depth multiple sequence alignments; the result is then confirmed on a database with broad coverage of protein sequences.",
          "venue": "bioRxiv",
          "doi": "10.1101/2021.04.08.439084",
          "url": "https://www.semanticscholar.org/paper/94526a3b070927dc7a0f066cf0a17b8abaf5ce1f",
          "authors": [
            "Tom Sercu",
            "Robert Verkuil",
            "Joshua Meier",
            "Brandon Amos",
            "Zeming Lin",
            "Caroline Chen",
            "Jason Liu",
            "Yann LeCun",
            "Alexander Rives"
          ]
        },
        {
          "title": "Handwritten Digit Recognition Using TensorFlow Lite Micro on i.MX RT devices",
          "year": 2021,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/b9ec816bc53bd86dc3849545bf8516bc0cb8cb9f",
          "authors": [
            "Yann LeCun",
            "Corinna Cortes"
          ]
        },
        {
          "title": "Optimization of Artificial Neural Network Hyperparameters For Processing Retrospective Information",
          "year": 2021,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/be59058dd2320648826021b8c04d4cfcf0c18431",
          "authors": [
            "A. Rogachev",
            "F. Scholle",
            "Yann LeCun",
            "Yoshua Bengio",
            "I. L. Kashirin",
            "M. Demchenko"
          ]
        },
        {
          "title": "Learning in High Dimension Always Amounts to Extrapolation",
          "year": 2021,
          "citations": 112,
          "abstract": "The notion of interpolation and extrapolation is fundamental in various fields from deep learning to function approximation. Interpolation occurs for a sample $x$ whenever this sample falls inside or on the boundary of the given dataset's convex hull. Extrapolation occurs when $x$ falls outside of that convex hull. One fundamental (mis)conception is that state-of-the-art algorithms work so well because of their ability to correctly interpolate training data. A second (mis)conception is that interpolation happens throughout tasks and datasets, in fact, many intuitions and theories rely on that assumption. We empirically and theoretically argue against those two points and demonstrate that on any high-dimensional ($>$100) dataset, interpolation almost surely never happens. Those results challenge the validity of our current interpolation/extrapolation definition as an indicator of generalization performances.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/e75c388b60cf447be7148be25feeee3e10d12cf4",
          "authors": [
            "Randall Balestriero",
            "J. Pesenti",
            "Yann LeCun"
          ]
        },
        {
          "title": "Implicit Rank-Minimizing Autoencoder",
          "year": 2020,
          "citations": 51,
          "abstract": "An important component of autoencoders is the method by which the information capacity of the latent representation is minimized or limited. In this work, the rank of the covariance matrix of the codes is implicitly minimized by relying on the fact that gradient descent learning in multi-layer linear networks leads to minimum-rank solutions. By inserting a number of extra linear layers between the encoder and the decoder, the system spontaneously learns representations with a low effective dimension. The model, dubbed Implicit Rank-Minimizing Autoencoder (IRMAE), is simple, deterministic, and learns compact latent spaces. We demonstrate the validity of the method on several image generation and representation learning tasks.",
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/10266bc9d3f6cf1966c846217b66ab5f26006446",
          "authors": [
            "Li Jing",
            "Jure Zbontar",
            "Yann LeCun"
          ]
        },
        {
          "title": "Jean piaget theory in punjabi pdf",
          "year": 2020,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/759f608c5246b7d634dfe13a21adc4731da4bddd",
          "authors": [
            "Jean PiagetPiaget",
            "H. Bergson",
            "P. Janet",
            "A. Binet",
            "Théodore Simon",
            "S. Spielrein",
            "Shlomo Wolbe",
            "B. Inhelder",
            "J. Bruner",
            "K. Kaye",
            "Citation",
            "L. Kohlberg",
            "R. Kegan",
            "H. Gardner",
            "T. Kuhn",
            "J. Flavell",
            "Yann LeCun",
            "J. Peterson",
            "J. Piaget"
          ]
        },
        {
          "title": "The Mind of a Mouse",
          "year": 2020,
          "citations": 160,
          "abstract": null,
          "venue": "Cell",
          "doi": "10.1016/j.cell.2020.08.010",
          "url": "https://www.semanticscholar.org/paper/a5fd28aa9240835a14b1c285096d62e3a3ba5722",
          "authors": [
            "L. Abbott",
            "D. Bock",
            "E. Callaway",
            "W. Denk",
            "C. Dulac",
            "A. Fairhall",
            "I. Fiete",
            "Kristen M. Harris",
            "M. Helmstaedter",
            "Viren Jain",
            "N. Kasthuri",
            "Yann LeCun",
            "J. Lichtman",
            "P. Littlewood",
            "L. Luo",
            "John H. R. Maunsell",
            "R. Reid",
            "B. Rosen",
            "G. Rubin",
            "T. Sejnowski",
            "H. Seung",
            "K. Svoboda",
            "D. Tank",
            "Doris Y. Tsao",
            "D. C. Essen"
          ]
        },
        {
          "title": "Sticky Reasoning within Learning Representations",
          "year": 2019,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/0633bf78c0b5aa041c881bd334906733302a4427",
          "authors": [
            "Yann LeCun"
          ]
        },
        {
          "title": "Model-Predictive Policy Learning with Uncertainty Regularization for Driving in Dense Traffic",
          "year": 2019,
          "citations": 125,
          "abstract": "Learning a policy using only observational data is challenging because the distribution of states it induces at execution time may differ from the distribution observed during training. We propose to train a policy by unrolling a learned model of the environment dynamics over multiple time steps while explicitly penalizing two costs: the original cost the policy seeks to optimize, and an uncertainty cost which represents its divergence from the states it is trained on. We measure this second cost by using the uncertainty of the dynamics model about its own predictions, using recent ideas from uncertainty estimation for deep networks. We evaluate our approach using a large-scale observational dataset of driving behavior recorded from traffic cameras, and show that we are able to learn effective driving policies from purely observational data, with no environment interaction.",
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/2eeace98cf3c105a8d37884dc8d33c50ae4b7ddb",
          "authors": [
            "Mikael Henaff",
            "A. Canziani",
            "Yann LeCun"
          ]
        },
        {
          "title": "Learning about an exponential amount of conditional distributions",
          "year": 2019,
          "citations": 29,
          "abstract": "We introduce the Neural Conditioner (NC), a self-supervised machine able to learn about all the conditional distributions of a random vector $X$. The NC is a function $NC(x \\cdot a, a, r)$ that leverages adversarial training to match each conditional distribution $P(X_r|X_a=x_a)$. After training, the NC generalizes to sample from conditional distributions never seen, including the joint distribution. The NC is also able to auto-encode examples, providing data representations useful for downstream classification tasks. In sum, the NC integrates different self-supervised tasks (each being the estimation of a conditional distribution) and levels of supervision (partially observed data) seamlessly into a single learning experience.",
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/4e48a5a00a79cb586c1c912507ec6e52890cdeab",
          "authors": [
            "Mohamed Ishmael Belghazi",
            "M. Oquab",
            "Yann LeCun",
            "David Lopez-Paz"
          ]
        },
        {
          "title": "The role of over-parametrization in generalization of neural networks",
          "year": 2019,
          "citations": 202,
          "abstract": null,
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/6e8001afb2e24b648ae9ceb4e00c20ded4a5ee99",
          "authors": [
            "Behnam Neyshabur",
            "Zhiyuan Li",
            "Srinadh Bhojanapalli",
            "Yann LeCun",
            "N. Srebro"
          ]
        },
        {
          "title": "Inspirational Adversarial Image Generation",
          "year": 2019,
          "citations": 24,
          "abstract": "The task of image generation started to receive some attention from artists and designers to inspire them in new creations. However, exploiting the results of deep generative models such as Generative Adversarial Networks can be long and tedious given the lack of existing tools. In this work, we propose a simple strategy to inspire creators with new generations learned from a dataset of their choice, while providing some control on them. We design a simple optimization method to find the optimal latent parameters corresponding to the closest generation to any input inspirational image. Specifically, we allow the generation given an inspirational image of the user choice by performing several optimization steps to recover optimal parameters from the model's latent space. We tested several exploration methods starting with classic gradient descents to gradient-free optimizers. Many gradient-free optimizers just need comparisons (better/worse than another image), so that they can even be used without numerical criterion, without inspirational image, but with only with human preference. Thus, by iterating on one's preferences we could make robust Facial Composite or Fashion Generation algorithms. High resolution of the produced design generations are obtained using progressive growing of GANs. Our results on four datasets of faces, fashion images, and textures show that satisfactory images are effectively retrieved in most cases.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/8881f1b45ec6f0e1805627c828629cdd925bcfc6",
          "authors": [
            "Baptiste Rozière",
            "M. Rivière",
            "O. Teytaud",
            "J. Rapin",
            "Yann LeCun",
            "C. Couprie"
          ]
        },
        {
          "title": "1.1 Deep Learning Hardware: Past, Present, and Future",
          "year": 2019,
          "citations": 115,
          "abstract": "Historically, progress in neural networks and deep learning research has been greatly influenced by the available hardware and software tools. This paper identifies trends in deep learning research that will influence hardware architectures and software platforms of the future.",
          "venue": "IEEE International Solid-State Circuits Conference",
          "doi": "10.1109/ISSCC.2019.8662396",
          "url": "https://www.semanticscholar.org/paper/91788beae2cd32b13c9ece1e724fd1988d9d9629",
          "authors": [
            "Yann LeCun"
          ]
        },
        {
          "title": "Unsupervised Image Matching and Object Discovery as Optimization",
          "year": 2019,
          "citations": 66,
          "abstract": "Learning with complete or partial supervision is power- ful but relies on ever-growing human annotation efforts. As a way to mitigate this serious problem, as well as to serve specific applications, unsupervised learning has emerged as an important field of research. In computer vision, unsu- pervised learning comes in various guises. We focus here on the unsupervised discovery and matching of object cate- gories among images in a collection, following the work of Cho et al. [12]. We show that the original approach can be reformulated and solved as a proper optimization problem. Experiments on several benchmarks establish the merit of our approach.",
          "venue": "Computer Vision and Pattern Recognition",
          "doi": "10.1109/CVPR.2019.00848",
          "url": "https://www.semanticscholar.org/paper/96f68a831d723dc0d841daa8e5c1f457603140d3",
          "authors": [
            "Huy V. Vo",
            "F. Bach",
            "Minsu Cho",
            "Kai Han",
            "Yann LeCun",
            "P. Pérez",
            "J. Ponce"
          ]
        },
        {
          "title": "Lesson planning",
          "year": 2019,
          "citations": 0,
          "abstract": null,
          "venue": "Healthcare Simulation at a Glance",
          "doi": "10.1007/978-1-4419-1428-6_4758",
          "url": "https://www.semanticscholar.org/paper/d6df4299193a145080896c67f5dfe34b9ad61fea",
          "authors": [
            "Cecilia Ka Yuk Chan",
            "Zoya A. Zorina",
            "Jesse R. Sparks",
            "S. López Ornat",
            "Christine D. Tsang",
            "Elena L. Grigorenko",
            "R. Lubow",
            "John C. Malone",
            "Michael Domjan",
            "Charles Yang",
            "Michelyn C. Butler",
            "M. Gettinger",
            "Thomas R. Minor",
            "Traci N. Plumb",
            "Hendrik Drachsler",
            "P. A. Kirschner",
            "Minoru Nakayama",
            "Rowena Santiago",
            "Ali Simsek",
            "Fang-Ying Yang",
            "Yi-Chun Chen",
            "G. Brooke",
            "Heidi L. Andrade",
            "Richard P. Cooper",
            "A. Podolskiy",
            "David W. Versailles",
            "Valérie Mérindol",
            "E. Guerci",
            "Nobuyuki Hanaki",
            "D. Grollman",
            "A. Billard",
            "Luis C. Lamb",
            "Artur d’Avila Garcez",
            "D. Németh",
            "K. Janacsek",
            "John A. Nunnery",
            "L. Byrd-Poller",
            "M. Haan",
            "Rodrigo Harrison",
            "Mauricio G. Villena",
            "L. Izquierdo",
            "Segismundo S. Izquierdo",
            "F. Vega-Redondo",
            "Tracy Packiam Alloway",
            "U. Halsband",
            "N. Seel",
            "G. Bedny",
            "Hansjörg von Brevern",
            "K. Synytsya",
            "Gabriele Kern-Isberner",
            "Joost Breuker",
            "S. Cerri",
            "T. Zittoun",
            "S. Brinkmann",
            "Negin Dahya",
            "S. B. Fountain",
            "Karen E. Doyle",
            "K. Sarfo",
            "Bertram C. Bruce",
            "N. Bloch",
            "C.-J. Olsson",
            "Lars Nyberg",
            "R. Freivalds",
            "Lynne Hall",
            "M. Hall",
            "Ulrike Hanke",
            "Lin S. Norton",
            "Aytac Gogus",
            "K. Illeris",
            "M. Macy",
            "A. Flache",
            "A. Robins",
            "Laura-Rose Thorogood",
            "M. Udell",
            "C. Wynne",
            "Paul C. Burnett",
            "M. Cannon",
            "Amy C. Edmondson",
            "Pitoyo Hartono",
            "A. Callender",
            "Rachel Barr",
            "Natalie Brito",
            "Noorizah Mohd. Noor",
            "Tg. Nor Rizan Tg. Mohd. Maasum",
            "K. Cennamo",
            "Marc'Aurelio Ranzato",
            "Y-Lan Boureau",
            "K. Kavukcuoglu",
            "Karol Gregor",
            "Yann LeCun",
            "M. Alias",
            "Caifeng Shan",
            "Alice Y. Kolb",
            "David A. Kolb",
            "R. Reilly",
            "Klaus Nielsen",
            "P. Couvillon",
            "Heather King",
            "Justin Dillon",
            "Delia Neuman",
            "J. E. Purdy",
            "Linda Kragelund",
            "F. Gobet",
            "Peter C. R. Lane",
            "Som Naidu",
            "Danny R. Bedgood",
            "Dirk Ifenthaler",
            "Ida Moadab",
            "Don M. Tucker",
            "Paul J. Hager",
            "J. Fejes",
            "Danielle C. Colas-Zelin",
            "L. Matzel",
            "P. Perruchet",
            "B. Poulin-Charronnat",
            "S. Pacton",
            "C. Linnman",
            "Mohamed A Zeidan",
            "M. Milad",
            "I. Holloway",
            "Daniel Ansari",
            "K. Lionello-DeNolf",
            "J. Burgoyne",
            "Judy Huang",
            "Roger K. Thomas",
            "S. Pietropaolo",
            "Wim E. Crusio",
            "Sabine Richter",
            "J. Elen",
            "G. Clarebout",
            "E. Bliss-Moreau",
            "Jonte Bernhard",
            "Marcia L. Conner",
            "Lanita Jacobs",
            "Mariel Miller",
            "A. Hadwin",
            "M. Coen",
            "Carlo Magno",
            "Eli Hinkel",
            "S. Szedmák",
            "F. Balagué",
            "M. Milrad",
            "H. U. Hoppe",
            "Krisztina Molnar",
            "Erica de Vries",
            "Emmanuel G. Blanchard",
            "C. Frasson",
            "Susanne P. Lajoie",
            "Tristan Cazenave",
            "Ton Jong",
            "Jan Meij",
            "J. Gavelek",
            "Ailing Kong",
            "A. Daffertshofer",
            "J. Alonso-Tapia",
            "S. Billett",
            "D. Rumbaugh",
            "Michael J. Beran",
            "Imran Ho-Abdullah",
            "Norsimah Mat Awal",
            "Dong-oh Seo",
            "M. Monfils",
            "Anthony A. Wright",
            "D. Deshler",
            "Frances M. Ihle",
            "Carrie Mark",
            "Daniel T. Pollitt",
            "Michael J. Kennedy",
            "Michael Jackson",
            "Terezinha Nunes",
            "B. Jackling",
            "R. Howard",
            "William G. Kennedy",
            "L. C. Drickamer"
          ]
        },
        {
          "title": "A Spectral Regularizer for Unsupervised Disentanglement",
          "year": 2018,
          "citations": 43,
          "abstract": "A generative model with a disentangled representation allows for independent control over different aspects of the output. Learning disentangled representations has been a recent topic of great interest, but it remains poorly understood. We show that even for GANs that do not possess disentangled representations, one can find curved trajectories in latent space over which local disentanglement occurs. These trajectories are found by iteratively following the leading right-singular vectors of the Jacobian of the generator with respect to its input. Based on this insight, we describe an efficient regularizer that aligns these vectors with the coordinate axes, and show that it can be used to induce disentangled representations in GANs, in a completely unsupervised manner.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/0ac54252eab1ac7641e03bc9b7344e2064e06405",
          "authors": [
            "A. Ramesh",
            "Youngduck Choi",
            "Yann LeCun"
          ]
        },
        {
          "title": "Byte-Level Recursive Convolutional Auto-Encoder for Text",
          "year": 2018,
          "citations": 3,
          "abstract": "This article proposes to auto-encode text at byte-level using convolutional networks with a recursive architecture. The motivation is to explore whether it is possible to have scalable and homogeneous text generation at byte-level in a non-sequential fashion through the simple task of auto-encoding. We show that non-sequential text generation from a fixed-length representation is not only possible, but also achieved much better auto-encoding results than recurrent networks. The proposed model is a multi-stage deep convolutional encoder-decoder framework using residual connections, containing up to 160 parameterized layers. Each encoder or decoder contains a shared group of modules that consists of either pooling or upsampling layers, making the network recursive in terms of abstraction levels in representation. Results for 6 large-scale paragraph datasets are reported, in 3 languages including Arabic, Chinese and English. Analyses are conducted to study several properties of the proposed model.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/290c96ff9be2fb517ff2eed3f55fdde919e44f05",
          "authors": [
            "Xiang Zhang",
            "Yann LeCun"
          ]
        },
        {
          "title": "GLoMo: Unsupervisedly Learned Relational Graphs as Transferable Representations",
          "year": 2018,
          "citations": 36,
          "abstract": "Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Our proposed transfer learning framework improves performance on various tasks including question answering, natural language inference, sentiment analysis, and image classification. We also show that the learned graphs are generic enough to be transferred to different embeddings on which the graphs have not been trained (including GloVe embeddings, ELMo embeddings, and task-specific RNN hidden unit), or embedding-free units such as image pixels.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/446efa0bcf3528b51332a12495cb56784dd8bad3",
          "authors": [
            "Zhilin Yang",
            "J. Zhao",
            "Bhuwan Dhingra",
            "Kaiming He",
            "William W. Cohen",
            "R. Salakhutdinov",
            "Yann LeCun"
          ]
        },
        {
          "title": "Towards Understanding the Role of Over-Parametrization in Generalization of Neural Networks",
          "year": 2018,
          "citations": 393,
          "abstract": "Despite existing work on ensuring generalization of neural networks in terms of scale sensitive complexity measures, such as norms, margin and sharpness, these complexity measures do not offer an explanation of why neural networks generalize better with over-parametrization. In this work we suggest a novel complexity measure based on unit-wise capacities resulting in a tighter generalization bound for two layer ReLU networks. Our capacity bound correlates with the behavior of test error with increasing network sizes, and could potentially explain the improvement in generalization with over-parametrization. We further present a matching lower bound for the Rademacher complexity that improves over previous capacity lower bounds for neural networks.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/51063caeb691f9a20e34feb721f14660a0df968e",
          "authors": [
            "Behnam Neyshabur",
            "Zhiyuan Li",
            "Srinadh Bhojanapalli",
            "Yann LeCun",
            "N. Srebro"
          ]
        },
        {
          "title": "GLoMo: Unsupervised Learning of Transferable Relational Graphs",
          "year": 2018,
          "citations": 23,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/684e712f59f11d2bdc98be4c210824ab9e6f11f4",
          "authors": [
            "Zhilin Yang",
            "J. Zhao",
            "Bhuwan Dhingra",
            "Kaiming He",
            "William W. Cohen",
            "R. Salakhutdinov",
            "Yann LeCun"
          ]
        },
        {
          "title": "AAAS AMA: Hi, we’re researchers from Google, Microsoft, and Facebook who study Artificial Intelligence. Ask us anything!",
          "year": 2018,
          "citations": 2,
          "abstract": null,
          "venue": "",
          "doi": "10.15200/WINN.151896.65484",
          "url": "https://www.semanticscholar.org/paper/7abb55c10bbc1cd590723edd0e1bb457c1b021ee",
          "authors": [
            "Yann LeCun",
            "AI Facebook",
            "New Research",
            "NY Eric York",
            "Horvitz",
            "Eric Horvitz"
          ]
        },
        {
          "title": "The Power and Limits of Deep Learning",
          "year": 2018,
          "citations": 32,
          "abstract": "Artificial intelligence (AI) is advancing very rapidly. I’ve had a front-row seat for a lot of the recent progress—first at Bell Labs (which was renamed AT&T Labs in 1996, while I was there) and th...",
          "venue": "Research technology management",
          "doi": "10.1080/08956308.2018.1516928",
          "url": "https://www.semanticscholar.org/paper/9e6006531597c0f8422e25de7d62c068ad9e68ee",
          "authors": [
            "Yann LeCun"
          ]
        },
        {
          "title": "Learning with Reflective Likelihoods",
          "year": 2018,
          "citations": 5,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/ad81013e8afc5e2fd5d279468dd6c9bb504179e7",
          "authors": [
            "A. B. Dieng",
            "Kyunghyun Cho",
            "D. Blei",
            "Yann LeCun"
          ]
        },
        {
          "title": "Adversarially-Trained Normalized Noisy-Feature Auto-Encoder for Text Generation",
          "year": 2018,
          "citations": 0,
          "abstract": "This article proposes Adversarially-Trained Normalized Noisy-Feature Auto-Encoder (ATNNFAE) for byte-level text generation. An ATNNFAE consists of an auto-encoder where the internal code is normalized on the unit sphere and corrupted by additive noise. Simultaneously, a replica of the decoder (sharing the same parameters as the AE decoder) is used as the generator and fed with random latent vectors. An adversarial discriminator is trained to distinguish training samples reconstructed from the AE from samples produced through the random-input generator, making the entire generator-discriminator path differentiable for discrete data like text. The combined effect of noise injection in the code and shared weights between the decoder and the generator can prevent the mode collapsing phenomenon commonly observed in GANs. Since perplexity cannot be applied to non-sequential text generation, we propose a new evaluation method using the total variance distance between frequencies of hash-coded byte-level n-grams (NGTVD). NGTVD is a single benchmark that can characterize both the quality and the diversity of the generated texts. Experiments are offered in 6 large-scale datasets in Arabic, Chinese and English, with comparisons against n-gram baselines and recurrent neural networks (RNNs). Ablation study on both the noise level and the discriminator is performed. We find that RNNs have trouble competing with the n-gram baselines, and the ATNNFAE results are generally competitive.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/c03607de715a6c578ac720a074d7fb494e37cc92",
          "authors": [
            "Xiang Zhang",
            "Yann LeCun"
          ]
        },
        {
          "title": "Backpropagation for Implicit Spectral Densities",
          "year": 2018,
          "citations": 10,
          "abstract": "Most successful machine intelligence systems rely on gradient-based learning, which is made possible by backpropagation. Some systems are designed to aid us in interpreting data when explicit goals cannot be provided. These unsupervised systems are commonly trained by backpropagating through a likelihood function. We introduce a tool that allows us to do this even when the likelihood is not explicitly set, by instead using the implicit likelihood of the model. Explicitly defining the likelihood often entails making heavy-handed assumptions that impede our ability to solve challenging tasks. On the other hand, the implicit likelihood of the model is accessible without the need for such assumptions. Our tool, which we call spectral backpropagation, allows us to optimize it in much greater generality than what has been attempted before. GANs can also be viewed as a technique for optimizing implicit likelihoods. We study them using spectral backpropagation in order to demonstrate robustness for high-dimensional problems, and identify two novel properties of the generator G: (1) there exist aberrant, nonsensical outputs to which G assigns very high likelihood, and (2) the eigenvectors of the metric induced by G over latent space correspond to quasi-disentangled explanatory factors.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/c52fd8ed00b4d3275889532f2f345130af462848",
          "authors": [
            "A. Ramesh",
            "Yann LeCun"
          ]
        },
        {
          "title": "Predicting Future Instance Segmentations by Forecasting Convolutional Features",
          "year": 2018,
          "citations": 96,
          "abstract": "Anticipating future events is an important prerequisite towards intelligent behavior. Video forecasting has been studied as a proxy task towards this goal. Recent work has shown that to predict semantic segmentation of future frames, forecasting at the semantic level is more effective than forecasting RGB frames and then segmenting these. In this paper we consider the more challenging problem of future instance segmentation, which additionally segments out individual objects. To deal with a varying number of output labels per image, we develop a predictive model in the space of fixed-sized convolutional features of the Mask R-CNN instance segmentation model. We apply the \"detection head\" of Mask R-CNN on the predicted features to produce the instance segmentation of future frames. Experiments show that this approach significantly improves over baselines based on optical flow.",
          "venue": "European Conference on Computer Vision",
          "doi": "10.1007/978-3-030-01240-3_36",
          "url": "https://www.semanticscholar.org/paper/cb503d90c0bd9a555a6b99429991c4d6f39e0f70",
          "authors": [
            "Pauline Luc",
            "C. Couprie",
            "Yann LeCun",
            "Jakob Verbeek"
          ]
        },
        {
          "title": "DeSIGN: Design Inspiration from Generative Networks",
          "year": 2018,
          "citations": 131,
          "abstract": "Can an algorithm create original and compelling fashion designs to serve as an inspirational assistant? To help answer this question, we design and investigate different image generation models associated with different loss functions to boost creativity in fashion generation. The dimensions of our explorations include: (i) different Generative Adversarial Networks architectures that start from noise vectors to generate fashion items, (ii) novel loss functions that encourage novelty, inspired from Sharma-Mittal divergence, a generalized mutual information measure for the widely used relative entropies such as Kullback-Leibler, and (iii) a generation process following the key elements of fashion design (disentangling shape and texture components). A key challenge of this study is the evaluation of generated designs and the retrieval of best ones, hence we put together an evaluation protocol associating automatic metrics and human experimental studies that we hope will help ease future research. We show that our proposed creativity criterion yield better overall appreciation than the one employed in Creative Adversarial Networks. In the end, about 61% of our images are thought to be created by human designers rather than by a computer while also being considered original per our human subject experiments, and our proposed loss scores the highest compared to existing losses in both novelty and likability.",
          "venue": "ECCV Workshops",
          "doi": "10.1007/978-3-030-11015-4_5",
          "url": "https://www.semanticscholar.org/paper/e9e605d95a2884cc6a4cdf1745472dec9eb23b88",
          "authors": [
            "Othman Sbai",
            "Mohamed Elhoseiny",
            "Antoine Bordes",
            "Yann LeCun",
            "C. Couprie"
          ]
        },
        {
          "title": "Comparing dynamics: deep neural networks versus glassy systems",
          "year": 2018,
          "citations": 122,
          "abstract": "We analyze numerically the training dynamics of deep neural networks (DNN) by using methods developed in statistical physics of glassy systems. The two main issues we address are (1) the complexity of the loss landscape and of the dynamics within it, and (2) to what extent DNNs share similarities with glassy systems. Our findings, obtained for different architectures and datasets, suggest that during the training process the dynamics slows down because of an increasingly large number of flat directions. At large times, when the loss is approaching zero, the system diffuses at the bottom of the landscape. Despite some similarities with the dynamics of mean-field glassy systems, in particular, the absence of barrier crossing, we find distinctive dynamical behaviors in the two cases, showing that the statistical properties of the corresponding loss and energy landscapes are different. In contrast, when the network is under-parametrized we observe a typical glassy behavior, thus suggesting the existence of different phases depending on whether the network is under-parametrized or over-parametrized.",
          "venue": "International Conference on Machine Learning",
          "doi": "10.1088/1742-5468/ab3281",
          "url": "https://www.semanticscholar.org/paper/fc998c5e7b0fd1609d5a91d700fec3ec9c72838c",
          "authors": [
            "Marco Baity-Jesi",
            "Levent Sagun",
            "M. Geiger",
            "S. Spigler",
            "G. B. Arous",
            "C. Cammarota",
            "Yann LeCun",
            "M. Wyart",
            "G. Biroli"
          ]
        },
        {
          "title": "Universality in halting time",
          "year": 2017,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/00c44c3355b094dd93cb279349485356092cd07d",
          "authors": [
            "Levent Sagun",
            "T. Trogdon",
            "Yann LeCun"
          ]
        },
        {
          "title": "Which Encoding is the Best for Text Classification in Chinese, English, Japanese and Korean?",
          "year": 2017,
          "citations": 72,
          "abstract": "This article offers an empirical study on the different ways of encoding Chinese, Japanese, Korean (CJK) and English languages for text classification. Different encoding levels are studied, including UTF-8 bytes, characters, words, romanized characters and romanized words. For all encoding levels, whenever applicable, we provide comparisons with linear models, fastText and convolutional networks. For convolutional networks, we compare between encoding mechanisms using character glyph images, one-hot (or one-of-n) encoding, and embedding. In total there are 473 models, using 14 large-scale text classification datasets in 4 languages including Chinese, English, Japanese and Korean. Some conclusions from these results include that byte-level one-hot encoding based on UTF-8 consistently produces competitive results for convolutional networks, that word-level n-grams linear models are competitive even without perfect word segmentation, and that fastText provides the best result using character-level n-gram encoding but can overfit when the features are overly rich.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/07466fb914982f55051cc0b236fd524bdcd8bdc7",
          "authors": [
            "Xiang Zhang",
            "Yann LeCun"
          ]
        },
        {
          "title": "Hierarchical loss for classification",
          "year": 2017,
          "citations": 18,
          "abstract": null,
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/15e2bbb28ef53f4b5da6a8c3934c54c1650fb947",
          "authors": [
            "C. Wu",
            "M. Tygert",
            "Yann LeCun"
          ]
        },
        {
          "title": "A hierarchical loss and its problems when classifying non-hierarchically",
          "year": 2017,
          "citations": 31,
          "abstract": "Failing to distinguish between a sheepdog and a skyscraper should be worse and penalized more than failing to distinguish between a sheepdog and a poodle; after all, sheepdogs and poodles are both breeds of dogs. However, existing metrics of failure (so-called “loss” or “win”) used in textual or visual classification/recognition via neural networks seldom leverage a-priori information, such as a sheepdog being more similar to a poodle than to a skyscraper. We define a metric that, inter alia, can penalize failure to distinguish between a sheepdog and a skyscraper more than failure to distinguish between a sheepdog and a poodle. Unlike previously employed possibilities, this metric is based on an ultrametric tree associated with any given tree organization into a semantically meaningful hierarchy of a classifier’s classes. An ultrametric tree is a tree with a so-called ultrametric distance metric such that all leaves are at the same distance from the root. Unfortunately, extensive numerical experiments indicate that the standard practice of training neural networks via stochastic gradient descent with random starting points often drives down the hierarchical loss nearly as much when minimizing the standard cross-entropy loss as when trying to minimize the hierarchical loss directly. Thus, this hierarchical loss is unreliable as an objective for plain, randomly started stochastic gradient descent to minimize; the main value of the hierarchical loss may be merely as a meaningful metric of success of a classifier.",
          "venue": "PLoS ONE",
          "doi": "10.1371/journal.pone.0226222",
          "url": "https://www.semanticscholar.org/paper/35903ec587d50db2d1ae5b26189b0f5c7771edb2",
          "authors": [
            "C. Wu",
            "M. Tygert",
            "Yann LeCun"
          ]
        },
        {
          "title": "Predicting Deeper into the Future of Semantic Segmentation",
          "year": 2017,
          "citations": 246,
          "abstract": "The ability to predict and therefore to anticipate the future is an important attribute of intelligence. It is also of utmost importance in real-time systems, e.g. in robotics or autonomous driving, which depend on visual scene understanding for decision making. While prediction of the raw RGB pixel values in future video frames has been studied in previous work, here we introduce the novel task of predicting semantic segmentations of future frames. Given a sequence of video frames, our goal is to predict segmentation maps of not yet observed video frames that lie up to a second or further in the future. We develop an autoregressive convolutional neural network that learns to iteratively generate multiple frames. Our results on the Cityscapes dataset show that directly predicting future segmentations is substantially better than predicting and then segmenting future RGB frames. Prediction results up to half a second in the future are visually convincing and are much more accurate than those of a baseline based on warping semantic segmentations using optical flow.",
          "venue": "IEEE International Conference on Computer Vision",
          "doi": "10.1109/ICCV.2017.77",
          "url": "https://www.semanticscholar.org/paper/516668a41d6106232a7cd56d20d3b3da343e5f36",
          "authors": [
            "Pauline Luc",
            "N. Neverova",
            "C. Couprie",
            "J. Verbeek",
            "Yann LeCun"
          ]
        },
        {
          "title": "Geometric Deep Learning: Going beyond Euclidean data",
          "year": 2017,
          "citations": 25,
          "abstract": null,
          "venue": "IEEE Signal Processing Magazine",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/7c60897979654a5838638df7a8aa80142a2ff4bd",
          "authors": [
            "M. Bronstein",
            "Joan Bruna",
            "Yann LeCun",
            "Arthur Szlam",
            "P. Vandergheynst"
          ]
        },
        {
          "title": "Proceedings of the International Computer Music Conference 2016 A Fluid Chord Voicing Generator",
          "year": 2017,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/8895fae88182fc5a5623a11c7916b026244f7093",
          "authors": [
            "D. Marcarian",
            "P. Savvidou",
            "B. Willis",
            "M. Skubic",
            "Yann LeCun",
            "K. Perlin",
            "J. Tilmanne",
            "M. Hashimoto",
            "Q. Sun",
            "J. Luo",
            "Y. He"
          ]
        },
        {
          "title": "Adversarially Regularized Autoencoders for Generating Discrete Structures",
          "year": 2017,
          "citations": 79,
          "abstract": "Generative adversarial networks are an effective approach for learning rich latent representations of continuous data, but have proven difficult to apply directly to discrete structured data, such as text sequences or discretized images. Ideally we could encode discrete structures in a continuous code space to avoid this problem, but it is difficult to learn an appropriate general-purpose encoder. In this work, we consider a simple approach for handling these two challenges jointly, employing a discrete structure autoencoder with a code space regularized by generative adversarial training. The model learns a smooth regularized code space while still being able to model the underlying data, and can be used as a discrete GAN with the ability to generate coherent discrete outputs from continuous samples. We demonstrate empirically how key properties of the data are captured in the model's latent space, and evaluate the model itself on the tasks of discrete image generation, text generation, and semi-supervised learning.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/89b139b8b507bdfb8f57b9cc0f09bfcf859bc966",
          "authors": [
            "J. Zhao",
            "Yoon Kim",
            "Kelly W. Zhang",
            "Alexander M. Rush",
            "Yann LeCun"
          ]
        },
        {
          "title": "A Closer Look at Spatiotemporal Convolutions for Action Recognition",
          "year": 2017,
          "citations": 3313,
          "abstract": "In this paper we discuss several forms of spatiotemporal convolutions for video analysis and study their effects on action recognition. Our motivation stems from the observation that 2D CNNs applied to individual frames of the video have remained solid performers in action recognition. In this work we empirically demonstrate the accuracy advantages of 3D CNNs over 2D CNNs within the framework of residual learning. Furthermore, we show that factorizing the 3D convolutional filters into separate spatial and temporal components yields significantly gains in accuracy. Our empirical study leads to the design of a new spatiotemporal convolutional block \"R(2+1)D\" which produces CNNs that achieve results comparable or superior to the state-of-the-art on Sports-1M, Kinetics, UCF101, and HMDB51.",
          "venue": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
          "doi": "10.1109/CVPR.2018.00675",
          "url": "https://www.semanticscholar.org/paper/89c3050522a0bb9820c32dc7444e003ef0d3e2e4",
          "authors": [
            "Du Tran",
            "Heng Wang",
            "L. Torresani",
            "Jamie Ray",
            "Yann LeCun",
            "Manohar Paluri"
          ]
        },
        {
          "title": "Prediction Under Uncertainty with Error-Encoding Networks",
          "year": 2017,
          "citations": 25,
          "abstract": "In this work we introduce a new framework for performing temporal predictions in the presence of uncertainty. It is based on a simple idea of disentangling com- ponents of the future state which are predictable from those which are inherently unpredictable, and encoding the unpredictable components into a low-dimensional latent variable which is fed into the forward model. Our method uses a simple su- pervised training objective which is fast and easy to train. We evaluate it in the context of video prediction on multiple datasets and show that it is able to consi- tently generate diverse predictions without the need for alternating minimization over a latent space or adversarial training.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/bfdb693df3a04fa9645233c444ccd8ec16c6c477",
          "authors": [
            "Mikael Henaff",
            "J. Zhao",
            "Yann LeCun"
          ]
        },
        {
          "title": "Model-Based Planning with Discrete and Continuous Actions",
          "year": 2017,
          "citations": 49,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/c6d78e818b0585144578d80b4d42585cd616709b",
          "authors": [
            "Mikael Henaff",
            "William F. Whitney",
            "Yann LeCun"
          ]
        },
        {
          "title": "Adversarially Regularized Autoencoders",
          "year": 2017,
          "citations": 293,
          "abstract": null,
          "venue": "International Conference on Machine Learning",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/d7f55400fd032d182d465eee91581d5ab845a95d",
          "authors": [
            "J. Zhao",
            "Yoon Kim",
            "Kelly W. Zhang",
            "Alexander M. Rush",
            "Yann LeCun"
          ]
        },
        {
          "title": "Model-Based Planning in Discrete Action Spaces",
          "year": 2017,
          "citations": 17,
          "abstract": "Planning actions using learned and differentiable forward models of the world is a general approach which has a number of desirable properties, including improved sample complexity over model-free RL methods, reuse of learned models across different tasks, and the ability to perform efficient gradient-based optimization in continuous action spaces. However, this approach does not apply straightforwardly when the action space is discrete, which may have limited its adoption. In this work, we introduce two discrete planning tasks inspired by existing question-answering datasets and show that it is in fact possible to effectively perform planning via backprop in discrete action spaces using two simple yet principled modifications. Our experiments show that this approach can significantly outperform model-free RL based methods and supervised imitation learners.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/d86d17f6459978084320d7d313f38f234cf8b899",
          "authors": [
            "Mikael Henaff",
            "William F. Whitney",
            "Yann LeCun"
          ]
        },
        {
          "title": "Predicting Deeper into the Future of Semantic Segmentation — Supplementary Material —",
          "year": 2017,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/de2c8419d8e5e1501f8daa17e10ee46c27adc5e4",
          "authors": [
            "Pauline Luc",
            "N. Neverova",
            "C. Couprie",
            "Jakob Verbeek",
            "Yann LeCun"
          ]
        },
        {
          "title": "+ YY ’ Z X-Residual Prediction Error TargetPredictionObservation Latent 0 State φ f 1 f 2",
          "year": 2017,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/f85ea632dc79e779a6a1b3170013288f55af0d52",
          "authors": [
            "Mikael Henaff",
            "J. Zhao",
            "Yann LeCun"
          ]
        },
        {
          "title": "Tracking the World State with Recurrent Entity Networks",
          "year": 2016,
          "citations": 233,
          "abstract": "We introduce a new model, the Recurrent Entity Network (EntNet). It is equipped with a dynamic long-term memory which allows it to maintain and update a representation of the state of the world as it receives new data. For language understanding tasks, it can reason on-the-fly as it reads text, not just when it is required to answer a question or respond as is the case for a Memory Network (Sukhbaatar et al., 2015). Like a Neural Turing Machine or Differentiable Neural Computer (Graves et al., 2014; 2016) it maintains a fixed size memory and can learn to perform location and content-based read and write operations. However, unlike those models it has a simple parallel architecture in which several memory locations can be updated simultaneously. The EntNet sets a new state-of-the-art on the bAbI tasks, and is the first method to solve all the tasks in the 10k training examples setting. We also demonstrate that it can solve a reasoning task which requires a large number of supporting facts, which other methods are not able to solve, and can generalize past its training horizon. It can also be practically used on large scale datasets such as Children's Book Test, where it obtains competitive performance, reading the story in a single pass.",
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/033dd6cf61a6017e9aa9b46068d3c89082849cf3",
          "authors": [
            "Mikael Henaff",
            "J. Weston",
            "Arthur Szlam",
            "Antoine Bordes",
            "Yann LeCun"
          ]
        },
        {
          "title": "Geometric Deep Learning: Going beyond Euclidean data",
          "year": 2016,
          "citations": 3561,
          "abstract": "Many scientific fields study data with an underlying structure that is non-Euclidean. Some examples include social networks in computational social sciences, sensor networks in communications, functional networks in brain imaging, regulatory networks in genetics, and meshed surfaces in computer graphics. In many applications, such geometric data are large and complex (in the case of social networks, on the scale of billions) and are natural targets for machine-learning techniques. In particular, we would like to use deep neural networks, which have recently proven to be powerful tools for a broad range of problems from computer vision, natural-language processing, and audio analysis. However, these tools have been most successful on data with an underlying Euclidean or grid-like structure and in cases where the invariances of these structures are built into networks used to model them.",
          "venue": "IEEE Signal Processing Magazine",
          "doi": "10.1109/MSP.2017.2693418",
          "url": "https://www.semanticscholar.org/paper/0e779fd59353a7f1f5b559b9d65fa4bfe367890c",
          "authors": [
            "M. Bronstein",
            "Joan Bruna",
            "Yann LeCun",
            "Arthur Szlam",
            "P. Vandergheynst"
          ]
        },
        {
          "title": "Phase 4: DCL System Using Deep Learning Approaches for Land-Based or Ship-Based Real-Time Recognition and Localization of Marine Mammals - Distributed Processing and Big Data Applications",
          "year": 2016,
          "citations": 1,
          "abstract": null,
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/12a1fbbb2a33bbf9fc4bf7a24c5934fb1b9b7c6f",
          "authors": [
            "Peter J. Dugan",
            "C. Clark",
            "Yann LeCun",
            "S. Parijs"
          ]
        },
        {
          "title": "Tunable Efficient Unitary Neural Networks (EUNN) and their application to RNNs",
          "year": 2016,
          "citations": 184,
          "abstract": "Using unitary (instead of general) matrices in artificial neural networks (ANNs) is a promising way to solve the gradient explosion/vanishing problem, as well as to enable ANNs to learn long-term correlations in the data. This approach appears particularly promising for Recurrent Neural Networks (RNNs). In this work, we present a new architecture for implementing an Efficient Unitary Neural Network (EUNNs); its main advantages can be summarized as follows. Firstly, the representation capacity of the unitary space in an EUNN is fully tunable, ranging from a subspace of SU(N) to the entire unitary space. Secondly, the computational complexity for training an EUNN is merely O(1) per parameter. Finally, we test the performance of EUNNs on the standard copying task, the pixel-permuted MNIST digit recognition benchmark as well as the Speech Prediction Test (TIMIT). We find that our architecture significantly outperforms both other state-of-the-art unitary RNNs and the LSTM architecture, in terms of the final performance and/or the wall-clock training speed. EUNNs are thus promising alternatives to RNNs and LSTMs for a wide variety of applications.",
          "venue": "International Conference on Machine Learning",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/1d782819afafe0d391e5b67151cb510e621f243d",
          "authors": [
            "Li Jing",
            "Yichen Shen",
            "T. Dubček",
            "J. Peurifoy",
            "S. Skirlo",
            "Yann LeCun",
            "Max Tegmark",
            "M. Soljačić"
          ]
        },
        {
          "title": "Energy-based Generative Adversarial Network",
          "year": 2016,
          "citations": 1131,
          "abstract": "We introduce the \"Energy-based Generative Adversarial Network\" model (EBGAN) which views the discriminator as an energy function that attributes low energies to the regions near the data manifold and higher energies to other regions. Similar to the probabilistic GANs, a generator is seen as being trained to produce contrastive samples with minimal energies, while the discriminator is trained to assign high energies to these generated samples. Viewing the discriminator as an energy function allows to use a wide variety of architectures and loss functionals in addition to the usual binary classifier with logistic output. Among them, we show one instantiation of EBGAN framework as using an auto-encoder architecture, with the energy being the reconstruction error, in place of the discriminator. We show that this form of EBGAN exhibits more stable behavior than regular GANs during training. We also show that a single-scale architecture can be trained to generate high-resolution images.",
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/2ba23d9b46027e47b4483243871760e315213ffe",
          "authors": [
            "J. Zhao",
            "Michaël Mathieu",
            "Yann LeCun"
          ]
        },
        {
          "title": "Fast Incremental Learning for Off-Road Robot Navigation",
          "year": 2016,
          "citations": 7,
          "abstract": "A promising approach to autonomous driving is machine learning. In such systems, training datasets are created that capture the sensory input to a vehicle as well as the desired response. A disadvantage of using a learned navigation system is that the learning process itself may require a huge number of training examples and a large amount of computing. To avoid the need to collect a large training set of driving examples, we describe a system that takes advantage of the huge number of training examples provided by ImageNet, but is able to adapt quickly using a small training set for the specific driving environment.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/3f1540459ef264051f15ac15cadcc4d924dc79a8",
          "authors": [
            "Artem Provodin",
            "L. Torabi",
            "B. Flepp",
            "Yann LeCun",
            "Michael Sergio",
            "L. Jackel",
            "Urs Muller",
            "Jure Zbontar"
          ]
        },
        {
          "title": "Disentangling factors of variation in deep representation using adversarial training",
          "year": 2016,
          "citations": 509,
          "abstract": "We introduce a conditional generative model for learning to disentangle the hidden factors of variation within a set of labeled observations, and separate them into complementary codes. One code summarizes the specified factors of variation associated with the labels. The other summarizes the remaining unspecified variability. During training, the only available source of supervision comes from our ability to distinguish among different observations belonging to the same class. Examples of such observations include images of a set of labeled objects captured at different viewpoints, or recordings of set of speakers dictating multiple phrases. In both instances, the intra-class diversity is the source of the unspecified factors of variation: each object is observed at multiple viewpoints, and each speaker dictates multiple phrases. Learning to disentangle the specified factors from the unspecified ones becomes easier when strong supervision is possible. Suppose that during training, we have access to pairs of images, where each pair shows two different objects captured from the same viewpoint. This source of alignment allows us to solve our task using existing methods. However, labels for the unspecified factors are usually unavailable in realistic scenarios where data acquisition is not strictly controlled. We address the problem of disentaglement in this more general setting by combining deep convolutional autoencoders with a form of adversarial training. Both factors of variation are implicitly captured in the organization of the learned embedding space, and can be used for solving single-image analogies. Experimental results on synthetic and real datasets show that the proposed method is capable of generalizing to unseen classes and intra-class variabilities.",
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/48a789a15e3572749905f036fcbf3310aee29b79",
          "authors": [
            "Michaël Mathieu",
            "J. Zhao",
            "P. Sprechmann",
            "A. Ramesh",
            "Yann LeCun"
          ]
        },
        {
          "title": "What is the Best Feature Learning Procedure in Hierarchical Recognition Architectures?",
          "year": 2016,
          "citations": 1,
          "abstract": "(This paper was written in November 2011 and never published. It is posted on arXiv.org in its original form in June 2016). Many recent object recognition systems have proposed using a two phase training procedure to learn sparse convolutional feature hierarchies: unsupervised pre-training followed by supervised fine-tuning. Recent results suggest that these methods provide little improvement over purely supervised systems when the appropriate nonlinearities are included. This paper presents an empirical exploration of the space of learning procedures for sparse convolutional networks to assess which method produces the best performance. In our study, we introduce an augmentation of the Predictive Sparse Decomposition method that includes a discriminative term (DPSD). We also introduce a new single phase supervised learning procedure that places an L1 penalty on the output state of each layer of the network. This forces the network to produce sparse codes without the expensive pre-training phase. Using DPSD with a new, complex predictor that incorporates lateral inhibition, combined with multi-scale feature pooling, and supervised refinement, the system achieves a 70.6\\% recognition rate on Caltech-101. With the addition of convolutional training, a 77\\% recognition was obtained on the CIfAR-10 dataset.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/4b5a5d55c37ca2b5e0bfd9bc366a597f749dfc78",
          "authors": [
            "Kevin Jarrett",
            "K. Kavukcuoglu",
            "Karol Gregor",
            "Yann LeCun"
          ]
        },
        {
          "title": "Orthogonal RNNs and Long-Memory Tasks",
          "year": 2016,
          "citations": 43,
          "abstract": null,
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/4ca151307e3be93c6cd14ed403f6162892e7fbed",
          "authors": [
            "Mikael Henaff",
            "Arthur Szlam",
            "Yann LeCun"
          ]
        },
        {
          "title": "Singularity of the Hessian in Deep Learning",
          "year": 2016,
          "citations": 59,
          "abstract": null,
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/5fbc36b30859f5f2f1af4f724531c94b1b1f926a",
          "authors": [
            "Levent Sagun",
            "L. Bottou",
            "Yann LeCun"
          ]
        },
        {
          "title": "Eigenvalues of the Hessian in Deep Learning: Singularity and Beyond",
          "year": 2016,
          "citations": 252,
          "abstract": "We look at the eigenvalues of the Hessian of a loss function before and after training. The eigenvalue distribution is seen to be composed of two parts, the bulk which is concentrated around zero, and the edges which are scattered away from zero. We present empirical evidence for the bulk indicating how over-parametrized the system is, and for the edges that depend on the input data.",
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/8151fbde700614ab25d6165b9ce5f76456c180d4",
          "authors": [
            "Levent Sagun",
            "L. Bottou",
            "Yann LeCun"
          ]
        },
        {
          "title": "Very Deep Convolutional Networks for Natural Language Processing",
          "year": 2016,
          "citations": 323,
          "abstract": "The dominant approach for many NLP tasks are recurrent neural networks, in particular LSTMs, and convolutional neural networks. However, these architectures are rather shallow in comparison to the deep convolutional networks which are very successful in computer vision. We present a new architecture for text processing which operates directly on the character level and uses only small convolutions and pooling operations. We are able to show that the performance of this model increases with the depth: using up to 29 convolutional layers, we report significant improvements over the state-of-the-art on several public text classification tasks. To the best of our knowledge, this is the first time that very deep convolutional nets have been applied to NLP.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/84ca430856a92000e90cd728445ca2241c10ddc3",
          "authors": [
            "Alexis Conneau",
            "Holger Schwenk",
            "Loïc Barrault",
            "Yann LeCun"
          ]
        },
        {
          "title": "Simultaneous Learning of Trees and Representations for Extreme Classification, with Application to Language Modeling",
          "year": 2016,
          "citations": 9,
          "abstract": null,
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/a0049f4e6ae42da87a6edd276618abec5a2e44b0",
          "authors": [
            "Yacine Jernite",
            "A. Choromańska",
            "D. Sontag",
            "Yann LeCun"
          ]
        },
        {
          "title": "Entropy-SGD: biasing gradient descent into wide valleys",
          "year": 2016,
          "citations": 825,
          "abstract": "This paper proposes a new optimization algorithm called Entropy-SGD for training deep neural networks that is motivated by the local geometry of the energy landscape. Local extrema with low generalization error have a large proportion of almost-zero eigenvalues in the Hessian with very few positive or negative eigenvalues. We leverage upon this observation to construct a local-entropy-based objective function that favors well-generalizable solutions lying in large flat regions of the energy landscape, while avoiding poorly-generalizable solutions located in the sharp valleys. Conceptually, our algorithm resembles two nested loops of SGD where we use Langevin dynamics in the inner loop to compute the gradient of the local entropy before each update of the weights. We show that the new objective has a smoother energy landscape and show improved generalization over SGD using uniform stability, under certain assumptions. Our experiments on convolutional and recurrent networks demonstrate that Entropy-SGD compares favorably to state-of-the-art techniques in terms of generalization error and training time.",
          "venue": "International Conference on Learning Representations",
          "doi": "10.1088/1742-5468/ab39d9",
          "url": "https://www.semanticscholar.org/paper/b6583fe9c9dc52bb129aff4cefc60519349f3b4c",
          "authors": [
            "P. Chaudhari",
            "A. Choromańska",
            "Stefano Soatto",
            "Yann LeCun",
            "Carlo Baldassi",
            "C. Borgs",
            "J. Chayes",
            "Levent Sagun",
            "R. Zecchina"
          ]
        },
        {
          "title": "Phase 1: DCL System Research Using Advanced Approaches for Land-based or Ship-based Real-Time Recognition and Localization of Marine Mammals - HPC System Implementation",
          "year": 2016,
          "citations": 1,
          "abstract": "We aim to investigate advancing the state of the art of detection, classification and localization (DCL) in the field of bioacoustics. The two primary goals are to develop transferable technologies for detection and classification in: (1) the area of advanced algorithms, such as deep learning and other methods; and (2) advanced systems, capable of real-time and archival and processing. This project will focus on long-term, continuous datasets to provide automatic recognition, minimizing human time to annotate the signals. Effort will begin by focusing on several years of multi-channel acoustic data collected in the Stellwagen Bank National Marine Sanctuary (SBNMS) between 2006 and 2010. Our efforts will incorporate existing technologies in the bioacoustics signal processing community, advanced high performance computing (HPC) systems, and new approaches aimed at automatically detecting-classifying and measuring features for species-specific marine mammal sounds within passive acoustic data.",
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/ba19e986dffe20dca60b502aeb097018d0af0f53",
          "authors": [
            "Peter J. Dugan",
            "C. Clark",
            "Yann LeCun",
            "S. Parijs"
          ]
        },
        {
          "title": "Phase 2: DCL System Using Deep Learning Approaches for Land-based or Ship-based Real-Time Recognition and Localization of Marine Mammals - Machine Learning Detection Algorithms",
          "year": 2016,
          "citations": 2,
          "abstract": null,
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/c05d6dc329a0c7a52794badaeb6d86df38a27b8e",
          "authors": [
            "Peter J. Dugan",
            "C. Clark",
            "Yann LeCun",
            "S. Parijs"
          ]
        },
        {
          "title": "Phase 3: DCL System Using Deep Learning Approaches for Land-based or Ship-based Real-Time Recognition and Localization of Marine Mammals - Bioacoustic Applicaitons",
          "year": 2016,
          "citations": 0,
          "abstract": null,
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/e1240e95706d52160a7c51c4f3b1fed4e42658a2",
          "authors": [
            "Peter J. Dugan",
            "C. Clark",
            "Yann LeCun",
            "S. Parijs"
          ]
        },
        {
          "title": "Recurrent Orthogonal Networks and Long-Memory Tasks",
          "year": 2016,
          "citations": 137,
          "abstract": "Although RNNs have been shown to be powerful tools for processing sequential data, finding architectures or optimization strategies that allow them to model very long term dependencies is still an active area of research. In this work, we carefully analyze two synthetic datasets originally outlined in (Hochreiter and Schmidhuber, 1997) which are used to evaluate the ability of RNNs to store information over many time steps. We explicitly construct RNN solutions to these problems, and using these constructions, illuminate both the problems themselves and the way in which RNNs store different types of information in their hidden states. These constructions furthermore explain the success of recent methods that specify unitary initializations or constraints on the transition matrices.",
          "venue": "International Conference on Machine Learning",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/ef3152106e7f4d05ad8d32a5b90d3790c5cdef24",
          "authors": [
            "Mikael Henaff",
            "Arthur Szlam",
            "Yann LeCun"
          ]
        },
        {
          "title": "Very Deep Convolutional Networks for Text Classification",
          "year": 2016,
          "citations": 999,
          "abstract": "The dominant approach for many NLP tasks are recurrent neural networks, in particular LSTMs, and convolutional neural networks. However, these architectures are rather shallow in comparison to the deep convolutional networks which have pushed the state-of-the-art in computer vision. We present a new architecture (VDCNN) for text processing which operates directly at the character level and uses only small convolutions and pooling operations. We are able to show that the performance of this model increases with the depth: using up to 29 convolutional layers, we report improvements over the state-of-the-art on several public text classification tasks. To the best of our knowledge, this is the first time that very deep convolutional nets have been applied to text processing.",
          "venue": "Conference of the European Chapter of the Association for Computational Linguistics",
          "doi": "10.18653/V1/E17-1104",
          "url": "https://www.semanticscholar.org/paper/f797fd44b9ddd5845611eb7a705ca9464a8819d1",
          "authors": [
            "Holger Schwenk",
            "Loïc Barrault",
            "Alexis Conneau",
            "Yann LeCun"
          ]
        },
        {
          "title": "Guest Editorial: Deep Learning",
          "year": 2015,
          "citations": 35,
          "abstract": null,
          "venue": "International Journal of Computer Vision",
          "doi": "10.1007/s11263-015-0813-1",
          "url": "https://www.semanticscholar.org/paper/08ee53dac878ee6ab1e5cf06824713bed614e17c",
          "authors": [
            "Marc'Aurelio Ranzato",
            "Geoffrey E. Hinton",
            "Yann LeCun"
          ]
        },
        {
          "title": "Universality in halting time and its applications in optimization",
          "year": 2015,
          "citations": 5,
          "abstract": null,
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/0bc66655d3c9ad7ab4f44e19b6777add3d83643c",
          "authors": [
            "Levent Sagun",
            "T. Trogdon",
            "Yann LeCun"
          ]
        },
        {
          "title": "Complex-valued convolutional networks yield data-driven multiscale windowed spectra",
          "year": 2015,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/13e03191c8d83903661de9fba9b2309d990e2c84",
          "authors": [
            "Joan Bruna",
            "Soumith Chintala",
            "Yann LeCun",
            "Serkan Piantino",
            "Arthur Szlam",
            "M. Tygert"
          ]
        },
        {
          "title": "Binary embeddings with structured hashed projections",
          "year": 2015,
          "citations": 33,
          "abstract": "We consider the hashing mechanism for constructing binary embeddings, that involves pseudo-random projections followed by nonlinear (sign function) mappings. The pseudorandom projection is described by a matrix, where not all entries are independent random variables but instead a fixed \"budget of randomness\" is distributed across the matrix. Such matrices can be efficiently stored in sub-quadratic or even linear space, provide reduction in randomness usage (i.e. number of required random values), and very often lead to computational speed ups. We prove several theoretical results showing that projections via various structured matrices followed by nonlinear mappings accurately preserve the angular distance between input high-dimensional vectors. To the best of our knowledge, these results are the first that give theoretical ground for the use of general structured matrices in the nonlinear setting. We empirically verify our theoretical findings and show the dependence of learning via structured hashed projections on the performance of neural network as well as nearest neighbor classifier.",
          "venue": "International Conference on Machine Learning",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/16a26289d7c37e6a0179fa57b14a327286696d33",
          "authors": [
            "A. Choromańska",
            "K. Choromanski",
            "Mariusz Bojarski",
            "Tony Jebara",
            "Sanjiv Kumar",
            "Yann LeCun"
          ]
        },
        {
          "title": "Deep multi-scale video prediction beyond mean square error",
          "year": 2015,
          "citations": 1939,
          "abstract": "Learning to predict future images from a video sequence involves the construction of an internal representation that models the image evolution accurately, and therefore, to some degree, its content and dynamics. This is why pixel-space video prediction may be viewed as a promising avenue for unsupervised feature learning. In addition, while optical flow has been a very studied problem in computer vision for a long time, future frame prediction is rarely approached. Still, many vision applications could benefit from the knowledge of the next frames of videos, that does not require the complexity of tracking every pixel trajectories. In this work, we train a convolutional network to generate future frames given an input sequence. To deal with the inherently blurry predictions obtained from the standard Mean Squared Error (MSE) loss function, we propose three different and complementary feature learning strategies: a multi-scale architecture, an adversarial training method, and an image gradient difference loss function. We compare our predictions to different published results based on recurrent neural networks on the UCF101 dataset",
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/17fa1c2a24ba8f731c8b21f1244463bc4b465681",
          "authors": [
            "Michaël Mathieu",
            "C. Couprie",
            "Yann LeCun"
          ]
        },
        {
          "title": "Deep Learning",
          "year": 2015,
          "citations": 39366,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/2913c2bf3f92b5ae369400a42b2d27cc5bc05ecb",
          "authors": [
            "Yann LeCun",
            "Yoshua Bengio",
            "Geoffrey E. Hinton"
          ]
        },
        {
          "title": "A theoretical argument for complex-valued convolutional networks",
          "year": 2015,
          "citations": 10,
          "abstract": null,
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/2eff9844bddfcabe7b3f16c07fe5dad20ccedd53",
          "authors": [
            "Joan Bruna",
            "Soumith Chintala",
            "Yann LeCun",
            "Serkan Piantino",
            "Arthur Szlam",
            "M. Tygert"
          ]
        },
        {
          "title": "Universal halting times in optimization and machine learning",
          "year": 2015,
          "citations": 9,
          "abstract": "The authors present empirical distributions for the halting time (measured by the number of iterations to reach a given accuracy) of optimization algorithms applied to two random systems: spin glasses and deep learning. Given an algorithm, which we take to be both the optimization routine and the form of the random landscape, the fluctuations of the halting time follow a distribution that, after centering and scaling, remains unchanged even when the distribution on the landscape is changed. We observe two qualitative classes: A Gumbel-like distribution that appears in Google searches, human decision times, the QR eigenvalue algorithm and spin glasses, and a Gaussian-like distribution that appears in conjugate gradient method, deep network with MNIST input data and deep network with random input data. This empirical evidence suggests presence of a class of distributions for which the halting time is independent of the underlying distribution under some conditions.",
          "venue": "",
          "doi": "10.1090/qam/1483",
          "url": "https://www.semanticscholar.org/paper/30dd56bcb013893330d48829f5c0d7c02ee2da64",
          "authors": [
            "Levent Sagun",
            "T. Trogdon",
            "Yann LeCun"
          ]
        },
        {
          "title": "Unsupervised Feature Learning from Temporal Data",
          "year": 2015,
          "citations": 35,
          "abstract": "Current state-of-the-art classification and detection algorithms rely on supervised training. In this work we study unsupervised feature learning in the context of temporally coherent video data. We focus on feature learning from unlabeled video data, using the assumption that adjacent video frames contain semantically similar information. This assumption is exploited to train a convolutional pooling auto-encoder regularized by slowness and sparsity. We establish a connection between slow feature learning to metric learning and show that the trained encoder can be used to define a more temporally and semantically coherent metric.",
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/394cbf2d589eadcfbdbdaaed65c77532b9c856af",
          "authors": [
            "Ross Goroshin",
            "Joan Bruna",
            "Jonathan Tompson",
            "D. Eigen",
            "Yann LeCun"
          ]
        },
        {
          "title": "Character-level Convolutional Networks for Text Classification",
          "year": 2015,
          "citations": 6575,
          "abstract": "This article offers an empirical exploration on the use of character-level convolutional networks (ConvNets) for text classification. We constructed several large-scale datasets to show that character-level convolutional networks could achieve state-of-the-art or competitive results. Comparisons are offered against traditional models such as bag of words, n-grams and their TFIDF variants, and deep learning models such as word-based ConvNets and recurrent neural networks.",
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/51a55df1f023571a7e07e338ee45a3e3d66ef73e",
          "authors": [
            "Xiang Zhang",
            "J. Zhao",
            "Yann LeCun"
          ]
        },
        {
          "title": "High Performance Computer Acoustic Data Accelerator: A New System for Exploring Marine Mammal Acoustics for Big Data Applications",
          "year": 2015,
          "citations": 15,
          "abstract": "This paper presents a new software model designed for distributed sonic signal detection runtime using machine learning algorithms called DeLMA. A new algorithm--Acoustic Data-mining Accelerator (ADA)--is also presented. ADA is a robust yet scalable solution for efficiently processing big sound archives using distributing computing technologies. Together, DeLMA and the ADA algorithm provide a powerful tool currently being used by the Bioacoustics Research Program (BRP) at the Cornell Lab of Ornithology, Cornell University. This paper provides a high level technical overview of the system, and discusses various aspects of the design. Basic runtime performance and project summary are presented. The DeLMA-ADA baseline performance comparing desktop serial configuration to a 64 core distributed HPC system shows as much as a 44 times faster increase in runtime execution. Performance tests using 48 cores on the HPC shows a 9x to 12x efficiency over a 4 core desktop solution. Project summary results for 19 east coast deployments show that the DeLMA-ADA solution has processed over three million channel hours of sound to date.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/6df3dc585e32f3b1cb49228d94a5469c30d79d2b",
          "authors": [
            "Peter J. Dugan",
            "J. Zollweg",
            "Marian Popescu",
            "D. Risch",
            "H. Glotin",
            "Yann LeCun",
            "C. Clark"
          ]
        },
        {
          "title": "Very deep multilingual convolutional neural networks for LVCSR",
          "year": 2015,
          "citations": 225,
          "abstract": "Convolutional neural networks (CNNs) are a standard component of many current state-of-the-art Large Vocabulary Continuous Speech Recognition (LVCSR) systems. However, CNNs in LVCSR have not kept pace with recent advances in other domains where deeper neural networks provide superior performance. In this paper we propose a number of architectural advances in CNNs for LVCSR. First, we introduce a very deep convolutional network architecture with up to 14 weight layers. There are multiple convolutional layers before each pooling layer, with small 3×3 kernels, inspired by the VGG Imagenet 2014 architecture. Then, we introduce multilingual CNNs with multiple untied layers. Finally, we introduce multi-scale input features aimed at exploiting more context at negligible computational cost. We evaluate the improvements first on a Babel task for low resource speech recognition, obtaining an absolute 5.77% WER improvement over the baseline PLP DNN by training our CNN on the combined data of six different languages. We then evaluate the very deep CNNs on the Hub5'00 benchmark (using the 262 hours of SWB-1 training data) achieving a word error rate of 11.8% after cross-entropy training, a 1.4% WER improvement (10.6% relative) over the best published CNN result so far.",
          "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
          "doi": "10.1109/ICASSP.2016.7472620",
          "url": "https://www.semanticscholar.org/paper/77b839147551e024a26b07d896677b38d2b327b7",
          "authors": [
            "Tom Sercu",
            "Christian Puhrsch",
            "Brian Kingsbury",
            "Yann LeCun"
          ]
        },
        {
          "title": "Source separation with scattering Non-Negative Matrix Factorization",
          "year": 2015,
          "citations": 14,
          "abstract": null,
          "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
          "doi": "10.1109/ICASSP.2015.7178296",
          "url": "https://www.semanticscholar.org/paper/810c3027863e021041074a23af5deb6307a0f1ca",
          "authors": [
            "Joan Bruna",
            "P. Sprechmann",
            "Yann LeCun"
          ]
        },
        {
          "title": "Universum Prescription: Regularization Using Unlabeled Data",
          "year": 2015,
          "citations": 31,
          "abstract": "\n \n This paper shows that simply prescribing \"none of the above\" labels to unlabeled data has a beneficial regularization effect to supervised learning. We call it universum prescription by the fact that the prescribed labels cannot be one of the supervised labels. In spite of its simplicity, universum prescription obtained competitive results in training deep convolutional networks for CIFAR-10, CIFAR-100, STL-10 and ImageNet datasets. A qualitative justification of these approaches using Rademacher complexity is presented. The effect of a regularization parameter — probability of sampling from unlabeled data — is also studied empirically.\n \n",
          "venue": "AAAI Conference on Artificial Intelligence",
          "doi": "10.1609/aaai.v31i1.10768",
          "url": "https://www.semanticscholar.org/paper/a9b4fc31e6c0253a8924d6fcd19c70c4ac6f3db2",
          "authors": [
            "Xiang Zhang",
            "Yann LeCun"
          ]
        },
        {
          "title": "Stereo Matching by Training a Convolutional Neural Network to Compare Image Patches",
          "year": 2015,
          "citations": 1428,
          "abstract": "We present a method for extracting depth information from a rectified image pair. Our approach focuses on the first stage of many stereo algorithms: the matching cost computation. We approach the problem by learning a similarity measure on small image patches using a convolutional neural network. Training is carried out in a supervised manner by constructing a binary classification data set with examples of similar and dissimilar pairs of patches. We examine two network architectures for this task: one tuned for speed, the other for accuracy. The output of the convolutional neural network is used to initialize the stereo matching cost. A series of post-processing steps follow: cross-based cost aggregation, semiglobal matching, a left-right consistency check, subpixel enhancement, a median filter, and a bilateral filter. We evaluate our method on the KITTI 2012, KITTI 2015, and Middlebury stereo data sets and show that it outperforms other approaches on all three data sets.",
          "venue": "Journal of machine learning research",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/ad3e7515c61ccdc2c36887e7d4929c78904881db",
          "authors": [
            "Jure Zbontar",
            "Yann LeCun"
          ]
        },
        {
          "title": "Stacked What-Where Auto-encoders",
          "year": 2015,
          "citations": 262,
          "abstract": "We present a novel architecture, the \"stacked what-where auto-encoders\" (SWWAE), which integrates discriminative and generative pathways and provides a unified approach to supervised, semi-supervised and unsupervised learning without relying on sampling during training. An instantiation of SWWAE uses a convolutional net (Convnet) (LeCun et al. (1998)) to encode the input, and employs a deconvolutional net (Deconvnet) (Zeiler et al. (2010)) to produce the reconstruction. The objective function includes reconstruction terms that induce the hidden states in the Deconvnet to be similar to those of the Convnet. Each pooling layer produces two sets of variables: the \"what\" which are fed to the next layer, and its complementary variable \"where\" that are fed to the corresponding layer in the generative decoder.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/cba5fbd40767a27d20e346a108b8867ac8591a27",
          "authors": [
            "J. Zhao",
            "Michaël Mathieu",
            "Ross Goroshin",
            "Yann LeCun"
          ]
        },
        {
          "title": "Super-Resolution with Deep Convolutional Sufficient Statistics",
          "year": 2015,
          "citations": 337,
          "abstract": "Inverse problems in image and audio, and super-resolution in particular, can be seen as high-dimensional structured prediction problems, where the goal is to characterize the conditional distribution of a high-resolution output given its low-resolution corrupted observation. When the scaling ratio is small, point estimates achieve impressive performance, but soon they suffer from the regression-to-the-mean problem, result of their inability to capture the multi-modality of this conditional distribution. Modeling high-dimensional image and audio distributions is a hard task, requiring both the ability to model complex geometrical structures and textured regions. In this paper, we propose to use as conditional model a Gibbs distribution, where its sufficient statistics are given by deep convolutional neural networks. The features computed by the network are stable to local deformation, and have reduced variance when the input is a stationary texture. These properties imply that the resulting sufficient statistics minimize the uncertainty of the target signals given the degraded observations, while being highly informative. The filters of the CNN are initialized by multiscale complex wavelets, and then we propose an algorithm to fine-tune them by estimating the gradient of the conditional log-likelihood, which bears some similarities with Generative Adversarial Networks. We evaluate experimentally the proposed approach in the image super-resolution task, but the approach is general and could be used in other challenging ill-posed problems such as audio bandwidth extension.",
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/cd108ed4f69b754cf0a5f3eb74d6c1949ea6674d",
          "authors": [
            "Joan Bruna",
            "P. Sprechmann",
            "Yann LeCun"
          ]
        },
        {
          "title": "Open Problem: The landscape of the loss surfaces of multilayer networks",
          "year": 2015,
          "citations": 127,
          "abstract": null,
          "venue": "Annual Conference Computational Learning Theory",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/d6739de41e880e3db525af91b9d19b2986aa0655",
          "authors": [
            "A. Choromańska",
            "Yann LeCun",
            "G. B. Arous"
          ]
        },
        {
          "title": "Learning to Linearize Under Uncertainty",
          "year": 2015,
          "citations": 144,
          "abstract": "Training deep feature hierarchies to solve supervised learning tasks has achieved state of the art performance on many problems in computer vision. However, a principled way in which to train such hierarchies in the unsupervised setting has remained elusive. In this work we suggest a new architecture and loss for training deep feature hierarchies that linearize the transformations observed in unlabeled natural video sequences. This is done by training a generative model to predict video frames. We also address the problem of inherent uncertainty in prediction by introducing latent variables that are non-deterministic functions of the input into the network architecture.",
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/dd2fa69647160bb2ea25dcc7b2f6409b01e40222",
          "authors": [
            "Ross Goroshin",
            "Michaël Mathieu",
            "Yann LeCun"
          ]
        },
        {
          "title": "Deep Convolutional Networks on Graph-Structured Data",
          "year": 2015,
          "citations": 1632,
          "abstract": "Deep Learning's recent successes have mostly relied on Convolutional Networks, which exploit fundamental statistical properties of images, sounds and video data: the local stationarity and multi-scale compositional structure, that allows expressing long range interactions in terms of shorter, localized interactions. However, there exist other important examples, such as text documents or bioinformatic data, that may lack some or all of these strong statistical regularities. \nIn this paper we consider the general question of how to construct deep architectures with small learning complexity on general non-Euclidean domains, which are typically unknown and need to be estimated from the data. In particular, we develop an extension of Spectral Networks which incorporates a Graph Estimation procedure, that we test on large-scale classification problems, matching or improving over Dropout Networks with far less parameters to estimate.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/e49ff72d420c8d72e62a9353e3abc053445e59bd",
          "authors": [
            "Mikael Henaff",
            "Joan Bruna",
            "Yann LeCun"
          ]
        },
        {
          "title": "Text Understanding from Scratch",
          "year": 2015,
          "citations": 564,
          "abstract": "This article demontrates that we can apply deep learning to text understanding from character-level inputs all the way up to abstract text concepts, using temporal convolutional networks (ConvNets). We apply ConvNets to various large-scale datasets, including ontology classification, sentiment analysis, and text categorization. We show that temporal ConvNets can achieve astonishing performance without the knowledge of words, phrases, sentences and any other syntactic or semantic structures with regards to a human language. Evidence shows that our models can work for both English and Chinese.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/f1b0df6b2977d28e55df82576b108e4f5d87e044",
          "authors": [
            "Xiang Zhang",
            "Yann LeCun"
          ]
        },
        {
          "title": "A Mathematical Motivation for Complex-Valued Convolutional Networks",
          "year": 2015,
          "citations": 106,
          "abstract": "Abstract A complex-valued convolutional network (convnet) implements the repeated application of the following composition of three operations, recursively applying the composition to an input vector of nonnegative real numbers: (1) convolution with complex-valued vectors, followed by (2) taking the absolute value of every entry of the resulting vectors, followed by (3) local averaging. For processing real-valued random vectors, complex-valued convnets can be viewed as data-driven multiscale windowed power spectra, data-driven multiscale windowed absolute spectra, data-driven multiwavelet absolute values, or (in their most general configuration) data-driven nonlinear multiwavelet packets. Indeed, complex-valued convnets can calculate multiscale windowed spectra when the convnet filters are windowed complex-valued exponentials. Standard real-valued convnets, using rectified linear units (ReLUs), sigmoidal (e.g., logistic or tanh) nonlinearities, or max pooling, for example, do not obviously exhibit the same exact correspondence with data-driven wavelets (whereas for complex-valued convnets, the correspondence is much more than just a vague analogy). Courtesy of the exact correspondence, the remarkably rich and rigorous body of mathematical analysis for wavelets applies directly to (complex-valued) convnets.",
          "venue": "Neural Computation",
          "doi": "10.1162/NECO_a_00824",
          "url": "https://www.semanticscholar.org/paper/f55fe2b4344f015927a834d8ad6f52a35c3a8c8e",
          "authors": [
            "M. Tygert",
            "Joan Bruna",
            "Soumith Chintala",
            "Yann LeCun",
            "Serkan Piantino",
            "Arthur Szlam"
          ]
        },
        {
          "title": "Joint Training of a Convolutional Network and a Graphical Model for Human Pose Estimation",
          "year": 2014,
          "citations": 1582,
          "abstract": "This paper proposes a new hybrid architecture that consists of a deep Convolu-tional Network and a Markov Random Field. We show how this architecture is successfully applied to the challenging problem of articulated human pose estimation in monocular images. The architecture can exploit structural domain constraints such as geometric relationships between body joint locations. We show that joint training of these two model paradigms improves performance and allows us to significantly outperform existing state-of-the-art techniques.",
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/12ecc2d786080f638a01b9999518e9386baa157d",
          "authors": [
            "Jonathan Tompson",
            "Arjun Jain",
            "Yann LeCun",
            "C. Bregler"
          ]
        },
        {
          "title": "Computing the stereo matching cost with a convolutional neural network",
          "year": 2014,
          "citations": 796,
          "abstract": "We present a method for extracting depth information from a rectified image pair. We train a convolutional neural network to predict how well two image patches match and use it to compute the stereo matching cost. The cost is refined by cross-based cost aggregation and semiglobal matching, followed by a left-right consistency check to eliminate errors in the occluded regions. Our stereo method achieves an error rate of 2.61% on the KITTI stereo dataset and is currently (August 2014) the top performing method on this dataset.",
          "venue": "Computer Vision and Pattern Recognition",
          "doi": "10.1109/CVPR.2015.7298767",
          "url": "https://www.semanticscholar.org/paper/2fdd82708a99cec2bcd45c2c7f337a9beccced04",
          "authors": [
            "Jure Zbontar",
            "Yann LeCun"
          ]
        },
        {
          "title": "Fast Convolutional Nets With fbfft: A GPU Performance Evaluation",
          "year": 2014,
          "citations": 354,
          "abstract": "We examine the performance profile of Convolutional Neural Network training on the current generation of NVIDIA Graphics Processing Units. We introduce two new Fast Fourier Transform convolution implementations: one based on NVIDIA's cuFFT library, and another based on a Facebook authored FFT implementation, fbfft, that provides significant speedups over cuFFT (over 1.5x) for whole CNNs. Both of these convolution implementations are available in open source, and are faster than NVIDIA's cuDNN implementation for many common convolutional layers (up to 23.5x for some synthetic kernel configurations). We discuss different performance regimes of convolutions, comparing areas where straightforward time domain convolutions outperform Fourier frequency domain convolutions. Details on algorithmic applications of NVIDIA GPU hardware specifics in the implementation of fbfft are also provided.",
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/326d65827307862ddc3d39b84ebc662e83ff95b3",
          "authors": [
            "Nicolas Vasilache",
            "Jeff Johnson",
            "Michaël Mathieu",
            "Soumith Chintala",
            "Serkan Piantino",
            "Yann LeCun"
          ]
        },
        {
          "title": "Explorations on high dimensional landscapes",
          "year": 2014,
          "citations": 65,
          "abstract": "Finding minima of a real valued non-convex function over a high dimensional space is a major challenge in science. We provide evidence that some such functions that are defined on high dimensional domains have a narrow band of values whose pre-image contains the bulk of its critical points. This is in contrast with the low dimensional picture in which this band is wide. Our simulations agree with the previous theoretical work on spin glasses that proves the existence of such a band when the dimension of the domain tends to infinity. Furthermore our experiments on teacher-student networks with the MNIST dataset establish a similar phenomenon in deep networks. We finally observe that both the gradient descent and the stochastic gradient descent methods can reach this level within the same number of steps.",
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/540393e544757f103efd549ac5196de117950f94",
          "authors": [
            "Levent Sagun",
            "V. U. Güney",
            "Yann LeCun"
          ]
        },
        {
          "title": "The bottlenecks in human letter recognition: a computational model",
          "year": 2014,
          "citations": 5,
          "abstract": null,
          "venue": "",
          "doi": "10.7490/F1000RESEARCH.1095738.1",
          "url": "https://www.semanticscholar.org/paper/553ad7d282e2c2bbad301c119e9aaaa9e8fa369a",
          "authors": [
            "Avi Ziskind",
            "Olivier J. Hénaff",
            "Yann LeCun",
            "D. Pelli"
          ]
        },
        {
          "title": "The Loss Surface of Multilayer Networks",
          "year": 2014,
          "citations": 146,
          "abstract": null,
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/6d9cb3d3c0330a6c2f42d159a3a706b6b49744b2",
          "authors": [
            "A. Choromańska",
            "Mikael Henaff",
            "Michaël Mathieu",
            "G. B. Arous",
            "Yann LeCun"
          ]
        },
        {
          "title": "Toward real-time indoor semantic segmentation using depth information",
          "year": 2014,
          "citations": 17,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/84e611d7b24323fda931a0e10aee59d8824e58bf",
          "authors": [
            "C. Couprie",
            "C. Farabet",
            "Laurent Najman",
            "Yann LeCun"
          ]
        },
        {
          "title": "Convolutional nets and watershed cuts for real-time semantic Labeling of RGBD videos",
          "year": 2014,
          "citations": 36,
          "abstract": null,
          "venue": "Journal of machine learning research",
          "doi": "10.5555/2627435.2697077",
          "url": "https://www.semanticscholar.org/paper/8934e44350ca741f7623bf26f89d43835ece0113",
          "authors": [
            "C. Couprie",
            "C. Farabet",
            "Laurent Najman",
            "Yann LeCun"
          ]
        },
        {
          "title": "Differentially- and non-differentially-private random decision trees",
          "year": 2014,
          "citations": 31,
          "abstract": "We consider supervised learning with random decision trees, where the tree construction is completely random. The method is popularly used and works well in practice despite the simplicity of the setting, but its statistical mechanism is not yet well-understood. In this paper we provide strong theoretical guarantees regarding learning with random decision trees. We analyze and compare three different variants of the algorithm that have minimal memory requirements: majority voting, threshold averaging and probabilistic averaging. The random structure of the tree enables us to adapt these methods to a differentially-private setting thus we also propose differentially-private versions of all three schemes. We give upper-bounds on the generalization error and mathematically explain how the accuracy depends on the number of random decision trees. Furthermore, we prove that only logarithmic (in the size of the dataset) number of independently selected random decision trees suffice to correctly classify most of the data, even when differential-privacy guarantees must be maintained. We empirically show that majority voting and threshold averaging give the best accuracy, also for conservative users requiring high privacy guarantees. Furthermore, we demonstrate that a simple majority voting rule is an especially good candidate for the differentially-private classifier since it is much less sensitive to the choice of forest parameters than other methods.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/a49c17b31a6d3a526b030927dace6919b6a68603",
          "authors": [
            "Mariusz Bojarski",
            "A. Choromańska",
            "K. Choromanski",
            "Yann LeCun"
          ]
        },
        {
          "title": "Audio Source Separation with Discriminative Scattering Networks",
          "year": 2014,
          "citations": 4,
          "abstract": "Many monaural signal decomposition techniques proposed in the literature operate on a feature space consisting of a time-frequency representation of the input data. A challenge faced by these approaches is to effectively exploit the temporal dependencies of the signals at scales larger than the duration of a time-frame. In this work we propose to tackle this problem by modeling the signals using a time-frequency representation with multiple temporal resolutions. For this reason we use a signal representation that consists of a pyramid of wavelet scattering operators, which generalizes Constant Q Transforms CQT with extra layers of convolution and complex modulus. We first show that learning standard models with this multi-resolution setting improves source separation results over fixed-resolution methods. As study case, we use Non-Negative Matrix Factorizations NMF that has been widely considered in many audio application. Then, we investigate the inclusion of the proposed multi-resolution setting into a discriminative training regime. We discuss several alternatives using different deep neural network architectures, and our preliminary experiments suggest that in this task, finite impulse, multi-resolution Convolutional Networks are a competitive baseline compared to recurrent alternatives.",
          "venue": "Latent Variable Analysis and Signal Separation",
          "doi": "10.1007/978-3-319-22482-4_30",
          "url": "https://www.semanticscholar.org/paper/a7cc2b78afcdbbfa2f8ba41addec2827c33f89c7",
          "authors": [
            "P. Sprechmann",
            "Joan Bruna",
            "Yann LeCun"
          ]
        },
        {
          "title": "The Loss Surfaces of Multilayer Networks",
          "year": 2014,
          "citations": 1246,
          "abstract": "We study the connection between the highly non-convex loss function of a simple model of the fully-connected feed-forward neural network and the Hamiltonian of the spherical spin-glass model under the assumptions of: i) variable independence, ii) redundancy in network parametrization, and iii) uniformity. These assumptions enable us to explain the complexity of the fully decoupled neural network through the prism of the results from random matrix theory. We show that for large-size decoupled networks the lowest critical values of the random loss function form a layered structure and they are located in a well-defined band lower-bounded by the global minimum. The number of local minima outside that band diminishes exponentially with the size of the network. We empirically verify that the mathematical model exhibits similar behavior as the computer simulations, despite the presence of high dependencies in real networks. We conjecture that both simulated annealing and SGD converge to the band of low critical points, and that all critical points found there are local minima of high quality measured by the test error. This emphasizes a major difference between largeand small-size networks where for the latter poor quality local minima have nonzero probability of being recovered. Finally, we prove that recovering the global minimum becomes harder as the network size increases and that it is in practice irrelevant as global minimum often leads to overfitting.",
          "venue": "International Conference on Artificial Intelligence and Statistics",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/ad8a12a19e74d9788f8fe92f5c0dfea7b6a52aba",
          "authors": [
            "A. Choromańska",
            "Mikael Henaff",
            "Michaël Mathieu",
            "G. B. Arous",
            "Yann LeCun"
          ]
        },
        {
          "title": "Real-Time Continuous Pose Recovery of Human Hands Using Convolutional Networks",
          "year": 2014,
          "citations": 801,
          "abstract": null,
          "venue": "ACM Transactions on Graphics",
          "doi": "10.1145/2629500",
          "url": "https://www.semanticscholar.org/paper/ae639e4bdd2e6a11bc44ff7f1ae53cd25462042b",
          "authors": [
            "Jonathan Tompson",
            "Murphy Stein",
            "Yann LeCun",
            "K. Perlin"
          ]
        },
        {
          "title": "Fast Approximation of Rotations and Hessians matrices",
          "year": 2014,
          "citations": 26,
          "abstract": "A new method to represent and approximate rotation matrices is introduced. The method represents approximations of a rotation matrix $Q$ with linearithmic complexity, i.e. with $\\frac{1}{2}n\\lg(n)$ rotations over pairs of coordinates, arranged in an FFT-like fashion. The approximation is \"learned\" using gradient descent. It allows to represent symmetric matrices $H$ as $QDQ^T$ where $D$ is a diagonal matrix. It can be used to approximate covariance matrix of Gaussian models in order to speed up inference, or to estimate and track the inverse Hessian of an objective function by relating changes in parameters to changes in gradient along the trajectory followed by the optimization procedure. Experiments were conducted to approximate synthetic matrices, covariance matrices of real data, and Hessian matrices of objective functions involved in machine learning problems.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/cd7c5cbc246e42ebb1368f81ef403c988a1d4c89",
          "authors": [
            "Michaël Mathieu",
            "Yann LeCun"
          ]
        },
        {
          "title": "Unsupervised Learning of Spatiotemporally Coherent Metrics",
          "year": 2014,
          "citations": 163,
          "abstract": "Current state-of-the-art classification and detection algorithms train deep convolutional networks using labeled data. In this work we study unsupervised feature learning with convolutional networks in the context of temporally coherent unlabeled data. We focus on feature learning from unlabeled video data, using the assumption that adjacent video frames contain semantically similar information. This assumption is exploited to train a convolutional pooling auto-encoder regularized by slowness and sparsity priors. We establish a connection between slow feature learning and metric learning. Using this connection we define \"temporal coherence\" -- a criterion which can be used to set hyper-parameters in a principled and automated manner. In a transfer learning experiment, we show that the resulting encoder can be used to define a more semantically coherent metric without the use of labels.",
          "venue": "IEEE International Conference on Computer Vision",
          "doi": "10.1109/ICCV.2015.465",
          "url": "https://www.semanticscholar.org/paper/d0a8b5cf98b6721b743571ee13e6032ff5598aea",
          "authors": [
            "Ross Goroshin",
            "Joan Bruna",
            "Jonathan Tompson",
            "D. Eigen",
            "Yann LeCun"
          ]
        },
        {
          "title": "Deep learning with Elastic Averaging SGD",
          "year": 2014,
          "citations": 630,
          "abstract": "We study the problem of stochastic optimization for deep learning in the parallel computing environment under communication constraints. A new algorithm is proposed in this setting where the communication and coordination of work among concurrent processes (local workers), is based on an elastic force which links the parameters they compute with a center variable stored by the parameter server (master). The algorithm enables the local workers to perform more exploration, i.e. the algorithm allows the local variables to fluctuate further from the center variable by reducing the amount of communication between local workers and the master. We empirically demonstrate that in the deep learning setting, due to the existence of many local optima, allowing more exploration can lead to the improved performance. We propose synchronous and asynchronous variants of the new algorithm. We provide the stability analysis of the asynchronous variant in the round-robin scheme and compare it with the more common parallelized method ADMM. We show that the stability of EASGD is guaranteed when a simple stability condition is satisfied, which is not the case for ADMM. We additionally propose the momentum-based version of our algorithm that can be applied in both synchronous and asynchronous settings. Asynchronous variant of the algorithm is applied to train convolutional neural networks for image classification on the CIFAR and ImageNet datasets. Experiments demonstrate that the new algorithm accelerates the training of deep architectures compared to DOWNPOUR and other common baseline approaches and furthermore is very communication efficient.",
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/d1e4365de165463e51134f10bf3939f2b00a6667",
          "authors": [
            "Sixin Zhang",
            "A. Choromańska",
            "Yann LeCun"
          ]
        },
        {
          "title": "Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation",
          "year": 2014,
          "citations": 1760,
          "abstract": "We present techniques for speeding up the test-time evaluation of large convolutional networks, designed for object recognition tasks. These models deliver impressive accuracy, but each image evaluation requires millions of floating point operations, making their deployment on smartphones and Internet-scale clusters problematic. The computation is dominated by the convolution operations in the lower layers of the model. We exploit the redundancy present within the convolutional filters to derive approximations that significantly reduce the required computation. Using large state-of-the-art models, we demonstrate speedups of convolutional layers on both CPU and GPU by a factor of 2 x, while keeping the accuracy within 1% of the original model.",
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/e5ae8ab688051931b4814f6d32b18391f8d1fa8d",
          "authors": [
            "Emily L. Denton",
            "Wojciech Zaremba",
            "Joan Bruna",
            "Yann LeCun",
            "R. Fergus"
          ]
        },
        {
          "title": "Efficient object localization using Convolutional Networks",
          "year": 2014,
          "citations": 1413,
          "abstract": "Recent state-of-the-art performance on human-body pose estimation has been achieved with Deep Convolutional Networks (ConvNets). Traditional ConvNet architectures include pooling and sub-sampling layers which reduce computational requirements, introduce invariance and prevent over-training. These benefits of pooling come at the cost of reduced localization accuracy. We introduce a novel architecture which includes an efficient `position refinement' model that is trained to estimate the joint offset location within a small region of the image. This refinement model is jointly trained in cascade with a state-of-the-art ConvNet model [21] to achieve improved accuracy in human joint location estimation. We show that the variance of our detector approaches the variance of human annotations on the FLIC [20] dataset and outperforms all existing approaches on the MPII-human-pose dataset [1].",
          "venue": "Computer Vision and Pattern Recognition",
          "doi": "10.1109/CVPR.2015.7298664",
          "url": "https://www.semanticscholar.org/paper/ebcea2d842d3d4e320500086aff0deb4cb4412ff",
          "authors": [
            "Jonathan Tompson",
            "Ross Goroshin",
            "Arjun Jain",
            "Yann LeCun",
            "C. Bregler"
          ]
        },
        {
          "title": "MoDeep: A Deep Learning Framework Using Motion Features for Human Pose Estimation",
          "year": 2014,
          "citations": 176,
          "abstract": "In this work, we propose a novel and efficient method for articulated human pose estimation in videos using a convolutional network architecture, which incorporates both color and motion features. We propose a new human body pose dataset, FLIC-motion (This dataset can be downloaded from http://cs.nyu.edu/~ajain/accv2014/.), that extends the FLIC dataset [1] with additional motion features. We apply our architecture to this dataset and report significantly better performance than current state-of-the-art pose detection systems.",
          "venue": "Asian Conference on Computer Vision",
          "doi": "10.1007/978-3-319-16808-1_21",
          "url": "https://www.semanticscholar.org/paper/f8f4481e521ff34683df44c0e467d03ab5dee2b0",
          "authors": [
            "Arjun Jain",
            "Jonathan Tompson",
            "Yann LeCun",
            "C. Bregler"
          ]
        },
        {
          "title": "Assignment 2 - Deep Learning with Sparse Coding",
          "year": 2013,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/016c85fb230e3be91ebc7e0d75eb12c9ddc7661c",
          "authors": [
            "Xiang Zhang",
            "Yann LeCun",
            "J. Langford"
          ]
        },
        {
          "title": "Saturating Auto-Encoders",
          "year": 2013,
          "citations": 44,
          "abstract": "We introduce a simple new regularizer for auto-encoders whose hidden-unit activation functions contain at least one zero-gradient (saturated) region. This regularizer explicitly encourages activations in the saturated region(s) of the corresponding activation function. We call these Saturating Auto-Encoders (SATAE). We show that the saturation regularizer explicitly limits the SATAE's ability to reconstruct inputs which are not near the data manifold. Furthermore, we show that a wide variety of features can be learned when different activation functions are used. Finally, connections are established with the Contractive and Sparse Auto-Encoders.",
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/0a9cbc7484a0da0962b39ca880ee63b398746170",
          "authors": [
            "Rostislav Goroshin",
            "Yann LeCun"
          ]
        },
        {
          "title": "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks",
          "year": 2013,
          "citations": 5090,
          "abstract": "We present an integrated framework for using Convolutional Networks for classification, localization and detection. We show how a multiscale and sliding window approach can be efficiently implemented within a ConvNet. We also introduce a novel deep learning approach to localization by learning to predict object boundaries. Bounding boxes are then accumulated rather than suppressed in order to increase detection confidence. We show that different tasks can be learned simultaneously using a single shared network. This integrated framework is the winner of the localization task of the ImageNet Large Scale Visual Recognition Challenge 2013 (ILSVRC2013) and obtained very competitive results for the detection and classifications tasks. In post-competition work, we establish a new state of the art for the detection task. Finally, we release a feature extractor from our best model called OverFeat.",
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/1109b663453e78a59e4f66446d71720ac58cec25",
          "authors": [
            "P. Sermanet",
            "D. Eigen",
            "Xiang Zhang",
            "Michaël Mathieu",
            "R. Fergus",
            "Yann LeCun"
          ]
        },
        {
          "title": "Learning Hierarchical Features for Scene Labeling",
          "year": 2013,
          "citations": 2757,
          "abstract": null,
          "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
          "doi": "10.1109/TPAMI.2012.231",
          "url": "https://www.semanticscholar.org/paper/237a04dd8291cbdb59b6dc4b53e689af743fe2a3",
          "authors": [
            "C. Farabet",
            "C. Couprie",
            "Laurent Najman",
            "Yann LeCun"
          ]
        },
        {
          "title": "Neural Information Processing (ICONIP 2013)",
          "year": 2013,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/297bcea9cca46cbe3181508972c724dc1c5d3f75",
          "authors": [
            "T. Vatanen",
            "T. Raiko",
            "Harri Valpola",
            "Yann LeCun"
          ]
        },
        {
          "title": "AAAI Workshop - Technical Report: Preface",
          "year": 2013,
          "citations": 0,
          "abstract": null,
          "venue": "AAAI Conference on Artificial Intelligence",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/31dbf596f6f6b472aba9ea3434e2463b20c98511",
          "authors": [
            "Marc Pickett",
            "B. Kuipers",
            "Yann LeCun",
            "Clayton T. Morrison"
          ]
        },
        {
          "title": "Regularization of Neural Networks using DropConnect",
          "year": 2013,
          "citations": 2608,
          "abstract": null,
          "venue": "International Conference on Machine Learning",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/38f35dd624cd1cf827416e31ac5e0e0454028eca",
          "authors": [
            "Li Wan",
            "Matthew D. Zeiler",
            "Sixin Zhang",
            "Yann LeCun",
            "R. Fergus"
          ]
        },
        {
          "title": "Signal recovery from Pooling Representations",
          "year": 2013,
          "citations": 101,
          "abstract": "In this work we compute lower Lipschitz bounds of lp pooling operators for p = 1, 2, ∞ as well as lp pooling operators preceded by half-rectification layers. These give sufficient conditions for the design of invertible neural network layers. Numerical experiments on MNIST and image patches confirm that pooling layers can be inverted with phase recovery algorithms. Moreover, the regularity of the inverse pooling, controlled by the lower Lipschitz constant, is empirically verified with a nearest neighbor regression.",
          "venue": "International Conference on Machine Learning",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/47f1b4ce7674b15d293f5a3c53d6da44bc8e137e",
          "authors": [
            "Joan Bruna",
            "Arthur Szlam",
            "Yann LeCun"
          ]
        },
        {
          "title": "Spectral Networks and Locally Connected Networks on Graphs",
          "year": 2013,
          "citations": 5173,
          "abstract": "Convolutional Neural Networks are extremely efficient architectures in image and audio recognition tasks, thanks to their ability to exploit the local translational invariance of signal classes over their domain. In this paper we consider possible generalizations of CNNs to signals defined on more general domains without the action of a translation group. In particular, we propose two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian. We show through experiments that for low-dimensional graphs it is possible to learn convolutional layers with a number of parameters independent of the input size, resulting in efficient deep architectures.",
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/5e925a9f1e20df61d1e860a7aa71894b35a1c186",
          "authors": [
            "Joan Bruna",
            "Wojciech Zaremba",
            "Arthur Szlam",
            "Yann LeCun"
          ]
        },
        {
          "title": "Real-time adaptive off-road vehicle navigation and terrain classification",
          "year": 2013,
          "citations": 12,
          "abstract": null,
          "venue": "Defense, Security, and Sensing",
          "doi": "10.1117/12.2015533",
          "url": "https://www.semanticscholar.org/paper/5fd1714d7fc5b3edfcfb755e11f914c46d377cc5",
          "authors": [
            "Urs Muller",
            "L. Jackel",
            "Yann LeCun",
            "B. Flepp"
          ]
        },
        {
          "title": "Discriminative recurrent sparse auto-encoders: 1st International Conference on Learning Representations, ICLR 2013",
          "year": 2013,
          "citations": 2,
          "abstract": null,
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/6ef907db1e8c7b0cde28c960267cdb6a7b9a56d1",
          "authors": [
            "J. Rolfe",
            "Yann LeCun"
          ]
        },
        {
          "title": "Discriminative Recurrent Sparse Auto-Encoders",
          "year": 2013,
          "citations": 73,
          "abstract": "We present the discriminative recurrent sparse auto-encoder model, comprising a recurrent encoder of rectified linear units, unrolled for a fixed number of iterations, and connected to two linear decoders that reconstruct the input and predict its supervised classification. Training via backpropagation-through-time initially minimizes an unsupervised sparse reconstruction error; the loss function is then augmented with a discriminative term on the supervised classification. The depth implicit in the temporally-unrolled form allows the system to exhibit all the power of deep networks, while substantially reducing the number of trainable parameters. \nFrom an initially unstructured network the hidden units differentiate into categorical-units, each of which represents an input prototype with a well-defined class; and part-units representing deformations of these prototypes. The learned organization of the recurrent encoder is hierarchical: part-units are driven directly by the input, whereas the activity of categorical-units builds up over time through interactions with the part-units. Even using a small number of hidden units per layer, discriminative recurrent sparse auto-encoders achieve excellent performance on MNIST.",
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/72c35d7eb807ed46fb82024922ffbf45218f5a95",
          "authors": [
            "J. Rolfe",
            "Yann LeCun"
          ]
        },
        {
          "title": "No More Pesky Learning Rates : Supplementary Material",
          "year": 2013,
          "citations": 2,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/7ac497addf456522d02d4426ea70d4fb20c86431",
          "authors": [
            "T. Schaul",
            "Sixin Zhang",
            "Yann LeCun"
          ]
        },
        {
          "title": "Feature learning and deep architectures: new directions for music informatics",
          "year": 2013,
          "citations": 135,
          "abstract": null,
          "venue": "Journal of Intelligence and Information Systems",
          "doi": "10.1007/s10844-013-0248-5",
          "url": "https://www.semanticscholar.org/paper/8b930259e50c9e7ef47d6ad2d57ff377d630361a",
          "authors": [
            "Eric J. Humphrey",
            "J. Bello",
            "Yann LeCun"
          ]
        },
        {
          "title": "Indoor Semantic Segmentation using depth information",
          "year": 2013,
          "citations": 497,
          "abstract": "This work addresses multi-class segmentation of indoor scenes with RGB-D inputs. While this area of research has gained much attention recently, most works still rely on hand-crafted features. In contrast, we apply a multiscale convolutional network to learn features directly from the images and the depth information. We obtain state-of-the-art on the NYU-v2 depth dataset with an accuracy of 64.5%. We illustrate the labeling of indoor scenes in videos sequences that could be processed in real-time using appropriate hardware such as an FPGA.",
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/8f3c7fc72635c3b95dc3530fdaceee1d4681548e",
          "authors": [
            "C. Couprie",
            "C. Farabet",
            "Laurent Najman",
            "Yann LeCun"
          ]
        },
        {
          "title": "Learning Stable Group Invariant Representations with Convolutional Networks",
          "year": 2013,
          "citations": 39,
          "abstract": "Transformation groups, such as translations or rotations, effectively express part of the variability observed in many recognition problems. The group structure enables the construction of invariant signal representations with appealing mathematical properties, where convolutions, together with pooling operators, bring stability to additive and geometric perturbations of the input. Whereas physical transformation groups are ubiquitous in image and audio applications, they do not account for all the variability of complex signal classes. \nWe show that the invariance properties built by deep convolutional networks can be cast as a form of stable group invariance. The network wiring architecture determines the invariance group, while the trainable filter coefficients characterize the group action. We give explanatory examples which illustrate how the network architecture controls the resulting invariance group. We also explore the principle by which additional convolutional layers induce a group factorization enabling more abstract, powerful invariant representations.",
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/a219e69af081740e0faab08028557965620d8303",
          "authors": [
            "Joan Bruna",
            "Arthur Szlam",
            "Yann LeCun"
          ]
        },
        {
          "title": "Fast Training of Convolutional Networks through FFTs",
          "year": 2013,
          "citations": 628,
          "abstract": "Convolutional networks are one of the most widely employed architectures in computer vision and machine learning. In order to leverage their ability to learn complex functions, large amounts of data are required for training. Training a large convolutional network to produce state-of-the-art results can take weeks, even when using modern GPUs. Producing labels using a trained network can also be costly when dealing with web-scale datasets. In this work, we present a simple algorithm which accelerates training and inference by a significant factor, and can yield improvements of over an order of magnitude compared to existing state-of-the-art implementations. This is done by computing convolutions as pointwise products in the Fourier domain while reusing the same transformed feature map many times. The algorithm is implemented on a GPU architecture and addresses a number of related challenges.",
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/a7621b4ec18719b08f3a2a444b6d37a2e20227b7",
          "authors": [
            "Michaël Mathieu",
            "Mikael Henaff",
            "Yann LeCun"
          ]
        },
        {
          "title": "Adaptive learning rates and parallelization for stochastic, sparse, non-smooth gradients",
          "year": 2013,
          "citations": 29,
          "abstract": "Recent work has established an empirically successful framework for adapting learning rates for stochastic gradient descent (SGD). This effectively removes all needs for tuning, while automatically reducing learning rates over time on stationary problems, and permitting learning rates to grow appropriately in non-stationary tasks. Here, we extend the idea in three directions, addressing proper minibatch parallelization, including reweighted updates for sparse or orthogonal gradients, improving robustness on non-smooth loss functions, in the process replacing the diagonal Hessian estimation procedure that may not always be available by a robust finite-difference approximation. The final algorithm integrates all these components, has linear complexity and is hyper-parameter free.",
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/b4b0a3a748dfd2618ffcf1f94411e339e1e78775",
          "authors": [
            "T. Schaul",
            "Yann LeCun"
          ]
        },
        {
          "title": "Saturating auto-encoders: International Conference on Learning Representations, ICLR 2013",
          "year": 2013,
          "citations": 1,
          "abstract": null,
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/b6c3a5c2eb0cca13d4944f549a3e29c596170e00",
          "authors": [
            "Rostislav Goroshin",
            "Yann LeCun"
          ]
        },
        {
          "title": "Causal graph-based video segmentation",
          "year": 2013,
          "citations": 26,
          "abstract": "Among the different methods producing superpixel segmentations of an image, the graph-based approach of Felzenszwalb and Huttenlocher is broadly employed. One of its interesting properties is that the regions are computed in a greedy manner in quasi-linear time by using a minimum spanning tree. The algorithm may be trivially extended to video segmentation by considering a video as a 3D volume, however, this can not be the case for causal segmentation, when subsequent frames are unknown. In a framework exploiting minimum spanning trees all along, we propose an efficient video segmentation approach that computes temporally consistent pixels in a causal manner, filling the need for causal and real time applications.",
          "venue": "2013 IEEE International Conference on Image Processing",
          "doi": "10.1109/ICIP.2013.6738875",
          "url": "https://www.semanticscholar.org/paper/c0d373ab0fc50663a2e638f2067dedaa9e2b2c7c",
          "authors": [
            "C. Couprie",
            "C. Farabet",
            "Yann LeCun",
            "Laurent Najman"
          ]
        },
        {
          "title": "Saturating Auto-Encoder",
          "year": 2013,
          "citations": 10,
          "abstract": null,
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/dab50f7682bf410743e2d2447eb5d2bc652f1463",
          "authors": [
            "Ross Goroshin",
            "Yann LeCun"
          ]
        },
        {
          "title": "Understanding Deep Architectures using a Recursive Convolutional Network",
          "year": 2013,
          "citations": 147,
          "abstract": "A key challenge in designing convolutional network models is sizing them appropriately. Many factors are involved in these decisions, including number of layers, feature maps, kernel sizes, etc. Complicating this further is the fact that each of these influence not only the numbers and dimensions of the activation units, but also the total number of parameters. In this paper we focus on assessing the independent contributions of three of these linked variables: The numbers of layers, feature maps, and parameters. To accomplish this, we employ a recursive convolutional network whose weights are tied between layers; this allows us to vary each of the three factors in a controlled setting. We find that while increasing the numbers of layers and parameters each have clear benefit, the number of feature maps (and hence dimensionality of the representation) appears ancillary, and finds most of its benefit through the introduction of more weights. Our results (i) empirically confirm the notion that adding layers alone increases computational power, within the context of convolutional layers, and (ii) suggest that precise sizing of convolutional feature map dimensions is itself of little concern; more attention should be paid to the number of parameters in these layers instead.",
          "venue": "International Conference on Learning Representations",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/e2d894584986b44710f634b696db371f8aff92e0",
          "authors": [
            "D. Eigen",
            "J. Rolfe",
            "R. Fergus",
            "Yann LeCun"
          ]
        },
        {
          "title": "DCL System Using Deep Learning Approaches for Land-Based or Ship-Based Real-Time Recognition and Localization of Marine Mammals",
          "year": 2013,
          "citations": 4,
          "abstract": "Abstract : The overarching goals of this work are to advance the state of the art for detection, classification, and localization (DCL) in the field of bioacoustics. This goal is primarily achieved by building a generic framework for detection-classification (DC) using a fast, efficient, and scalable architecture, demonstrating the capabilities of the system using a variety of low-frequency and mid-frequency cetacean sounds. Two primary goals are to develop transferable technologies for detection and classification in the area of advanced algorithms, such as deep learning and other methods; and in advanced systems, capable of real-time and archival processing. Currently, massive amounts of acoustic data are being collected by various institutions, corporations, and national defense agencies. The long-term goal is to provide technical capability to analyze the data using automatic algorithms for DC based on machine intelligence. The goal of the automation is to provide effective and efficient mechanisms by which to process large acoustic datasets for understanding the bioacoustic behaviors of marine mammals. This capability will provide insights into the potential ecological impacts and influences of anthropogenic ocean sounds. From Oct 2012 through Sep 2013, our research focused on five major initiatives: (1) International workshops, conferences, and data challenges; (2) Enhancements of the Acoustic Segmentation Recognition (ASR) algorithm for frequency-modulated sounds: Right Whale Study; (3) Enhancements of the ASR algorithm for pulse trains: Minke Whale Study; (4) Mining Big Data Sound Archives using High Performance Computing software and hardware; and (5) Large Pulse Train Study: Minke Vocal Activity East Coast United States.",
          "venue": "",
          "doi": "10.21236/ada573473",
          "url": "https://www.semanticscholar.org/paper/e52804a57e0f32be1dc015800a9b58d35639a17d",
          "authors": [
            "Peter J. Dugan",
            "C. Clark",
            "Yann LeCun",
            "S. Parijs"
          ]
        },
        {
          "title": "Pushing Stochastic Gradient towards Second-Order Methods -- Backpropagation Learning with Transformations in Nonlinearities",
          "year": 2013,
          "citations": 34,
          "abstract": "Recently, we proposed to transform the outputs of each hidden neuron in a multi-layer perceptron network to have zero output and zero slope on average, and use separate shortcut connections to model the linear dependencies instead. We continue the work by firstly introducing a third transformation to normalize the scale of the outputs of each hidden neuron, and secondly by analyzing the connections to second order optimization methods. We show that the transformations make a simple stochastic gradient behave closer to second-order optimization methods and thus speed up learning. This is shown both in theory and with experiments. The experiments on the third transformation show that while it further increases the speed of learning, it can also hurt performance by converging to a worse local optimum, where both the inputs and outputs of many hidden neurons are close to zero.",
          "venue": "International Conference on Learning Representations",
          "doi": "10.1007/978-3-642-42054-2_55",
          "url": "https://www.semanticscholar.org/paper/f72c079d9179cfaada1135a7e4c77d48b6309a30",
          "authors": [
            "T. Vatanen",
            "T. Raiko",
            "Harri Valpola",
            "Yann LeCun"
          ]
        },
        {
          "title": "Learning Through the Breach: Language Socialization",
          "year": 2012,
          "citations": 3,
          "abstract": null,
          "venue": "",
          "doi": "10.1007/springerreference_301829",
          "url": "https://www.semanticscholar.org/paper/0cf33632c2031f475803ee9d9215578fa0af927a",
          "authors": [
            "C. Chan",
            "Z. Zorina",
            "Jesse R. Sparks",
            "S. L. Ornat",
            "C. Tsang",
            "E. Grigorenko",
            "R. Lubow",
            "J. Malone",
            "M. Domjan",
            "Charles Yang",
            "Michelyn C. Butler",
            "M. Gettinger",
            "T. Minor",
            "Traci N. Plumb",
            "H. Drachsler",
            "P. Kirschner",
            "M. Nakayama",
            "Rowena Santiago",
            "Ali Şimşek",
            "Fang‐Ying Yang",
            "Yi-Chun Chen",
            "G. Brooke",
            "Heidi L. Andrade",
            "R. Cooper",
            "A. Podolskiy",
            "David W. Versailles",
            "Valérie Mérindol",
            "E. Guerci",
            "Nobuyuki Hanaki",
            "D. Grollman",
            "A. Billard",
            "L. Lamb",
            "A. Garcez",
            "D. Németh",
            "K. Janacsek",
            "John A. Nunnery",
            "L. Byrd-Poller",
            "M. Haan",
            "Rodrigo Harrison",
            "Mauricio G. Villena",
            "L. Izquierdo",
            "Segismundo S. Izquierdo",
            "F. Vega-Redondo",
            "T. Alloway",
            "U. Halsband",
            "N. Seel",
            "G. Bedny",
            "Hansjörg von Brevern",
            "K. Synytsya",
            "G. Kern-Isberner",
            "J. Breuker",
            "S. Cerri",
            "T. Zittoun",
            "S. Brinkmann",
            "Negin Dahya",
            "S. B. Fountain",
            "Karen E. Doyle",
            "K. Sarfo",
            "Bertram C. Bruce",
            "N. Bloch",
            "C. Olsson",
            "L. Nyberg",
            "R. Freivalds",
            "L. Hall",
            "M. Hall",
            "U. Hanke",
            "L. Norton",
            "Aytac Gogus",
            "K. Illeris",
            "M. Macy",
            "A. Flache",
            "A. Robins",
            "L. Thorogood",
            "M. Udell",
            "C. Wynne",
            "P. Burnett",
            "M. Cannon",
            "A. Edmondson",
            "P. Hartono",
            "A. Callender",
            "R. Barr",
            "N. Brito",
            "Noorizah Mohd. Noor",
            "Tg. Nor Rizan Tg. Mohamad Maasum",
            "K. Cennamo",
            "Marc'Aurelio Ranzato",
            "Y-Lan Boureau",
            "K. Kavukcuoglu",
            "Karol Gregor",
            "Yann LeCun",
            "M. Alias",
            "Caifeng Shan",
            "Alice Y. Kolb",
            "D. Kolb",
            "R. Reilly",
            "K. Nielsen",
            "P. Couvillon",
            "H. King",
            "J. Dillon",
            "D. Neuman",
            "J. E. Purdy",
            "Linda Kragelund",
            "F. Gobet",
            "P. C. Lane",
            "S. Naidu",
            "Danny R. Bedgood",
            "Dirk Ifenthaler",
            "Ida Moadab",
            "D. Tucker",
            "P. Hager",
            "J. Fejes",
            "Danielle C. Colas-Zelin",
            "L. Matzel",
            "P. Perruchet",
            "B. Poulin-Charronnat",
            "S. Pacton",
            "C. Linnman",
            "Mohamed A Zeidan",
            "M. Milad",
            "I. Holloway",
            "D. Ansari",
            "K. Lionello-DeNolf",
            "J. Burgoyne",
            "Judy Huang",
            "Roger K. Thomas",
            "S. Pietropaolo",
            "Wim E. Crusio",
            "Sabine Richter",
            "J. Elen",
            "G. Clarebout",
            "E. Bliss-Moreau",
            "Jonte Bernhard",
            "Marcia L. Conner",
            "Lanita Jacobs",
            "Mariel Miller",
            "A. Hadwin",
            "M. Coen",
            "Carlo P. Magno",
            "Eli Hinkel",
            "S. Szedmák",
            "F. Balagué",
            "M. Milrad",
            "H. Hoppe",
            "Krisztina Molnár",
            "E. Vries",
            "E. Blanchard",
            "C. Frasson",
            "Susanne P. Lajoie",
            "T. Cazenave",
            "T. Jong",
            "J. Meij",
            "J. Gavelek",
            "A. Kong",
            "A. Daffertshofer",
            "J. Alonso-Tapia",
            "S. Billett",
            "D. Rumbaugh",
            "M. Beran",
            "Imran Ho-Abdullah",
            "Norsimah Mat Awal",
            "D. Seo",
            "M. Monfils",
            "A. Wright",
            "D. Deshler",
            "Frances M. Ihle",
            "Carrie Mark",
            "Daniel T. Pollitt",
            "M. Kennedy",
            "M. Jackson",
            "T. Nunes",
            "B. Jackling",
            "R. Howard",
            "W. Kennedy",
            "L. C. Drickamer"
          ]
        },
        {
          "title": "Comparison between Frame-Constrained Fix-Pixel-Value and Frame-Free Spiking-Dynamic-Pixel ConvNets for Visual Processing",
          "year": 2012,
          "citations": 74,
          "abstract": "Most scene segmentation and categorization architectures for the extraction of features in images and patches make exhaustive use of 2D convolution operations for template matching, template search, and denoising. Convolutional Neural Networks (ConvNets) are one example of such architectures that can implement general-purpose bio-inspired vision systems. In standard digital computers 2D convolutions are usually expensive in terms of resource consumption and impose severe limitations for efficient real-time applications. Nevertheless, neuro-cortex inspired solutions, like dedicated Frame-Based or Frame-Free Spiking ConvNet Convolution Processors, are advancing real-time visual processing. These two approaches share the neural inspiration, but each of them solves the problem in different ways. Frame-Based ConvNets process frame by frame video information in a very robust and fast way that requires to use and share the available hardware resources (such as: multipliers, adders). Hardware resources are fixed- and time-multiplexed by fetching data in and out. Thus memory bandwidth and size is important for good performance. On the other hand, spike-based convolution processors are a frame-free alternative that is able to perform convolution of a spike-based source of visual information with very low latency, which makes ideal for very high-speed applications. However, hardware resources need to be available all the time and cannot be time-multiplexed. Thus, hardware should be modular, reconfigurable, and expansible. Hardware implementations in both VLSI custom integrated circuits (digital and analog) and FPGA have been already used to demonstrate the performance of these systems. In this paper we present a comparison study of these two neuro-inspired solutions. A brief description of both systems is presented and also discussions about their differences, pros and cons.",
          "venue": "Frontiers in Neuroscience",
          "doi": "10.3389/fnins.2012.00032",
          "url": "https://www.semanticscholar.org/paper/18816aa33e7afd3eabfa7ac6437e90220aa5b317",
          "authors": [
            "C. Farabet",
            "R. Paz",
            "J. Pérez-Carrasco",
            "C. Zamarreño-Ramos",
            "A. Linares-Barranco",
            "Yann LeCun",
            "E. Culurciello",
            "T. Serrano-Gotarredona",
            "B. Linares-Barranco"
          ]
        },
        {
          "title": "Semantic Road Segmentation via Multi-scale Ensembles of Learned Features",
          "year": 2012,
          "citations": 58,
          "abstract": null,
          "venue": "ECCV Workshops",
          "doi": "10.1007/978-3-642-33868-7_58",
          "url": "https://www.semanticscholar.org/paper/2239f2a97d80b63466815e2e2d6ee993d156813e",
          "authors": [
            "J. Álvarez",
            "Yann LeCun",
            "T. Gevers",
            "Antonio M. López"
          ]
        },
        {
          "title": "Learning in Informal Settings",
          "year": 2012,
          "citations": 12,
          "abstract": null,
          "venue": "",
          "doi": "10.1007/springerreference_301826",
          "url": "https://www.semanticscholar.org/paper/27a1c8c5e228cf4d5fd020e347a58bfb00c95d46",
          "authors": [
            "C. Chan",
            "Z. Zorina",
            "Jesse R. Sparks",
            "S. L. Ornat",
            "C. Tsang",
            "E. Grigorenko",
            "R. Lubow",
            "J. Malone",
            "M. Domjan",
            "Charles Yang",
            "Michelyn C. Butler",
            "M. Gettinger",
            "T. Minor",
            "Traci N. Plumb",
            "H. Drachsler",
            "P. Kirschner",
            "M. Nakayama",
            "Rowena Santiago",
            "Ali Şimşek",
            "Fang‐Ying Yang",
            "Yi-Chun Chen",
            "G. Brooke",
            "Heidi L. Andrade",
            "R. Cooper",
            "A. Podolskiy",
            "David W. Versailles",
            "Valérie Mérindol",
            "E. Guerci",
            "Nobuyuki Hanaki",
            "D. Grollman",
            "A. Billard",
            "L. Lamb",
            "A. Garcez",
            "D. Németh",
            "K. Janacsek",
            "John A. Nunnery",
            "Lynda Byrd-Poller",
            "M. Haan",
            "Rodrigo Harrison",
            "Mauricio G. Villena",
            "L. Izquierdo",
            "Segismundo S. Izquierdo",
            "F. Vega-Redondo",
            "T. Alloway",
            "U. Halsband",
            "N. Seel",
            "G. Bedny",
            "Hansjörg von Brevern",
            "K. Synytsya",
            "G. Kern-Isberner",
            "J. Breuker",
            "S. Cerri",
            "T. Zittoun",
            "S. Brinkmann",
            "Negin Dahya",
            "S. B. Fountain",
            "Karen E. Doyle",
            "K. Sarfo",
            "Bertram C. Bruce",
            "N. Bloch",
            "C. Olsson",
            "L. Nyberg",
            "R. Freivalds",
            "L. Hall",
            "M. Hall",
            "U. Hanke",
            "L. Norton",
            "Aytac Gogus",
            "K. Illeris",
            "M. Macy",
            "A. Flache",
            "A. Robins",
            "L. Thorogood",
            "M. Udell",
            "C. Wynne",
            "P. Burnett",
            "M. Cannon",
            "A. Edmondson",
            "P. Hartono",
            "A. Callender",
            "R. Barr",
            "N. Brito",
            "Noorizah Mohd. Noor",
            "Tg. Nor Rizan Tg. Mohamad Maasum",
            "K. Cennamo",
            "Marc'Aurelio Ranzato",
            "Y-Lan Boureau",
            "K. Kavukcuoglu",
            "Karol Gregor",
            "Yann LeCun",
            "M. Alias",
            "Caifeng Shan",
            "Alice Y. Kolb",
            "D. Kolb",
            "R. Reilly",
            "K. Nielsen",
            "P. Couvillon",
            "H. King",
            "J. Dillon",
            "D. Neuman",
            "J. E. Purdy",
            "Linda Kragelund",
            "F. Gobet",
            "P. C. Lane",
            "S. Naidu",
            "Danny R. Bedgood",
            "Dirk Ifenthaler",
            "Ida Moadab",
            "D. Tucker",
            "P. Hager",
            "J. Fejes",
            "Danielle C. Colas-Zelin",
            "L. Matzel",
            "P. Perruchet",
            "B. Poulin-Charronnat",
            "S. Pacton",
            "C. Linnman",
            "Mohamed A Zeidan",
            "M. Milad",
            "I. Holloway",
            "D. Ansari",
            "K. Lionello-denolf",
            "J. Burgoyne",
            "Judy Huang",
            "Roger K. Thomas",
            "S. Pietropaolo",
            "Wim E. Crusio",
            "Sabine Richter",
            "J. Elen",
            "G. Clarebout",
            "Eliza Bliss-Moreau",
            "Jonte Bernhard",
            "Marcia L. Conner",
            "Lanita Jacobs",
            "Mariel Miller",
            "A. Hadwin",
            "M. Coen",
            "Carlo P. Magno",
            "Eli Hinkel",
            "S. Szedmák",
            "F. Balagué",
            "M. Milrad",
            "H. Hoppe",
            "Krisztina Molnár",
            "E. Vries",
            "E. Blanchard",
            "C. Frasson",
            "Susanne P. Lajoie",
            "T. Cazenave",
            "T. Jong",
            "J. Meij",
            "J. Gavelek",
            "A. Kong",
            "A. Daffertshofer",
            "J. Alonso-Tapia",
            "S. Billett",
            "D. Rumbaugh",
            "M. Beran",
            "Imran Ho-Abdullah",
            "Norsimah Mat Awal",
            "D. Seo",
            "M. Monfils",
            "A. Wright",
            "D. Deshler",
            "Frances M. Ihle",
            "Carrie Mark",
            "Daniel T. Pollitt",
            "M. Kennedy",
            "M. Jackson",
            "T. Nunes",
            "B. Jackling",
            "R. Howard",
            "W. Kennedy",
            "L. C. Drickamer"
          ]
        },
        {
          "title": "Learning from Text",
          "year": 2012,
          "citations": 2,
          "abstract": null,
          "venue": "",
          "doi": "10.1007/978-1-4419-1428-6_894",
          "url": "https://www.semanticscholar.org/paper/4b680f31d78db262fe82613e62730f6ec1356eb3",
          "authors": [
            "C. Chan",
            "Z. Zorina",
            "Jesse R. Sparks",
            "S. L. Ornat",
            "C. Tsang",
            "E. Grigorenko",
            "R. Lubow",
            "J. Malone",
            "M. Domjan",
            "Charles Yang",
            "Michelyn C. Butler",
            "M. Gettinger",
            "T. Minor",
            "Traci N. Plumb",
            "H. Drachsler",
            "P. Kirschner",
            "M. Nakayama",
            "Rowena Santiago",
            "Ali Şimşek",
            "Fang‐Ying Yang",
            "Yi-Chun Chen",
            "G. Brooke",
            "Heidi L. Andrade",
            "R. Cooper",
            "A. Podolskiy",
            "David W. Versailles",
            "Valérie Mérindol",
            "E. Guerci",
            "Nobuyuki Hanaki",
            "D. Grollman",
            "A. Billard",
            "L. Lamb",
            "A. Garcez",
            "D. Németh",
            "K. Janacsek",
            "John A. Nunnery",
            "L. Byrd-Poller",
            "M. Haan",
            "Rodrigo Harrison",
            "Mauricio G. Villena",
            "L. Izquierdo",
            "Segismundo S. Izquierdo",
            "F. Vega-Redondo",
            "T. Alloway",
            "U. Halsband",
            "N. Seel",
            "G. Bedny",
            "Hansjörg von Brevern",
            "K. Synytsya",
            "G. Kern-Isberner",
            "J. Breuker",
            "S. Cerri",
            "T. Zittoun",
            "S. Brinkmann",
            "Negin Dahya",
            "S. B. Fountain",
            "Karen E. Doyle",
            "K. Sarfo",
            "Bertram C. Bruce",
            "N. Bloch",
            "C. Olsson",
            "L. Nyberg",
            "R. Freivalds",
            "L. Hall",
            "M. Hall",
            "U. Hanke",
            "L. Norton",
            "Aytac Gogus",
            "K. Illeris",
            "M. Macy",
            "A. Flache",
            "A. Robins",
            "L. Thorogood",
            "M. Udell",
            "C. Wynne",
            "P. Burnett",
            "M. Cannon",
            "A. Edmondson",
            "P. Hartono",
            "A. Callender",
            "R. Barr",
            "N. Brito",
            "Noorizah Mohd. Noor",
            "Tg. Nor Rizan Tg. Mohamad Maasum",
            "K. Cennamo",
            "Marc'Aurelio Ranzato",
            "Y-Lan Boureau",
            "K. Kavukcuoglu",
            "Karol Gregor",
            "Yann LeCun",
            "M. Alias",
            "Caifeng Shan",
            "Alice Y. Kolb",
            "D. Kolb",
            "R. Reilly",
            "K. Nielsen",
            "P. Couvillon",
            "H. King",
            "J. Dillon",
            "D. Neuman",
            "J. E. Purdy",
            "Linda Kragelund",
            "F. Gobet",
            "P. C. Lane",
            "S. Naidu",
            "Danny R. Bedgood",
            "Dirk Ifenthaler",
            "Ida Moadab",
            "D. Tucker",
            "P. Hager",
            "J. Fejes",
            "Danielle C. Colas-Zelin",
            "L. Matzel",
            "P. Perruchet",
            "B. Poulin-Charronnat",
            "S. Pacton",
            "C. Linnman",
            "Mohamed A Zeidan",
            "M. Milad",
            "I. Holloway",
            "D. Ansari",
            "K. Lionello-DeNolf",
            "J. Burgoyne",
            "Judy Huang",
            "Roger K. Thomas",
            "S. Pietropaolo",
            "Wim E. Crusio",
            "Sabine Richter",
            "J. Elen",
            "G. Clarebout",
            "E. Bliss-Moreau",
            "Jonte Bernhard",
            "Marcia L. Conner",
            "Lanita Jacobs",
            "Mariel Miller",
            "A. Hadwin",
            "M. Coen",
            "Carlo P. Magno",
            "Eli Hinkel",
            "S. Szedmák",
            "F. Balagué",
            "M. Milrad",
            "H. Hoppe",
            "Krisztina Molnár",
            "E. Vries",
            "E. Blanchard",
            "C. Frasson",
            "Susanne P. Lajoie",
            "T. Cazenave",
            "T. Jong",
            "J. Meij",
            "J. Gavelek",
            "A. Kong",
            "A. Daffertshofer",
            "J. Alonso-Tapia",
            "S. Billett",
            "D. Rumbaugh",
            "M. Beran",
            "Imran Ho-Abdullah",
            "Norsimah Mat Awal",
            "D. Seo",
            "M. Monfils",
            "A. Wright",
            "D. Deshler",
            "Frances M. Ihle",
            "Carrie Mark",
            "Daniel T. Pollitt",
            "M. Kennedy",
            "M. Jackson",
            "T. Nunes",
            "B. Jackling",
            "R. Howard",
            "W. Kennedy",
            "L. C. Drickamer"
          ]
        },
        {
          "title": "Scene parsing with Multiscale Feature Learning, Purity Trees, and Optimal Covers",
          "year": 2012,
          "citations": 205,
          "abstract": "Scene parsing consists in labeling each pixel in an image with the category of the object it belongs to. We propose a method that uses a multiscale convolutional network trained from raw pixels to extract dense feature vectors that encode regions of multiple sizes centered on each pixel. The method alleviates the need for engineered features. In parallel to feature extraction, a tree of segments is computed from a graph of pixel dissimilarities. The feature vectors associated with the segments covered by each node in the tree are aggregated and fed to a classifier which produces an estimate of the distribution of object categories contained in the segment. A subset of tree nodes that cover the image are then selected so as to maximize the average \"purity\" of the class distributions, hence maximizing the overall likelihood that each segment will contain a single object. The system yields record accuracies on the the Sift Flow Dataset (33 classes) and the Barcelona Dataset (170 classes) and near-record accuracy on the Stanford Background Dataset (8 classes), while being an order of magnitude faster than competing approaches, producing a 320 × 240 image labeling in less than 1 second, including feature extraction.",
          "venue": "International Conference on Machine Learning",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/56b3ff898cadde865d20ddb4e7a33434de186794",
          "authors": [
            "C. Farabet",
            "C. Couprie",
            "Laurent Najman",
            "Yann LeCun"
          ]
        },
        {
          "title": "Road Scene Segmentation from a Single Image",
          "year": 2012,
          "citations": 254,
          "abstract": null,
          "venue": "European Conference on Computer Vision",
          "doi": "10.1007/978-3-642-33786-4_28",
          "url": "https://www.semanticscholar.org/paper/62cf68c67802b6e8126ecfb3fb794b867fd2ab3a",
          "authors": [
            "J. Álvarez",
            "T. Gevers",
            "Yann LeCun",
            "Antonio M. López"
          ]
        },
        {
          "title": "Moving Beyond Feature Design: Deep Architectures and Automatic Feature Learning in Music Informatics",
          "year": 2012,
          "citations": 153,
          "abstract": null,
          "venue": "International Society for Music Information Retrieval Conference",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/7a42dedd7050442a78940bae6a62899919693b17",
          "authors": [
            "Eric J. Humphrey",
            "J. Bello",
            "Yann LeCun"
          ]
        },
        {
          "title": "Flexible-Cost SLAM",
          "year": 2012,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/8a96d99e4fe1bfe471889ccc2e816522b967d88f",
          "authors": [
            "Yann LeCun",
            "M. Grimes"
          ]
        },
        {
          "title": "AISTAT AISTATS Fifteenth International Conference on Artificial Intelligence and Statistics (AISTAT 2012) AISTAT AISTATS, La Palma, Canary Islands, April 21-23, 2012",
          "year": 2012,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/8f83cbb3f7594c7227d9e318437d700945473df7",
          "authors": [
            "T. Raiko",
            "Harri Valpola",
            "Yann LeCun"
          ]
        },
        {
          "title": "DCL System Research Using Advanced Approaches for Land-based or Ship-based Real-Time Recognition and Localization of Marine Mammals",
          "year": 2012,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": "10.21236/ada572279",
          "url": "https://www.semanticscholar.org/paper/8fea0cbdf12afec45db609219a56016ecc571147",
          "authors": [
            "Peter J. Dugan",
            "C. Clark",
            "Yann LeCun",
            "S. Parijs"
          ]
        },
        {
          "title": "NeuFlow: Dataflow vision processing system-on-a-chip",
          "year": 2012,
          "citations": 91,
          "abstract": null,
          "venue": "Midwest Symposium on Circuits and Systems",
          "doi": "10.1109/MWSCAS.2012.6292202",
          "url": "https://www.semanticscholar.org/paper/90ddfda9c97e96fbba0b5a314853e5867d813a2b",
          "authors": [
            "Phi-Hung Pham",
            "D. Jelača",
            "C. Farabet",
            "B. Martini",
            "Yann LeCun",
            "E. Culurciello"
          ]
        },
        {
          "title": "Learning and Development After School",
          "year": 2012,
          "citations": 2,
          "abstract": null,
          "venue": "",
          "doi": "10.1007/springerreference_301883",
          "url": "https://www.semanticscholar.org/paper/9f2f315d994a95e04c695c392ac3d80c0345b880",
          "authors": [
            "C. Chan",
            "Z. Zorina",
            "Jesse R. Sparks",
            "S. L. Ornat",
            "C. Tsang",
            "E. Grigorenko",
            "R. Lubow",
            "J. Malone",
            "M. Domjan",
            "Charles Yang",
            "Michelyn C. Butler",
            "M. Gettinger",
            "T. Minor",
            "Traci N. Plumb",
            "H. Drachsler",
            "P. Kirschner",
            "M. Nakayama",
            "Rowena Santiago",
            "Ali Şimşek",
            "Fang‐Ying Yang",
            "Yi-Chun Chen",
            "G. Brooke",
            "Heidi L. Andrade",
            "R. Cooper",
            "A. Podolskiy",
            "David W. Versailles",
            "Valérie Mérindol",
            "E. Guerci",
            "Nobuyuki Hanaki",
            "D. Grollman",
            "A. Billard",
            "L. Lamb",
            "A. Garcez",
            "D. Németh",
            "K. Janacsek",
            "John A. Nunnery",
            "Lynda Byrd-Poller",
            "M. Haan",
            "Rodrigo Harrison",
            "Mauricio G. Villena",
            "L. Izquierdo",
            "Segismundo S. Izquierdo",
            "F. Vega-Redondo",
            "T. Alloway",
            "U. Halsband",
            "N. Seel",
            "G. Bedny",
            "Hansjörg von Brevern",
            "K. Synytsya",
            "G. Kern-Isberner",
            "J. Breuker",
            "S. Cerri",
            "T. Zittoun",
            "S. Brinkmann",
            "Negin Dahya",
            "S. B. Fountain",
            "Karen E. Doyle",
            "K. Sarfo",
            "Bertram C. Bruce",
            "N. Bloch",
            "C. Olsson",
            "L. Nyberg",
            "R. Freivalds",
            "L. Hall",
            "M. Hall",
            "U. Hanke",
            "L. Norton",
            "Aytac Gogus",
            "K. Illeris",
            "M. Macy",
            "A. Flache",
            "A. Robins",
            "L. Thorogood",
            "M. Udell",
            "C. Wynne",
            "P. Burnett",
            "M. Cannon",
            "A. Edmondson",
            "P. Hartono",
            "A. Callender",
            "R. Barr",
            "N. Brito",
            "Noorizah Mohd. Noor",
            "Tg. Nor Rizan Tg. Mohamad Maasum",
            "K. Cennamo",
            "Marc'Aurelio Ranzato",
            "Y-Lan Boureau",
            "K. Kavukcuoglu",
            "Karol Gregor",
            "Yann LeCun",
            "M. Alias",
            "Caifeng Shan",
            "Alice Y. Kolb",
            "D. Kolb",
            "R. Reilly",
            "K. Nielsen",
            "P. Couvillon",
            "H. King",
            "J. Dillon",
            "D. Neuman",
            "J. E. Purdy",
            "Linda Kragelund",
            "F. Gobet",
            "P. C. Lane",
            "S. Naidu",
            "Danny R. Bedgood",
            "Dirk Ifenthaler",
            "Ida Moadab",
            "D. Tucker",
            "P. Hager",
            "J. Fejes",
            "Danielle C. Colas-Zelin",
            "L. Matzel",
            "P. Perruchet",
            "B. Poulin-Charronnat",
            "S. Pacton",
            "C. Linnman",
            "Mohamed A Zeidan",
            "M. Milad",
            "I. Holloway",
            "D. Ansari",
            "K. Lionello-denolf",
            "J. Burgoyne",
            "Judy Huang",
            "Roger K. Thomas",
            "S. Pietropaolo",
            "Wim E. Crusio",
            "Sabine Richter",
            "J. Elen",
            "G. Clarebout",
            "Eliza Bliss-Moreau",
            "Jonte Bernhard",
            "Marcia L. Conner",
            "Lanita Jacobs",
            "Mariel Miller",
            "A. Hadwin",
            "M. Coen",
            "Carlo P. Magno",
            "Eli Hinkel",
            "S. Szedmák",
            "F. Balagué",
            "M. Milrad",
            "H. Hoppe",
            "Krisztina Molnár",
            "E. Vries",
            "E. Blanchard",
            "C. Frasson",
            "Susanne P. Lajoie",
            "T. Cazenave",
            "T. Jong",
            "J. Meij",
            "J. Gavelek",
            "A. Kong",
            "A. Daffertshofer",
            "J. Alonso-Tapia",
            "S. Billett",
            "D. Rumbaugh",
            "M. Beran",
            "Imran Ho-Abdullah",
            "Norsimah Mat Awal",
            "D. Seo",
            "M. Monfils",
            "A. Wright",
            "D. Deshler",
            "Frances M. Ihle",
            "Carrie Mark",
            "Daniel T. Pollitt",
            "M. Kennedy",
            "M. Jackson",
            "T. Nunes",
            "B. Jackling",
            "R. Howard",
            "W. Kennedy",
            "L. C. Drickamer"
          ]
        },
        {
          "title": "Convolutional neural networks applied to house numbers digit classification",
          "year": 2012,
          "citations": 551,
          "abstract": "We classify digits of real-world house numbers using convolutional neural networks (ConvNets). Con-vNets are hierarchical feature learning neural networks whose structure is biologically inspired. Unlike many popular vision approaches that are hand-designed, ConvNets can automatically learn a unique set of features optimized for a given task. We augmented the traditional ConvNet architecture by learning multi-stage features and by using Lp pooling and establish a new state-of-the-art of 95.10% accuracy on the SVHN dataset (48% error improvement). Furthermore, we analyze the benefits of different pooling methods and multi-stage features in ConvNets. The source code and a tutorial are available at eblearn.sf.net.",
          "venue": "International Conference on Pattern Recognition",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/9f7f9aba0a6a966ce04e29e401ea28f9eae82f02",
          "authors": [
            "P. Sermanet",
            "Soumith Chintala",
            "Yann LeCun"
          ]
        },
        {
          "title": "Pedestrian Detection with Unsupervised Multi-stage Feature Learning",
          "year": 2012,
          "citations": 832,
          "abstract": "Pedestrian detection is a problem of considerable practical interest. Adding to the list of successful applications of deep learning methods to vision, we report state-of-the-art and competitive results on all major pedestrian datasets with a convolutional network model. The model uses a few new twists, such as multi-stage features, connections that skip layers to integrate global shape information with local distinctive motif information, and an unsupervised method based on convolutional sparse coding to pre-train the filters at each stage.",
          "venue": "2013 IEEE Conference on Computer Vision and Pattern Recognition",
          "doi": "10.1109/CVPR.2013.465",
          "url": "https://www.semanticscholar.org/paper/a1306ce652f556fbb9e794d91084a29294298e6d",
          "authors": [
            "P. Sermanet",
            "K. Kavukcuoglu",
            "Soumith Chintala",
            "Yann LeCun"
          ]
        },
        {
          "title": "Efficient BackProp",
          "year": 2012,
          "citations": 3363,
          "abstract": null,
          "venue": "Neural Networks",
          "doi": "10.1007/978-3-642-35289-8_3",
          "url": "https://www.semanticscholar.org/paper/b87274e6d9aa4e6ba5148898aa92941617d2b6ed",
          "authors": [
            "Yann LeCun",
            "L. Bottou",
            "Genevieve B. Orr",
            "K. Müller"
          ]
        },
        {
          "title": "Deep Learning Made Easier by Linear Transformations in Perceptrons",
          "year": 2012,
          "citations": 210,
          "abstract": null,
          "venue": "International Conference on Artificial Intelligence and Statistics",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/b8ef1230a5cc9ea7cd8358f1ae7d1af97813ba14",
          "authors": [
            "T. Raiko",
            "Harri Valpola",
            "Yann LeCun"
          ]
        },
        {
          "title": "Statistical Machine Learning and Dissolved Gas Analysis: A Review",
          "year": 2012,
          "citations": 114,
          "abstract": null,
          "venue": "IEEE Transactions on Power Delivery",
          "doi": "10.1109/TPWRD.2012.2197868",
          "url": "https://www.semanticscholar.org/paper/c58cafdd224437f2f7ee59ca70c10cf13ab260d9",
          "authors": [
            "Piotr Wojciech Mirowski",
            "Yann LeCun"
          ]
        },
        {
          "title": "1 Efficient BackProp",
          "year": 2012,
          "citations": 4,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/c7f032fb72e4666f6b1763f2eec5906c86459b5b",
          "authors": [
            "Yann LeCun",
            "L. Bottou",
            "Genevieve B. Orr",
            "K. Müller"
          ]
        },
        {
          "title": "No more pesky learning rates",
          "year": 2012,
          "citations": 487,
          "abstract": "The performance of stochastic gradient descent (SGD) depends critically on how learning rates are tuned and decreased over time. We propose a method to automatically adjust multiple learning rates so as to minimize the expected error at any one time. The method relies on local gradient variations across samples. In our approach, learning rates can increase as well as decrease, making it suitable for non-stationary problems. Using a number of convex and non-convex learning tasks, we show that the resulting algorithm matches the performance of SGD or other adaptive approaches with their best settings obtained through systematic search, and effectively removes the need for learning rate tuning.",
          "venue": "International Conference on Machine Learning",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/e5a685f40338f9c2f3e68e142efa217aad16dd56",
          "authors": [
            "T. Schaul",
            "Sixin Zhang",
            "Yann LeCun"
          ]
        },
        {
          "title": "Learning Invariant Feature Hierarchies",
          "year": 2012,
          "citations": 161,
          "abstract": null,
          "venue": "ECCV Workshops",
          "doi": "10.1007/978-3-642-33863-2_51",
          "url": "https://www.semanticscholar.org/paper/e882a6014ac4d66b1035729305ff8aa76ba5d09d",
          "authors": [
            "Yann LeCun"
          ]
        },
        {
          "title": "Fast Approximations to Structured Sparse Coding and Applications to Object Classification",
          "year": 2012,
          "citations": 39,
          "abstract": "We describe a method for fast approximation of sparse coding. A given input vector is passed through a binary tree. Each leaf of the tree contains a subset of dictionary elements. The coefficients corresponding to these dictionary elements are allowed to be nonzero and their values are calculated quickly by multiplication with a precomputed pseudoinverse. The tree parameters, the dictionary, and the subsets of the dictionary corresponding to each leaf are learned. In the process of describing this algorithm, we discuss the more general problem of learning the groups in group structured sparse modeling. We show that our method creates good sparse representations by using it in the object recognition framework of [1,2]. Implementing our own fast version of the SIFT descriptor the whole system runs at 20 frames per second on 321 ×481 sized images on a laptop with a quad-core cpu, while sacrificing very little accuracy on the Caltech 101, Caltech 256, and 15 scenes benchmarks.",
          "venue": "European Conference on Computer Vision",
          "doi": "10.1007/978-3-642-33715-4_15",
          "url": "https://www.semanticscholar.org/paper/e884feeab763a2e4a4d1279267a42d17c67c015c",
          "authors": [
            "Arthur Szlam",
            "Karol Gregor",
            "Yann LeCun"
          ]
        },
        {
          "title": "Structured sparse coding via lateral inhibition",
          "year": 2011,
          "citations": 58,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/044fddbc2e52add6d2b2c9d79544446854ebeb39",
          "authors": [
            "Arthur Szlam",
            "Karol Gregor",
            "Yann LeCun"
          ]
        },
        {
          "title": "NeuFlow: A runtime reconfigurable dataflow processor for vision",
          "year": 2011,
          "citations": 386,
          "abstract": null,
          "venue": "CVPR 2011 WORKSHOPS",
          "doi": "10.1109/CVPRW.2011.5981829",
          "url": "https://www.semanticscholar.org/paper/204710a6a6d935150b5b16daf74493dea6d1b7a2",
          "authors": [
            "C. Farabet",
            "B. Martini",
            "B. Corda",
            "Polina Akselrod",
            "E. Culurciello",
            "Yann LeCun"
          ]
        },
        {
          "title": "Unsupervised Learning of Sparse Features for Scalable Audio Classification",
          "year": 2011,
          "citations": 137,
          "abstract": null,
          "venue": "International Society for Music Information Retrieval Conference",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/34642631a6ef8130b98ce73e61298bb9c89b0c71",
          "authors": [
            "Mikael Henaff",
            "Kevin Jarrett",
            "K. Kavukcuoglu",
            "Yann LeCun"
          ]
        },
        {
          "title": "Hardware accelerated visual attention algorithm",
          "year": 2011,
          "citations": 7,
          "abstract": null,
          "venue": "Annual Conference on Information Sciences and Systems",
          "doi": "10.1109/CISS.2011.5766191",
          "url": "https://www.semanticscholar.org/paper/4c87d431433a5e16598a110691ff77160f012da0",
          "authors": [
            "Polina Akselrod",
            "Faye Zhao",
            "Ifigeneia Derekli",
            "C. Farabet",
            "B. Martini",
            "Yann LeCun",
            "E. Culurciello"
          ]
        },
        {
          "title": "Building Artificial Vision Systems with Machine Learning",
          "year": 2011,
          "citations": 1,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/7ad0435f585f7bebe5c9207ee54228b2858cfc8f",
          "authors": [
            "Yann LeCun"
          ]
        },
        {
          "title": "Concerto for violin and Markov model",
          "year": 2011,
          "citations": 0,
          "abstract": null,
          "venue": "Communications of the ACM",
          "doi": "10.1145/1897852.1897874",
          "url": "https://www.semanticscholar.org/paper/85c783700095ed2e6714bf2dd39e7f3dd79b72dd",
          "authors": [
            "J. Bello",
            "Yann LeCun",
            "R. Rowe"
          ]
        },
        {
          "title": "Ask the locals: Multi-way local pooling for image recognition",
          "year": 2011,
          "citations": 302,
          "abstract": null,
          "venue": "Vision",
          "doi": "10.1109/ICCV.2011.6126555",
          "url": "https://www.semanticscholar.org/paper/9791f1e47a48fa05387cb8dd93da53bf8f43c1f4",
          "authors": [
            "Y-Lan Boureau",
            "Nicolas Le Roux",
            "F. Bach",
            "J. Ponce",
            "Yann LeCun"
          ]
        },
        {
          "title": "Traffic sign recognition with multi-scale Convolutional Networks",
          "year": 2011,
          "citations": 795,
          "abstract": null,
          "venue": "The 2011 International Joint Conference on Neural Networks",
          "doi": "10.1109/IJCNN.2011.6033589",
          "url": "https://www.semanticscholar.org/paper/9ab0de951cc9cdf16887b1f841f8da6affc9c0de",
          "authors": [
            "P. Sermanet",
            "Yann LeCun"
          ]
        },
        {
          "title": "The NIPS workshop on Deep Learning and Unsupervised Feature Learning",
          "year": 2011,
          "citations": 11,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/ae47286f40db22e64aaeec97497b9f522bd00943",
          "authors": [
            "T. Raiko",
            "Harri Valpola",
            "Yann LeCun"
          ]
        },
        {
          "title": "Large-Scale FPGA-based Convolutional Networks",
          "year": 2011,
          "citations": 135,
          "abstract": null,
          "venue": "",
          "doi": "10.1017/CBO9781139042918.020",
          "url": "https://www.semanticscholar.org/paper/b970c9d53c699a8e09f1d8dbe440b6f309712a89",
          "authors": [
            "C. Farabet",
            "Yann LeCun",
            "K. Kavukcuoglu",
            "B. Martini",
            "Polina Akselrod",
            "S. Talay",
            "E. Culurciello"
          ]
        },
        {
          "title": "Learning Representations by Maximizing Compression",
          "year": 2011,
          "citations": 17,
          "abstract": "We give an algorithm that learns a representation of data through compression. The algorithm 1) predicts bits sequentially from those previously seen and 2) has a structure and a number of computations similar to an autoencoder. The likelihood under the model can be calculated exactly, and arithmetic coding can be used directly for compression. When training on digits the algorithm learns filters similar to those of restricted boltzman machines and denoising autoencoders. Independent samples can be drawn from the model by a single sweep through the pixels. The algorithm has a good compression performance when compared to other methods that work under random ordering of pixels.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/bf326ddb9b9b15f5a285600af29e43c558ac890f",
          "authors": [
            "Karol Gregor",
            "Yann LeCun"
          ]
        },
        {
          "title": "Efficient Learning of Sparse Invariant Representations",
          "year": 2011,
          "citations": 5,
          "abstract": "We propose a simple and efficient algorithm for learning sparse invariant representations from unlabeled data with fast inference. When trained on short movies sequences, the learned features are selective to a range of orientations and spatial frequencies, but robust to a wide range of positions, similar to complex cells in the primary visual cortex. We give a hierarchical version of the algorithm, and give guarantees of fast convergence under certain conditions.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/d427d3327cbab52468d310af6331e8cc84dea8ff",
          "authors": [
            "Karol Gregor",
            "Yann LeCun"
          ]
        },
        {
          "title": "Convolutional Matching Pursuit and Dictionary Training",
          "year": 2010,
          "citations": 49,
          "abstract": "Here, {W,Z} are the dictionary and the coefficients, respectively, and zk is the kth column of Z. K, q, and λ are user selected parameters controlling the power of the model. More recently, many models with additional structure have been proposed. For example, in [9, 2], the dictionary elements are arranged in groups and the sparsity is on the group level. In [3, 5, 7], the dictionaries are constructed to be translation invariant. In the former work, the dictionary is constructed via a non-negative matrix factorization. In the latter two works, the construction is a convolutional analogue of 1.2 or an l variant, with 0 < p < 1. In this short note we work with greedy algorithms for solving the convolutional analogues of 1.1. Specifically, we demonstrate that sparse coding by matching pursuit and dictionary learning via K-SVD [1] can be used in the translation invariant setting.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/10c8b29d7820bab2bab0610b9211b6852f272002",
          "authors": [
            "Arthur Szlam",
            "K. Kavukcuoglu",
            "Yann LeCun"
          ]
        },
        {
          "title": "Final thesis for the fulfilment of the requirements for the degree of MSc. in Applied Computing Science Improving Score Matching for learning statistical models of natural images",
          "year": 2010,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/1f6062b766dfa0dabc4edb58d3694798556c62dc",
          "authors": [
            "Yann LeCun"
          ]
        },
        {
          "title": "Emergence of Complex-Like Cells in a Temporal Product Network with Local Receptive Fields",
          "year": 2010,
          "citations": 72,
          "abstract": "We introduce a new neural architecture and an unsupervised algorithm for learning invariant representations from temporal sequence of images. The system uses two groups of complex cells whose outputs are combined multiplicatively: one that represents the content of the image, constrained to be constant over several consecutive frames, and one that represents the precise location of features, which is allowed to vary over time but constrained to be sparse. The architecture uses an encoder to extract features, and a decoder to reconstruct the input from the features. The method was applied to patches extracted from consecutive movie frames and produces orientation and frequency selective units analogous to the complex cells in V1. An extension of the method is proposed to train a network composed of units with local receptive field spread over a large image of arbitrary size. A layer of complex cells, subject to sparsity constraints, pool feature units over overlapping local neighborhoods, which causes the feature units to organize themselves into pinwheel patterns of orientation-selective receptive fields, similar to those observed in the mammalian visual cortex. A feed-forward encoder efficiently computes the feature representation of full images.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/31f04f8f83365fabf7ba9c9be1179c0da6815128",
          "authors": [
            "Karol Gregor",
            "Yann LeCun"
          ]
        },
        {
          "title": "A Theoretical Analysis of Feature Pooling in Visual Recognition",
          "year": 2010,
          "citations": 1366,
          "abstract": null,
          "venue": "International Conference on Machine Learning",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/405aed4b8ecdd869b2e83095dde51c396334115f",
          "authors": [
            "Y-Lan Boureau",
            "J. Ponce",
            "Yann LeCun"
          ]
        },
        {
          "title": "REASSESSING FHA RISK 1",
          "year": 2010,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/474b68356813e17dc22150df627f35703d98600c",
          "authors": [
            "Diego Aragon",
            "Andrew Caplin",
            "S. Chopra",
            "John Leahy",
            "Yann LeCun",
            "Marco Scoffier",
            "Joseph S. Tracy"
          ]
        },
        {
          "title": "Learning mid-level features for recognition",
          "year": 2010,
          "citations": 1157,
          "abstract": null,
          "venue": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
          "doi": "10.1109/CVPR.2010.5539963",
          "url": "https://www.semanticscholar.org/paper/498efaa51f5eda731dc6199c3547b9465717fa68",
          "authors": [
            "Y-Lan Boureau",
            "F. Bach",
            "Yann LeCun",
            "J. Ponce"
          ]
        },
        {
          "title": "Hybrid hessians for flexible optimization of pose graphs",
          "year": 2010,
          "citations": 15,
          "abstract": null,
          "venue": "2010 IEEE/RSJ International Conference on Intelligent Robots and Systems",
          "doi": "10.1109/IROS.2010.5650091",
          "url": "https://www.semanticscholar.org/paper/499e299ff22c9ff7b53fcd704eb38f0ce1fce1fd",
          "authors": [
            "M. Grimes",
            "Dragomir Anguelov",
            "Yann LeCun"
          ]
        },
        {
          "title": "Convolutional Learning of Spatio-temporal Features",
          "year": 2010,
          "citations": 697,
          "abstract": null,
          "venue": "European Conference on Computer Vision",
          "doi": "10.1007/978-3-642-15567-3_11",
          "url": "https://www.semanticscholar.org/paper/4d476b96be73fccc61f2076befbf5a468caa4180",
          "authors": [
            "Graham W. Taylor",
            "R. Fergus",
            "Yann LeCun",
            "C. Bregler"
          ]
        },
        {
          "title": "Time Series Modeling with Hidden Variables and Gradient-Based Algorithms",
          "year": 2010,
          "citations": 4,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/5f21dd0b3eecf2a3d396f91f7183d59be6ef07fa",
          "authors": [
            "Yann LeCun",
            "Piotr Wojciech Mirowski"
          ]
        },
        {
          "title": "Bio-Inspired Vision Processor for Ultra-Fast Object Categorization",
          "year": 2010,
          "citations": 3,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/6116a4b9af3c3e8313b442f62cf1cfd918b756e9",
          "authors": [
            "C. Farabet",
            "B. Martini",
            "Polina Akselrod",
            "B. Corda",
            "S. Talay",
            "Yann LeCun",
            "E. Culurciello"
          ]
        },
        {
          "title": "Predictive network modeling of the high-resolution dynamic plant transcriptome in response to nitrate",
          "year": 2010,
          "citations": 250,
          "abstract": "BackgroundNitrate, acting as both a nitrogen source and a signaling molecule, controls many aspects of plant development. However, gene networks involved in plant adaptation to fluctuating nitrate environments have not yet been identified.ResultsHere we use time-series transcriptome data to decipher gene relationships and consequently to build core regulatory networks involved in Arabidopsis root adaptation to nitrate provision. The experimental approach has been to monitor genome-wide responses to nitrate at 3, 6, 9, 12, 15 and 20 minutes using Affymetrix ATH1 gene chips. This high-resolution time course analysis demonstrated that the previously known primary nitrate response is actually preceded by a very fast gene expression modulation, involving genes and functions needed to prepare plants to use or reduce nitrate. A state-space model inferred from this microarray time-series data successfully predicts gene behavior in unlearnt conditions.ConclusionsThe experiments and methods allow us to propose a temporal working model for nitrate-driven gene networks. This network model is tested both in silico and experimentally. For example, the over-expression of a predicted gene hub encoding a transcription factor induced early in the cascade indeed leads to the modification of the kinetic nitrate response of sentinel genes such as NIR, NIA2, and NRT1.1, and several other transcription factors. The potential nitrate/hormone connections implicated by this time-series data are also evaluated.",
          "venue": "Genome Biology",
          "doi": "10.1186/gb-2010-11-12-r123",
          "url": "https://www.semanticscholar.org/paper/631b72d4f83f86f4c8d271c736ed3087c5f7be6e",
          "authors": [
            "Gabriel Krouk",
            "Piotr Wojciech Mirowski",
            "Yann LeCun",
            "D. Shasha",
            "G. Coruzzi"
          ]
        },
        {
          "title": "Regularized estimation of image statistics by Score Matching",
          "year": 2010,
          "citations": 87,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/74706fab48249b071e10615f8da60b8401fb9f3f",
          "authors": [
            "Diederik P. Kingma",
            "Yann LeCun"
          ]
        },
        {
          "title": "Dynamic auto-encoders for semantic indexing",
          "year": 2010,
          "citations": 34,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/80922663aaa7b09e86276ab97210ab2372d3f61a",
          "authors": [
            "Piotr Wojciech Mirowski",
            "Marc'Aurelio Ranzato",
            "Yann LeCun"
          ]
        },
        {
          "title": "Learning Feature Hierarchies for Object Recognition",
          "year": 2010,
          "citations": 2,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/84d2aaa96412156c6be140b0fb27731ecb822044",
          "authors": [
            "Yann LeCun",
            "K. Kavukcuoglu"
          ]
        },
        {
          "title": "Learning Convolutional Feature Hierarchies for Visual Recognition",
          "year": 2010,
          "citations": 594,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/8b25a44f617c1ed3ed52c6655b0d456ff1c565bd",
          "authors": [
            "K. Kavukcuoglu",
            "P. Sermanet",
            "Y-Lan Boureau",
            "Karol Gregor",
            "Michaël Mathieu",
            "Yann LeCun"
          ]
        },
        {
          "title": "Hardware accelerated convolutional neural networks for synthetic vision systems",
          "year": 2010,
          "citations": 240,
          "abstract": null,
          "venue": "Proceedings of 2010 IEEE International Symposium on Circuits and Systems",
          "doi": "10.1109/ISCAS.2010.5537908",
          "url": "https://www.semanticscholar.org/paper/c3c82b476162d2d006e02180530875a64af18154",
          "authors": [
            "C. Farabet",
            "B. Martini",
            "Polina Akselrod",
            "S. Talay",
            "Yann LeCun",
            "E. Culurciello"
          ]
        },
        {
          "title": "Convolutional networks and applications in vision",
          "year": 2010,
          "citations": 2075,
          "abstract": null,
          "venue": "Proceedings of 2010 IEEE International Symposium on Circuits and Systems",
          "doi": "10.1109/ISCAS.2010.5537907",
          "url": "https://www.semanticscholar.org/paper/c43025c429b1fbf6f1379f61801a1b40834d62e7",
          "authors": [
            "Yann LeCun",
            "K. Kavukcuoglu",
            "C. Farabet"
          ]
        },
        {
          "title": "Fast Inference in Sparse Coding Algorithms with Applications to Object Recognition",
          "year": 2010,
          "citations": 250,
          "abstract": "Adaptive sparse coding methods learn a possibly overcomplete set of basis functions, such that natural image patches can be reconstructed by linearly combining a small subset of these bases. The applicability of these methods to visual object recognition tasks has been limited because of the prohibitive cost of the optimization algorithms required to compute the sparse representation. In this work we propose a simple and efficient algorithm to learn basis functions. After training, this model also provides a fast and smooth approximator to the optimal representation, achieving even better accuracy than exact sparse coding algorithms on visual object recognition tasks.",
          "venue": "arXiv.org",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/c63ef05c5f9c424b5cfeeed90dbe35eedf6cb8ec",
          "authors": [
            "K. Kavukcuoglu",
            "Marc'Aurelio Ranzato",
            "Yann LeCun"
          ]
        },
        {
          "title": "Reassessing FHA Risk",
          "year": 2010,
          "citations": 24,
          "abstract": null,
          "venue": "",
          "doi": "10.3386/W15802",
          "url": "https://www.semanticscholar.org/paper/cb4ac759471a80cc5d15fd36361c6c73c407dd97",
          "authors": [
            "Diego Aragon",
            "Andrew Caplin",
            "S. Chopra",
            "John Leahy",
            "Yann LeCun",
            "Marco Scoffier",
            "Joseph S. Tracy"
          ]
        },
        {
          "title": "Learning Fast Approximations of Sparse Coding",
          "year": 2010,
          "citations": 1889,
          "abstract": null,
          "venue": "International Conference on Machine Learning",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/e8f811399746c059bf4d4c3d43334045e0222209",
          "authors": [
            "Karol Gregor",
            "Yann LeCun"
          ]
        },
        {
          "title": "CNP: An FPGA-based processor for Convolutional Networks",
          "year": 2009,
          "citations": 362,
          "abstract": null,
          "venue": "International Conference on Field-Programmable Logic and Applications",
          "doi": "10.1109/FPL.2009.5272559",
          "url": "https://www.semanticscholar.org/paper/07956c7cf9bf4267b86d52aa4143c17a4aa5d0d6",
          "authors": [
            "C. Farabet",
            "Cyril Poulet",
            "Jefferson Y. Han",
            "Yann LeCun"
          ]
        },
        {
          "title": "Efficient off-road localization using visually corrected odometry",
          "year": 2009,
          "citations": 11,
          "abstract": null,
          "venue": "IEEE International Conference on Robotics and Automation",
          "doi": "10.1109/ROBOT.2009.5152880",
          "url": "https://www.semanticscholar.org/paper/083d38843c14e02970cf86d9161a5a2bf40d2bab",
          "authors": [
            "M. Grimes",
            "Yann LeCun"
          ]
        },
        {
          "title": "High-Accuracy Object Recognition with a New Convolutional Net Architecture and Learning Algorithm",
          "year": 2009,
          "citations": 1,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/10d2ea8d995c04e244bea89c66315f3a41338dd0",
          "authors": [
            "Kevin Jarrett",
            "Marc'Aurelio Ranzato",
            "K. Kavukcuoglu",
            "Yann LeCun"
          ]
        },
        {
          "title": "What is the best multi-stage architecture for object recognition?",
          "year": 2009,
          "citations": 2358,
          "abstract": null,
          "venue": "IEEE International Conference on Computer Vision",
          "doi": "10.1109/ICCV.2009.5459469",
          "url": "https://www.semanticscholar.org/paper/1f88427d7aa8225e47f946ac41a0667d7b69ac52",
          "authors": [
            "Kevin Jarrett",
            "K. Kavukcuoglu",
            "Marc'Aurelio Ranzato",
            "Yann LeCun"
          ]
        },
        {
          "title": "Learning long‐range vision for autonomous off‐road driving",
          "year": 2009,
          "citations": 314,
          "abstract": null,
          "venue": "J. Field Robotics",
          "doi": "10.1002/rob.20276",
          "url": "https://www.semanticscholar.org/paper/2d8f527d1a96b0dae209daa6a241cf3255a6ec0d",
          "authors": [
            "R. Hadsell",
            "P. Sermanet",
            "J. Ben",
            "A. Erkan",
            "Marco Scoffier",
            "K. Kavukcuoglu",
            "Urs Muller",
            "Yann LeCun"
          ]
        },
        {
          "title": "Unsupervised Learning of Feature Hierarchies",
          "year": 2009,
          "citations": 20,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/3b3c153b09495e2f79dd973253f9d2ee763940a5",
          "authors": [
            "Yann LeCun",
            "Marc'Aurelio Ranzato"
          ]
        },
        {
          "title": "Learning invariant features through topographic filter maps",
          "year": 2009,
          "citations": 347,
          "abstract": null,
          "venue": "2009 IEEE Conference on Computer Vision and Pattern Recognition",
          "doi": "10.1109/CVPR.2009.5206545",
          "url": "https://www.semanticscholar.org/paper/54a9c2553138932426faebcaa67a63a84a56b55d",
          "authors": [
            "K. Kavukcuoglu",
            "Marc'Aurelio Ranzato",
            "R. Fergus",
            "Yann LeCun"
          ]
        },
        {
          "title": "Dynamic Factor Graphs for Time Series Modeling",
          "year": 2009,
          "citations": 54,
          "abstract": null,
          "venue": "ECML/PKDD",
          "doi": "10.1007/978-3-642-04174-7_9",
          "url": "https://www.semanticscholar.org/paper/678d67db7b65b07b6d4b941cc138a33dcdf47b81",
          "authors": [
            "Piotr Wojciech Mirowski",
            "Yann LeCun"
          ]
        },
        {
          "title": "An FPGA-based stream processor for embedded real-time vision with Convolutional Networks",
          "year": 2009,
          "citations": 63,
          "abstract": null,
          "venue": "2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops",
          "doi": "10.1109/ICCVW.2009.5457611",
          "url": "https://www.semanticscholar.org/paper/777de11e21d10cb627d109d0f64630115ff7823f",
          "authors": [
            "C. Farabet",
            "Cyril Poulet",
            "Yann LeCun"
          ]
        },
        {
          "title": "EBLearn: Open-Source Energy-Based Learning in C++",
          "year": 2009,
          "citations": 34,
          "abstract": null,
          "venue": "IEEE International Conference on Tools with Artificial Intelligence",
          "doi": "10.1109/ICTAI.2009.28",
          "url": "https://www.semanticscholar.org/paper/78e5bca056ffc6186400ba540a0c0f43df909a12",
          "authors": [
            "P. Sermanet",
            "K. Kavukcuoglu",
            "Yann LeCun"
          ]
        },
        {
          "title": "Literacy and Learning",
          "year": 2009,
          "citations": 1,
          "abstract": null,
          "venue": "",
          "doi": "10.1007/978-1-4419-1428-6_553",
          "url": "https://www.semanticscholar.org/paper/7ac232e5b466002a5890d5d9fd11adcc8a948b62",
          "authors": [
            "Cecilia Ka Yuk Chan",
            "Zoya A. Zorina",
            "Jesse R. Sparks",
            "S. López Ornat",
            "Christine D. Tsang",
            "Elena L. Grigorenko",
            "R. Lubow",
            "John C. Malone",
            "Michael Domjan",
            "Charles Yang",
            "Michelyn C. Butler",
            "M. Gettinger",
            "Thomas R. Minor",
            "Traci N. Plumb",
            "Hendrik Drachsler",
            "P. A. Kirschner",
            "Minoru Nakayama",
            "Rowena Santiago",
            "Ali Simsek",
            "Fang-Ying Yang",
            "Yi-Chun Chen",
            "G. Brooke",
            "Heidi L. Andrade",
            "Richard P. Cooper",
            "A. Podolskiy",
            "David W. Versailles",
            "Valérie Mérindol",
            "E. Guerci",
            "Nobuyuki Hanaki",
            "D. Grollman",
            "A. Billard",
            "Luis C. Lamb",
            "Artur d’Avila Garcez",
            "D. Németh",
            "K. Janacsek",
            "John J. Nunnery",
            "L. Byrd-Poller",
            "M. Haan",
            "Rodrigo Harrison",
            "Mauricio G. Villena",
            "L. Izquierdo",
            "Segismundo S. Izquierdo",
            "F. Vega-Redondo",
            "Tracy Packiam Alloway",
            "Ulrike Halsband",
            "N. Seel",
            "G. Bedny",
            "Hansjörg von Brevern",
            "K. Synytsya",
            "Gabriele Kern-Isberner",
            "Joost Breuker",
            "S. Cerri",
            "T. Zittoun",
            "S. Brinkmann",
            "Negin Dahya",
            "S. B. Fountain",
            "Karen E. Doyle",
            "K. Sarfo",
            "Bertram C. Bruce",
            "N. Bloch",
            "C.-J. Olsson",
            "Lars Nyberg",
            "R. Freivalds",
            "Lynne Hall",
            "M. Hall",
            "Ulrike Hanke",
            "Lin S. Norton",
            "Aytac Gogus",
            "K. Illeris",
            "M. Macy",
            "A. Flache",
            "Anthony Robins",
            "L. Thorogood",
            "M. Udell",
            "C. Wynne",
            "Paul C. Burnett",
            "M. Cannon",
            "Amy C. Edmondson",
            "Pitoyo Hartono",
            "A. Callender",
            "Rachel Barr",
            "Natalie Brito",
            "Noorizah Mohd. Noor",
            "Tg. Nor Rizan Tg. Mohd. Maasum",
            "K. Cennamo",
            "Marc'Aurelio Ranzato",
            "Y-Lan Boureau",
            "K. Kavukcuoglu",
            "Karol Gregor",
            "Yann LeCun",
            "M. Alias",
            "Caifeng Shan",
            "Alice Y. Kolb",
            "David A. Kolb",
            "R. Reilly",
            "Klaus Nielsen",
            "Patricia Couvillon",
            "Heather King",
            "Justin Dillon",
            "Delia Neuman",
            "J. E. Purdy",
            "Linda Kragelund",
            "Fernand Gobet",
            "Peter C. R. Lane",
            "Som Naidu",
            "Danny R. Bedgood",
            "Dirk Ifenthaler",
            "Ida Moadab",
            "Don M. Tucker",
            "Paul J. Hager",
            "J. Fejes",
            "Danielle C. Colas-Zelin",
            "L. Matzel",
            "P. Perruchet",
            "B. Poulin-Charronnat",
            "S. Pacton",
            "C. Linnman",
            "Mohamed A Zeidan",
            "M. Milad",
            "I. Holloway",
            "Daniel Ansari",
            "K. Lionello-DeNolf",
            "John Burgoyne",
            "Judy Huang",
            "Roger K. Thomas",
            "S. Pietropaolo",
            "Wim E. Crusio",
            "Sabine Richter",
            "J. Elen",
            "G. Clarebout",
            "E. Bliss-Moreau",
            "Jonte Bernhard",
            "Marcia L. Conner",
            "Lanita Jacobs",
            "Mariel Miller",
            "Allyson F. Hadwin",
            "M. Coen",
            "Carlo Magno",
            "Eli Hinkel",
            "S. Szedmák",
            "F. Balagué",
            "M. Milrad",
            "H. U. Hoppe",
            "Krisztina Molnar",
            "Erica de Vries",
            "Emmanuel G. Blanchard",
            "C. Frasson",
            "Susanne P. Lajoie",
            "Tristan Cazenave",
            "Ton Jong",
            "Jan Meij",
            "J. Gavelek",
            "Ailing Kong",
            "A. Daffertshofer",
            "J. Alonso-Tapia",
            "Stephen Billett",
            "D. Rumbaugh",
            "Michael J. Beran",
            "Imran Ho-Abdullah",
            "Norsimah Mat Awal",
            "Dong-oh Seo",
            "M. Monfils",
            "Anthony A. Wright",
            "D. Deshler",
            "Frances M. Ihle",
            "Carrie Mark",
            "Daniel T. Pollitt",
            "Michael J. Kennedy",
            "Michael Jackson",
            "Terezinha Nunes",
            "B. Jackling",
            "R. Howard",
            "William G. Kennedy",
            "L. C. Drickamer"
          ]
        },
        {
          "title": "Workshop summary: Workshop on learning feature hierarchies",
          "year": 2009,
          "citations": 2,
          "abstract": null,
          "venue": "International Conference on Machine Learning",
          "doi": "10.1145/1553374.1553543",
          "url": "https://www.semanticscholar.org/paper/7c488cbc4103524b27f42254e9455429b23d92ca",
          "authors": [
            "Kai Yu",
            "R. Salakhutdinov",
            "Yann LeCun",
            "Geoffrey E. Hinton",
            "Yoshua Bengio"
          ]
        },
        {
          "title": "Classification of patterns of EEG synchronization for seizure prediction",
          "year": 2009,
          "citations": 397,
          "abstract": null,
          "venue": "Clinical Neurophysiology",
          "doi": "10.1016/j.clinph.2009.09.002",
          "url": "https://www.semanticscholar.org/paper/9da463da5a35149397273553c4de4626c49bf712",
          "authors": [
            "Piotr Wojciech Mirowski",
            "D. Madhavan",
            "Yann LeCun",
            "R. Kuzniecky"
          ]
        },
        {
          "title": "Learning long-range vision for autonomous off-road driving",
          "year": 2009,
          "citations": 125,
          "abstract": null,
          "venue": "",
          "doi": "10.1002/ROB.V26:2",
          "url": "https://www.semanticscholar.org/paper/a90998e0023db48b207cee3b39b0441b3935aaa7",
          "authors": [
            "R. Hadsell",
            "P. Sermanet",
            "J. Ben",
            "A. Erkan",
            "Marco Scoffier",
            "K. Kavukcuoglu",
            "Urs Muller",
            "Yann LeCun"
          ]
        },
        {
          "title": "A multirange architecture for collision‐free off‐road robot navigation",
          "year": 2009,
          "citations": 48,
          "abstract": null,
          "venue": "J. Field Robotics",
          "doi": "10.1002/rob.20270",
          "url": "https://www.semanticscholar.org/paper/b48d78ed73144d69f6239696e55ba9596fe7813b",
          "authors": [
            "P. Sermanet",
            "R. Hadsell",
            "Marco Scoffier",
            "M. Grimes",
            "J. Ben",
            "A. Erkan",
            "Chris Crudele",
            "Urs Miller",
            "Yann LeCun"
          ]
        },
        {
          "title": "Deep belief net learning in a long-range vision system for autonomous off-road driving",
          "year": 2008,
          "citations": 100,
          "abstract": null,
          "venue": "2008 IEEE/RSJ International Conference on Intelligent Robots and Systems",
          "doi": "10.1109/IROS.2008.4651217",
          "url": "https://www.semanticscholar.org/paper/010b7587ef04d12f162cbdf55657442e289b343d",
          "authors": [
            "R. Hadsell",
            "A. Erkan",
            "P. Sermanet",
            "Marco Scoffier",
            "Urs Muller",
            "Yann LeCun"
          ]
        },
        {
          "title": "Mapping and planning under uncertainty in mobile robots with long-range perception",
          "year": 2008,
          "citations": 38,
          "abstract": null,
          "venue": "2008 IEEE/RSJ International Conference on Intelligent Robots and Systems",
          "doi": "10.1109/IROS.2008.4651203",
          "url": "https://www.semanticscholar.org/paper/1331f67dd0c39845a7b129817a0697d798ffc548",
          "authors": [
            "P. Sermanet",
            "R. Hadsell",
            "Marco Scoffier",
            "Urs Muller",
            "Yann LeCun"
          ]
        },
        {
          "title": "Machine Learning and the Spatial Structure of House Prices and Housing Returns",
          "year": 2008,
          "citations": 29,
          "abstract": null,
          "venue": "",
          "doi": "10.2139/ssrn.1316046",
          "url": "https://www.semanticscholar.org/paper/35d47b5d82e1cdb4d70de7bf35cdfe970d793f35",
          "authors": [
            "Andrew Caplin",
            "S. Chopra",
            "John Leahy",
            "Yann LeCun",
            "Trivikraman Thampy"
          ]
        },
        {
          "title": "Autonomous Learning for Long Range Vision in Mobile Robots",
          "year": 2008,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/39d3c37cb479cd16c027919a5c8774649daec4a9",
          "authors": [
            "R. Hadsell",
            "P. Sermanet",
            "A. Erkan",
            "K. Kavukcuoglu",
            "Urs Muller",
            "Yann LeCun"
          ]
        },
        {
          "title": "Learning Long-Range Vision for an Offroad Robot",
          "year": 2008,
          "citations": 2,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/4b8d80f91d271f61b26db5ad627e24e59955c56a",
          "authors": [
            "Yann LeCun",
            "R. Hadsell"
          ]
        },
        {
          "title": "Comparing SVM and convolutional networks for epileptic seizure prediction from intracranial EEG",
          "year": 2008,
          "citations": 174,
          "abstract": null,
          "venue": "IEEE Workshop on Machine Learning for Signal Processing",
          "doi": "10.1109/MLSP.2008.4685487",
          "url": "https://www.semanticscholar.org/paper/966ce7b2567280088ee1d5816cee9e06d12fa19d",
          "authors": [
            "Piotr Wojciech Mirowski",
            "Yann LeCun",
            "D. Madhavan",
            "R. Kuzniecky"
          ]
        },
        {
          "title": "Learning maneuver dictionaries for ground robot planning",
          "year": 2008,
          "citations": 15,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/bb0eefb5b7d1a07c9abb2efa888060cde8a20bcc",
          "authors": [
            "P. Sermanet",
            "Marco Scoffier",
            "Chris Crudele",
            "Urs Muller",
            "Yann LeCun"
          ]
        },
        {
          "title": "Factor Graphs for Relational Regression",
          "year": 2008,
          "citations": 5,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/d3c3ad20aa5580a6784e445d0296c4ef09a59684",
          "authors": [
            "Yann LeCun",
            "S. Chopra"
          ]
        },
        {
          "title": "Computeur Vision and Pattern Recognition (CVPR). Conference",
          "year": 2008,
          "citations": 1,
          "abstract": null,
          "venue": "Computer Vision and Pattern Recognition",
          "doi": "10.1007/S11263-008-0162-4",
          "url": "https://www.semanticscholar.org/paper/d66f62ffdab3b24326bebd0cf81db5789e56dce0",
          "authors": [
            "A. Fitzgibbon",
            "C. J. Taylor",
            "Yann LeCun"
          ]
        },
        {
          "title": "Editorial",
          "year": 2008,
          "citations": 0,
          "abstract": null,
          "venue": "International Journal of Computer Vision",
          "doi": "10.1007/s11263-008-0162-4",
          "url": "https://www.semanticscholar.org/paper/f200d76bb51c822e797bc54fb12c8c0fc384d9b1",
          "authors": [
            "A. Fitzgibbon",
            "C. J. Taylor",
            "Yann LeCun"
          ]
        },
        {
          "title": "Invariant Feature Learning on a Mobile Robot",
          "year": 2008,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/f67eceab1c562ef3e265f2a64223ffead3ed3c22",
          "authors": [
            "R. Hadsell",
            "Yann LeCun"
          ]
        },
        {
          "title": "Time-Delay Neural Networks and Independent Component Analysis for EEG-Based Prediction of Epileptic Seizures Propagation",
          "year": 2007,
          "citations": 24,
          "abstract": null,
          "venue": "AAAI Conference on Artificial Intelligence",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/0bb4afa755f8694a9c8bdac67149907833637b42",
          "authors": [
            "Piotr Wojciech Mirowski",
            "D. Madhavan",
            "Yann LeCun"
          ]
        },
        {
          "title": "SPEED-RANGE DILEMMAS FOR VISION-BASED NAVIGATION IN UNSTRUCTURED TERRAIN",
          "year": 2007,
          "citations": 10,
          "abstract": null,
          "venue": "",
          "doi": "10.3182/20070903-3-FR-2921.00052",
          "url": "https://www.semanticscholar.org/paper/181c805eb0b2524efb16c6b14dcf2e435140e634",
          "authors": [
            "P. Sermanet",
            "R. Hadsell",
            "J. Ben",
            "A. Erkan",
            "B. Flepp",
            "Urs Muller",
            "Yann LeCun"
          ]
        },
        {
          "title": "Adaptive long range vision in unstructured terrain",
          "year": 2007,
          "citations": 18,
          "abstract": null,
          "venue": "2007 IEEE/RSJ International Conference on Intelligent Robots and Systems",
          "doi": "10.1109/IROS.2007.4399622",
          "url": "https://www.semanticscholar.org/paper/18966721a3dc227d8632afbaa75d95cbc1708119",
          "authors": [
            "A. Erkan",
            "R. Hadsell",
            "P. Sermanet",
            "J. Ben",
            "Urs Muller",
            "Yann LeCun"
          ]
        },
        {
          "title": "A Unified Energy-Based Framework for Unsupervised Learning",
          "year": 2007,
          "citations": 142,
          "abstract": null,
          "venue": "International Conference on Artificial Intelligence and Statistics",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/306ddd8b7ea3ead125491efc3e8a9f738ce65b89",
          "authors": [
            "Marc'Aurelio Ranzato",
            "Y-Lan Boureau",
            "S. Chopra",
            "Yann LeCun"
          ]
        },
        {
          "title": "A Sparse and Locally Shift Invariant Feature Extractor Applied to Document Images",
          "year": 2007,
          "citations": 27,
          "abstract": null,
          "venue": "IEEE International Conference on Document Analysis and Recognition",
          "doi": "10.1109/ICDAR.2007.35",
          "url": "https://www.semanticscholar.org/paper/3cfff20568fe1964b407e2a4452f6064ca794f3c",
          "authors": [
            "Marc'Aurelio Ranzato",
            "Yann LeCun"
          ]
        },
        {
          "title": "Sparse Feature Learning for Deep Belief Networks",
          "year": 2007,
          "citations": 939,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/41fef1a197fab9684a4608b725d3ae72e1ab4b39",
          "authors": [
            "Marc'Aurelio Ranzato",
            "Y-Lan Boureau",
            "Yann LeCun"
          ]
        },
        {
          "title": "Energy-Based Factor Graphs for Prediction in Relational Data",
          "year": 2007,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/47e5b8dcd44d3d1f595e9e8636ebe2ecdc1de744",
          "authors": [
            "S. Chopra",
            "Yann LeCun"
          ]
        },
        {
          "title": "A multi-range vision strategy for autonomous offroad navigation",
          "year": 2007,
          "citations": 15,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/5fe3deeec85b63e9f10f643389a08e8a0aa8d2a6",
          "authors": [
            "R. Hadsell",
            "A. Erkan",
            "P. Sermanet",
            "J. Ben",
            "K. Kavukcuoglu",
            "Urs Muller",
            "Yann LeCun"
          ]
        },
        {
          "title": "Online Learning for Offroad Robots: Spatial Label Propagation to Learn Long-Range Traversability",
          "year": 2007,
          "citations": 34,
          "abstract": null,
          "venue": "Robotics: Science and Systems",
          "doi": "10.15607/RSS.2007.III.003",
          "url": "https://www.semanticscholar.org/paper/6e06fa79a4a7fbbda36ae4d12cd0d5135b67d28d",
          "authors": [
            "R. Hadsell",
            "P. Sermanet",
            "J. Ben",
            "A. Erkan",
            "Jeff Han",
            "Urs Muller",
            "Yann LeCun"
          ]
        },
        {
          "title": "Scaling learning algorithms towards AI",
          "year": 2007,
          "citations": 1368,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/6fdb77260fc83dff91c44fea0f31a2cb8ed13d04",
          "authors": [
            "Yoshua Bengio",
            "Yann LeCun"
          ]
        },
        {
          "title": "Global Map Long Range Vision ( FAROD ) Cameras Vehicle Map Global planner Route to goal Global Map Goal Local candidates",
          "year": 2007,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/7c305a78154c714372a10ce615accc408c0eb221",
          "authors": [
            "R. Hadsell",
            "A. Erkan",
            "P. Sermanet",
            "J. Ben",
            "K. Kavukcuoglu",
            "Urs Muller",
            "Yann LeCun"
          ]
        },
        {
          "title": "Automatic recognition of biological particles in microscopic images",
          "year": 2007,
          "citations": 118,
          "abstract": null,
          "venue": "Pattern Recognition Letters",
          "doi": "10.1016/j.patrec.2006.06.010",
          "url": "https://www.semanticscholar.org/paper/9228aece7615fbc33394a3124aef27f9a85853c3",
          "authors": [
            "Marc'Aurelio Ranzato",
            "P. E. Taylor",
            "J. House",
            "R. Flagan",
            "Yann LeCun",
            "P. Perona"
          ]
        },
        {
          "title": "Discovering the hidden structure of house prices with a non-parametric latent manifold model",
          "year": 2007,
          "citations": 28,
          "abstract": null,
          "venue": "Knowledge Discovery and Data Mining",
          "doi": "10.1145/1281192.1281214",
          "url": "https://www.semanticscholar.org/paper/9f4028fea3fcc99776391d66d4e40edbe78388b3",
          "authors": [
            "S. Chopra",
            "Trivikraman Thampy",
            "John Leahy",
            "Andrew Caplin",
            "Yann LeCun"
          ]
        },
        {
          "title": "The Need for Open Source Software in Machine Learning",
          "year": 2007,
          "citations": 235,
          "abstract": null,
          "venue": "Journal of machine learning research",
          "doi": "10.5555/1314498.1314577",
          "url": "https://www.semanticscholar.org/paper/ab08f2a0b98fe7938d08875eb6125fa518620222",
          "authors": [
            "S. Sonnenburg",
            "M. Braun",
            "Cheng Soon Ong",
            "Samy Bengio",
            "L. Bottou",
            "G. Holmes",
            "Yann LeCun",
            "K. Müller",
            "Fernando C Pereira",
            "C. Rasmussen",
            "Gunnar Rätsch",
            "B. Scholkopf",
            "Alex Smola",
            "Pascal Vincent",
            "J. Weston",
            "R. C. Williamson"
          ]
        },
        {
          "title": "Energy-Based Models in Document Recognition and Computer Vision",
          "year": 2007,
          "citations": 60,
          "abstract": null,
          "venue": "IEEE International Conference on Document Analysis and Recognition",
          "doi": "10.1109/ICDAR.2007.107",
          "url": "https://www.semanticscholar.org/paper/c09c49d92d10a84e6efdbaf67d979bab2c22be3e",
          "authors": [
            "Yann LeCun",
            "S. Chopra",
            "Marc'Aurelio Ranzato",
            "Fu Jie Huang"
          ]
        },
        {
          "title": "Unsupervised Learning of Invariant Feature Hierarchies with Applications to Object Recognition",
          "year": 2007,
          "citations": 1190,
          "abstract": null,
          "venue": "2007 IEEE Conference on Computer Vision and Pattern Recognition",
          "doi": "10.1109/CVPR.2007.383157",
          "url": "https://www.semanticscholar.org/paper/ccd52aff02b0f902f4ce7247c4fee7273014c41c",
          "authors": [
            "Marc'Aurelio Ranzato",
            "Fu Jie Huang",
            "Y-Lan Boureau",
            "Yann LeCun"
          ]
        },
        {
          "title": "Learning Sparse and Invariant Features Hierarchies",
          "year": 2007,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/dad2f8fd3e155c86b089b5b054a1e0c5b8f79915",
          "authors": [
            "Fu Jie Huang",
            "Yann LeCun"
          ]
        },
        {
          "title": "Message from the Program and General Chairs",
          "year": 2006,
          "citations": 0,
          "abstract": null,
          "venue": "Computer Vision and Pattern Recognition",
          "doi": "10.1109/CVPR.2006.184",
          "url": "https://www.semanticscholar.org/paper/1d0e3de0d4716f99008e6251261d1c7d8feb6f9a",
          "authors": [
            "A. Fitzgibbon",
            "C. J. Taylor",
            "Yann LeCun",
            "D. Huttenlocher",
            "David Forsyth"
          ]
        },
        {
          "title": "Dimensionality Reduction by Learning an Invariant Mapping",
          "year": 2006,
          "citations": 5511,
          "abstract": null,
          "venue": "Computer Vision and Pattern Recognition",
          "doi": "10.1109/CVPR.2006.100",
          "url": "https://www.semanticscholar.org/paper/46f30e94dd3d5902141c5fbe58d0bc9189545c76",
          "authors": [
            "R. Hadsell",
            "S. Chopra",
            "Yann LeCun"
          ]
        },
        {
          "title": "On-Line Learning of Long-Range Obstacle Detection for Off-Road Robots",
          "year": 2006,
          "citations": 2,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/7959e1cb872a7dd284bf082f8cf16fc2c00da750",
          "authors": [
            "R. Hadsell",
            "P. Sermanet",
            "J. Ben",
            "Jeff Han",
            "S. Chopra",
            "Marc'Aurelio Ranzato",
            "Yury Sulsky",
            "B. Flepp",
            "Urs Muller",
            "Yann LeCun"
          ]
        },
        {
          "title": "A Tutorial on Energy-Based Learning",
          "year": 2006,
          "citations": 1642,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/7fc604e1a3e45cd2d2742f96d62741930a363efa",
          "authors": [
            "Yann LeCun",
            "S. Chopra",
            "R. Hadsell",
            "Aurelio Ranzato",
            "Fu Jie Huang"
          ]
        },
        {
          "title": "E cient Learning of Sparse Overcomplete Representations with an Energy-Based Model",
          "year": 2006,
          "citations": 13,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/8680319b8619e71bb5bd75103d2b7f1d08f48491",
          "authors": [
            "Marc'Aurelio Ranzato",
            "Christopher S. Poultney",
            "S. Chopra",
            "Yann LeCun"
          ]
        },
        {
          "title": "Efficient Learning of Sparse Representations with an Energy-Based Model",
          "year": 2006,
          "citations": 1342,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": "10.7551/mitpress/7503.003.0147",
          "url": "https://www.semanticscholar.org/paper/932c2a02d462abd75af018125413b1ceaa1ee3f4",
          "authors": [
            "Marc'Aurelio Ranzato",
            "Christopher S. Poultney",
            "S. Chopra",
            "Yann LeCun"
          ]
        },
        {
          "title": "PROC OF THE IEEE NOVEMBER Gradient Based Learning Applied to Document Recognition",
          "year": 2006,
          "citations": 22,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/afc0a5d20dd7160f42fc5c27ef9746b14ebe53f4",
          "authors": [
            "Yann LeCun",
            "L. Bottou",
            "Yoshua Bengio"
          ]
        },
        {
          "title": "Proceedings : 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition : CVPR 2006 : June 17-22, 2006, New York, NY",
          "year": 2006,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/baf9530d8ab59e42fef6b35b51b27261e1854183",
          "authors": [
            "A. Fitzgibbon",
            "C. J. Taylor",
            "Yann LeCun"
          ]
        },
        {
          "title": "Large-scale Learning with SVM and Convolutional for Generic Object Categorization",
          "year": 2006,
          "citations": 383,
          "abstract": null,
          "venue": "Computer Vision and Pattern Recognition",
          "doi": "10.1109/CVPR.2006.164",
          "url": "https://www.semanticscholar.org/paper/cf03fdf52dd6e4249cbbdbd0bffbbbe5ca389feb",
          "authors": [
            "Fu Jie Huang",
            "Yann LeCun"
          ]
        },
        {
          "title": "Building an Automatic Phenotyping System of Developing Embryos",
          "year": 2006,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/eafc996e3a178e93bd7efe926edbcb4129dbb0fe",
          "authors": [
            "Yann LeCun",
            "F. Ning"
          ]
        },
        {
          "title": "Toward automatic phenotyping of developing embryos from videos",
          "year": 2005,
          "citations": 290,
          "abstract": null,
          "venue": "IEEE Transactions on Image Processing",
          "doi": "10.1109/TIP.2005.852470",
          "url": "https://www.semanticscholar.org/paper/c029513aef54460ef6a468ff83f549d7ffbb646b",
          "authors": [
            "F. Ning",
            "D. Delhomme",
            "Yann LeCun",
            "F. Piano",
            "L. Bottou",
            "P. Barbano"
          ]
        },
        {
          "title": "Off-Road Obstacle Avoidance through End-to-End Learning",
          "year": 2005,
          "citations": 609,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/c63d2e3b11d25971cc50cde869f59d34c62a1291",
          "authors": [
            "Yann LeCun",
            "Urs Muller",
            "J. Ben",
            "E. Cosatto",
            "B. Flepp"
          ]
        },
        {
          "title": "Learning a similarity metric discriminatively, with application to face verification",
          "year": 2005,
          "citations": 4428,
          "abstract": null,
          "venue": "Computer Vision and Pattern Recognition",
          "doi": "10.1109/CVPR.2005.202",
          "url": "https://www.semanticscholar.org/paper/cfaae9b6857b834043606df3342d8dc97524aa9d",
          "authors": [
            "S. Chopra",
            "R. Hadsell",
            "Yann LeCun"
          ]
        },
        {
          "title": "The mnist database of handwritten digits",
          "year": 2005,
          "citations": 7094,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/dc52d1ede1b90bf9d296bc5b34c9310b7eaa99a2",
          "authors": [
            "Yann LeCun",
            "Corinna Cortes"
          ]
        },
        {
          "title": "Graph transformer networks for image recognition",
          "year": 2005,
          "citations": 14,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/f78017ab52a9e10d206da41363ec0c11a10e4757",
          "authors": [
            "L. Bottou",
            "Yann LeCun"
          ]
        },
        {
          "title": "Loss Functions for Discriminative Training of Energy-Based Models",
          "year": 2005,
          "citations": 160,
          "abstract": null,
          "venue": "International Conference on Artificial Intelligence and Statistics",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/fae82787fc4268f579823696bf8f54b22e253711",
          "authors": [
            "Yann LeCun",
            "Fu Jie Huang"
          ]
        },
        {
          "title": "Synergistic Face Detection and Pose Estimation with Energy-Based Models",
          "year": 2004,
          "citations": 430,
          "abstract": null,
          "venue": "Journal of machine learning research",
          "doi": "10.5555/1314498.1314539",
          "url": "https://www.semanticscholar.org/paper/6b728a7442ca158f895d07c11c77d302269a832d",
          "authors": [
            "Margarita Osadchy",
            "Yann LeCun",
            "Matthew L. Miller"
          ]
        },
        {
          "title": "Learning methods for generic object recognition with invariance to pose and lighting",
          "year": 2004,
          "citations": 1565,
          "abstract": null,
          "venue": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.",
          "doi": "10.1109/CVPR.2004.144",
          "url": "https://www.semanticscholar.org/paper/f354310098e09c1e1dc88758fca36767fd9d084d",
          "authors": [
            "Yann LeCun",
            "Fu Jie Huang",
            "L. Bottou"
          ]
        },
        {
          "title": "Large Scale Online Learning",
          "year": 2003,
          "citations": 452,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/133809cf62bf67f0a63b35e5ef5180d20c9aec19",
          "authors": [
            "L. Bottou",
            "Yann LeCun"
          ]
        },
        {
          "title": "Real Time Voice Processing with Audiovisual Feedback: Toward Autonomous Agents with Perfect Pitch",
          "year": 2002,
          "citations": 28,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/6986517700641f245e908e64c2acf6dd5f333b95",
          "authors": [
            "L. Saul",
            "Daniel D. Lee",
            "C. Isbell",
            "Yann LeCun"
          ]
        },
        {
          "title": "A general segmentation scheme for DjVu document compression",
          "year": 2002,
          "citations": 21,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/c4afb604c6e00c9fcc358daae260eeedb84be863",
          "authors": [
            "P. Haffner",
            "L. Bottou",
            "Yann LeCun",
            "L. Vincent"
          ]
        },
        {
          "title": "Image and video coding—emerging standards and beyond",
          "year": 2001,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": "10.1016/B978-155860651-7/50094-2",
          "url": "https://www.semanticscholar.org/paper/24232511c7cb88468b5e69f7638e1c722315f616",
          "authors": [
            "B. Haskell",
            "P. Howard",
            "Yann LeCun",
            "Atul Puri",
            "J. Ostermann",
            "M. Civanlar",
            "L. Rabiner",
            "L. Bottou",
            "P. Haffner"
          ]
        },
        {
          "title": "Advances in neural information processing systems: Proceedings of the first 12 conferences (CDROM)",
          "year": 2001,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/6822d4f630b7e7de2582e77b577b6f037e32ee5c",
          "authors": [
            "M. I. Jordan",
            "Yann LeCun",
            "S. Solla"
          ]
        },
        {
          "title": "Efficient conversion of digital documents to multilayer raster formats",
          "year": 2001,
          "citations": 10,
          "abstract": null,
          "venue": "Proceedings of Sixth International Conference on Document Analysis and Recognition",
          "doi": "10.1109/ICDAR.2001.953829",
          "url": "https://www.semanticscholar.org/paper/bc95fe16a7a9f29b13ea242cdc69ec3b977f245d",
          "authors": [
            "L. Bottou",
            "P. Haffner",
            "Yann LeCun"
          ]
        },
        {
          "title": "Djvu: Un systeme de compression d'images pour la distribution reticulaire de documents numerises (Djvu: An image compression system for distributing scanned document on the internet)",
          "year": 2000,
          "citations": 2,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/6519eb56306e2c848d883a4f47919dd9fdcab755",
          "authors": [
            "L. Bottou",
            "P. Haffner",
            "Yann LeCun",
            "P. Howard",
            "Pascal Vincent",
            "B. Riemers"
          ]
        },
        {
          "title": "Transformation invariance in pattern recognition: Tangent distance and propagation",
          "year": 2000,
          "citations": 160,
          "abstract": null,
          "venue": "International journal of imaging systems and technology (Print)",
          "doi": "10.1002/1098-1098(2000)11:3%3C181::AID-IMA1003%3E3.0.CO;2-E",
          "url": "https://www.semanticscholar.org/paper/76c67b335b8192b61a0e9364827afcc2f0842d11",
          "authors": [
            "Patrice Y. Simard",
            "Yann LeCun",
            "J. Denker",
            "B. Victorri"
          ]
        },
        {
          "title": "DjVu: analyzing and compressing scanned documents for Internet distribution",
          "year": 1999,
          "citations": 53,
          "abstract": null,
          "venue": "Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318)",
          "doi": "10.1109/ICDAR.1999.791865",
          "url": "https://www.semanticscholar.org/paper/3089d4a41a3310a62bc2effd4a69577f79014f8f",
          "authors": [
            "P. Haffner",
            "L. Bottou",
            "P. Howard",
            "Yann LeCun"
          ]
        },
        {
          "title": "Multimedia Processing for Advanced Communications Services",
          "year": 1999,
          "citations": 2,
          "abstract": null,
          "venue": "",
          "doi": "10.1007/978-1-4471-0859-7_42",
          "url": "https://www.semanticscholar.org/paper/3fb58e78700febc4a03ebd8eccea794218bd7149",
          "authors": [
            "B. Shahraray",
            "R. Cox",
            "B. Haskell",
            "Yann LeCun",
            "L. Rabiner"
          ]
        },
        {
          "title": "Object Recognition with Gradient-Based Learning",
          "year": 1999,
          "citations": 1027,
          "abstract": null,
          "venue": "Shape, Contour and Grouping in Computer Vision",
          "doi": "10.1007/3-540-46805-6_19",
          "url": "https://www.semanticscholar.org/paper/9a5ea367f0fb05805acaa84a402f5d036eea37dc",
          "authors": [
            "Yann LeCun",
            "P. Haffner",
            "L. Bottou",
            "Yoshua Bengio"
          ]
        },
        {
          "title": "Color documents on the Web with DjVu",
          "year": 1999,
          "citations": 13,
          "abstract": null,
          "venue": "Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348)",
          "doi": "10.1109/ICIP.1999.821605",
          "url": "https://www.semanticscholar.org/paper/dec714928a06610355e4d44c9468d2be0af2f47c",
          "authors": [
            "P. Haffner",
            "Yann LeCun",
            "L. Bottou",
            "P. Howard",
            "Pascal Vincent",
            "B. Riemers"
          ]
        },
        {
          "title": "OPTICAL CHARACTER RECOGNTION FOR AUTOMATIC TELLER MACHINES",
          "year": 1998,
          "citations": 3,
          "abstract": null,
          "venue": "",
          "doi": "10.1142/9789812816955_0044",
          "url": "https://www.semanticscholar.org/paper/0f64a60e61a466487f0db5046b2b454756ecb32f",
          "authors": [
            "L. Jackel",
            "Yann LeCun",
            "C. E. Stenard",
            "B. I. Strom",
            "D. Sharman",
            "D. Zuckert"
          ]
        },
        {
          "title": "Gradient-based learning applied to document recognition",
          "year": 1998,
          "citations": 57256,
          "abstract": null,
          "venue": "Proceedings of the IEEE",
          "doi": "10.1109/5.726791",
          "url": "https://www.semanticscholar.org/paper/162d958ff885f1462aeda91cd72582323fd6a1f4",
          "authors": [
            "Yann LeCun",
            "L. Bottou",
            "Yoshua Bengio",
            "P. Haffner"
          ]
        },
        {
          "title": "Unsupervised Learning of Sparse and Invariant Features Hierarchies",
          "year": 1998,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/3011a4d3c3dd2d303a71949db348dd1d999c9db2",
          "authors": [
            "Y-Lan Boureau",
            "Fu Jie Huang",
            "Yann LeCun"
          ]
        },
        {
          "title": "High quality document image compression with \"DjVu\"",
          "year": 1998,
          "citations": 276,
          "abstract": null,
          "venue": "J. Electronic Imaging",
          "doi": "10.1117/1.482609",
          "url": "https://www.semanticscholar.org/paper/34103850fbd71d43b19f8335f378f421ab9a1aa8",
          "authors": [
            "L. Bottou",
            "P. Haffner",
            "P. Howard",
            "Patrice Y. Simard",
            "Yoshua Bengio",
            "Yann LeCun"
          ]
        },
        {
          "title": "DjVu: a Compression Method for Distributing Scanned Documents in Color over the Internet",
          "year": 1998,
          "citations": 9,
          "abstract": "We present a new image compression technique called “DjVu” that is specifically geared towards the compression of scanned documents in color at high revolution. DjVu enable any screen connected to the Internet to access and display images of scanned pages while faithfully reproducing the font, color, drawings, pictures, and paper texture. With DjVu, a typical magazine page in color at 300dpi can be compressed down to between 40 to 60 KB, approximately 5 to 10 times better than JPEG for a similar level of subjective quality. A real-time, memory efficient version of the decoder is available as a plug-in for popular web browsers.",
          "venue": "International Conference on Communications in Computing",
          "doi": "10.2352/CIC.1998.6.1.art00047",
          "url": "https://www.semanticscholar.org/paper/4737e136dbf34e37b8c2ee3c615e3e808d5d63fc",
          "authors": [
            "Yann LeCun",
            "L. Bottou",
            "P. Haffner",
            "P. Howard"
          ]
        },
        {
          "title": "Convolutional networks for images, speech, and time series",
          "year": 1998,
          "citations": 5983,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/563e821bb5ea825efb56b77484f5287f08cf3753",
          "authors": [
            "Yann LeCun",
            "Yoshua Bengio"
          ]
        },
        {
          "title": "Browsing through high quality document images with DjVu",
          "year": 1998,
          "citations": 18,
          "abstract": null,
          "venue": "Proceedings IEEE International Forum on Research and Technology Advances in Digital Libraries -ADL'98-",
          "doi": "10.1109/ADL.1998.670431",
          "url": "https://www.semanticscholar.org/paper/714c5e9f832b12e4029bc8516b3d9fe11ae0553e",
          "authors": [
            "P. Haffner",
            "L. Bottou",
            "P. Howard",
            "Patrice Y. Simard",
            "Yoshua Bengio",
            "Yann LeCun"
          ]
        },
        {
          "title": "[Learning with computers].",
          "year": 1998,
          "citations": 48,
          "abstract": null,
          "venue": "Schweizer Monatsschrift fur Zahnmedizin = Revue mensuelle suisse d'odonto-stomatologie = Rivista mensile svizzera di odontologia e stomatologia",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/784cb31fc9fe06cfda34368b59258b0e5a7201e9",
          "authors": [
            "Cecilia Ka Yuk Chan",
            "Zoya A. Zorina",
            "Jesse R. Sparks",
            "S. López Ornat",
            "Christine D. Tsang",
            "Elena L. Grigorenko",
            "R. Lubow",
            "John C. Malone",
            "Michael Domjan",
            "Charles Yang",
            "Michelyn C. Butler",
            "M. Gettinger",
            "Thomas R. Minor",
            "Traci N. Plumb",
            "Hendrik Drachsler",
            "P. A. Kirschner",
            "Minoru Nakayama",
            "Rowena Santiago",
            "Ali Simsek",
            "Fang-Ying Yang",
            "Yi-Chun Chen",
            "G. Brooke",
            "Heidi L. Andrade",
            "Richard P. Cooper",
            "A. Podolskiy",
            "David W. Versailles",
            "Valérie Mérindol",
            "E. Guerci",
            "Nobuyuki Hanaki",
            "D. Grollman",
            "A. Billard",
            "Luis C. Lamb",
            "Artur d’Avila Garcez",
            "D. Németh",
            "K. Janacsek",
            "John A. Nunnery",
            "L. Byrd-Poller",
            "M. Haan",
            "Rodrigo Harrison",
            "Mauricio G. Villena",
            "L. Izquierdo",
            "Segismundo S. Izquierdo",
            "F. Vega-Redondo",
            "Tracy Packiam Alloway",
            "Ulrike Halsband",
            "N. Seel",
            "G. Bedny",
            "Hansjörg von Brevern",
            "K. Synytsya",
            "Gabriele Kern-Isberner",
            "Joost Breuker",
            "S. Cerri",
            "T. Zittoun",
            "S. Brinkmann",
            "Negin Dahya",
            "S. B. Fountain",
            "Karen E. Doyle",
            "K. Sarfo",
            "Bertram C. Bruce",
            "N. Bloch",
            "C.-J. Olsson",
            "Lars Nyberg",
            "R. Freivalds",
            "Lynne Hall",
            "M. Hall",
            "Ulrike Hanke",
            "Lin S. Norton",
            "Aytac Gogus",
            "K. Illeris",
            "M. Macy",
            "A. Flache",
            "A. Robins",
            "L. Thorogood",
            "M. Udell",
            "C. Wynne",
            "Paul C. Burnett",
            "M. Cannon",
            "Amy C. Edmondson",
            "Pitoyo Hartono",
            "A. Callender",
            "Rachel Barr",
            "Natalie Brito",
            "Noorizah Mohd. Noor",
            "Tg. Nor Rizan Tg. Mohd. Maasum",
            "K. Cennamo",
            "Marc'Aurelio Ranzato",
            "Y-Lan Boureau",
            "K. Kavukcuoglu",
            "Karol Gregor",
            "Yann LeCun",
            "M. Alias",
            "Caifeng Shan",
            "Alice Y. Kolb",
            "David A. Kolb",
            "R. Reilly",
            "Klaus Nielsen",
            "Patricia Couvillon",
            "Heather King",
            "Justin Dillon",
            "Delia Neuman",
            "J. E. Purdy",
            "Linda Kragelund",
            "Fernand Gobet",
            "Peter C. R. Lane",
            "Som Naidu",
            "Danny R. Bedgood",
            "Dirk Ifenthaler",
            "Ida Moadab",
            "Don M. Tucker",
            "Paul J. Hager",
            "J. Fejes",
            "Danielle C. Colas-Zelin",
            "L. Matzel",
            "P. Perruchet",
            "B. Poulin-Charronnat",
            "S. Pacton",
            "C. Linnman",
            "Mohamed A Zeidan",
            "M. Milad",
            "I. Holloway",
            "Daniel Ansari",
            "K. Lionello-DeNolf",
            "John Burgoyne",
            "Judy Huang",
            "Roger K. Thomas",
            "S. Pietropaolo",
            "Wim E. Crusio",
            "Sabine Richter",
            "J. Elen",
            "G. Clarebout",
            "E. Bliss-Moreau",
            "Jonte Bernhard",
            "Marcia L. Conner",
            "Lanita Jacobs",
            "Mariel Miller",
            "A. Hadwin",
            "M. Coen",
            "Carlo Magno",
            "Eli Hinkel",
            "S. Szedmák",
            "F. Balagué",
            "M. Milrad",
            "H. U. Hoppe",
            "Krisztina Molnar",
            "Erica de Vries",
            "Emmanuel G. Blanchard",
            "C. Frasson",
            "Susanne P. Lajoie",
            "Tristan Cazenave",
            "Ton Jong",
            "Jan Meij",
            "J. Gavelek",
            "Ailing Kong",
            "A. Daffertshofer",
            "J. Alonso-Tapia",
            "S. Billett",
            "D. Rumbaugh",
            "Michael J. Beran",
            "Imran Ho-Abdullah",
            "Norsimah Mat Awal",
            "Dong-oh Seo",
            "M. Monfils",
            "Anthony A. Wright",
            "D. Deshler",
            "Frances M. Ihle",
            "Carrie Mark",
            "Daniel T. Pollitt",
            "Michael J. Kennedy",
            "Michael Jackson",
            "Terezinha Nunes",
            "B. Jackling",
            "R. Howard",
            "William G. Kennedy",
            "L. C. Drickamer"
          ]
        },
        {
          "title": "On the applications of multimedia processing to communications",
          "year": 1998,
          "citations": 58,
          "abstract": null,
          "venue": "Proceedings of the IEEE",
          "doi": "10.1109/5.664272",
          "url": "https://www.semanticscholar.org/paper/82cf2c37ed3eca25660ead9c034ecadcfb76fb4a",
          "authors": [
            "R. Cox",
            "B. Haskell",
            "Yann LeCun",
            "B. Shahraray",
            "L. Rabiner"
          ]
        },
        {
          "title": "Applications of Artificial Neural Networks to Image Processing",
          "year": 1998,
          "citations": 15,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/9c40fe0b583565d01f5d4032d574a020866bb817",
          "authors": [
            "R. Chellappa",
            "K. Fukushima",
            "A. Katsaggelos",
            "S. Kung",
            "Yann LeCun",
            "N. Nasrabadi",
            "T. Poggio"
          ]
        },
        {
          "title": "Boxlets: A Fast Convolution Algorithm for Signal Processing and Neural Networks",
          "year": 1998,
          "citations": 156,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/b2ef3d741a8d267b813781a73d4222b6dbba99fa",
          "authors": [
            "Patrice Y. Simard",
            "L. Bottou",
            "P. Haffner",
            "Yann LeCun"
          ]
        },
        {
          "title": "Image and video coding-emerging standards and beyond",
          "year": 1998,
          "citations": 90,
          "abstract": null,
          "venue": "IEEE Trans. Circuits Syst. Video Technol.",
          "doi": "10.1109/76.735379",
          "url": "https://www.semanticscholar.org/paper/bb52c49e2a82cfc33491c7bdf61faea0e8251a9e",
          "authors": [
            "B. Haskell",
            "P. Howard",
            "Yann LeCun",
            "Atul Puri",
            "J. Ostermann",
            "M. Civanlar",
            "L. Rabiner",
            "L. Bottou",
            "P. Haffner"
          ]
        },
        {
          "title": "On the application of multimedia processing to telecommunications",
          "year": 1997,
          "citations": 9,
          "abstract": null,
          "venue": "Proceedings of International Conference on Image Processing",
          "doi": "10.1109/ICIP.1997.647370",
          "url": "https://www.semanticscholar.org/paper/04b5268727c322dcd9d10a14decb5d8c03a4f378",
          "authors": [
            "R. Cox",
            "B. Haskell",
            "Yann LeCun",
            "B. Shahraray",
            "L. Rabiner"
          ]
        },
        {
          "title": "Reading checks with multilayer graph transformer networks",
          "year": 1997,
          "citations": 57,
          "abstract": null,
          "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
          "doi": "10.1109/ICASSP.1997.599580",
          "url": "https://www.semanticscholar.org/paper/25de919ccc51093737e2d61cea3037ee6bd3775f",
          "authors": [
            "Yann LeCun",
            "L. Bottou",
            "Yoshua Bengio"
          ]
        },
        {
          "title": "Discriminative feature and model design for automatic speech recognition",
          "year": 1997,
          "citations": 19,
          "abstract": "AUTOMATIC SPEECH RECOGNITION Mazin Rahim, Yoshua Bengio and Yann LeCun AT&T Labs Research, 600 Mountain Avenue, Murray Hill, New Jersey 07974, USA ABSTRACT A system for discriminative feature and model design is presented for automatic speech recognition. Training based on minimum classi cation error with a single objective function is applied for designing a set of parallel networks performing feature transformation and a set of hidden Markov models performing speech recognition. This paper compares the use of linear and non-linear functional transformations when applied to conventional recognition features, such as spectrum or cepstrum. It also provides a framework for integrated feature and model training when using class-speci c transformations. Experimental results on telephone-based connected digit recognition are presented.",
          "venue": "EUROSPEECH",
          "doi": "10.21437/Eurospeech.1997-46",
          "url": "https://www.semanticscholar.org/paper/2a5c494c9ac68c8915d9df880a3bf6fe48a696a8",
          "authors": [
            "M. Rahim",
            "Yoshua Bengio",
            "Yann LeCun"
          ]
        },
        {
          "title": "Global training of document processing systems using graph transformer networks",
          "year": 1997,
          "citations": 122,
          "abstract": null,
          "venue": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
          "doi": "10.1109/CVPR.1997.609370",
          "url": "https://www.semanticscholar.org/paper/4f0ab1dcdc9f405ca90e36a35ea335196464d387",
          "authors": [
            "L. Bottou",
            "Yoshua Bengio",
            "Yann LeCun"
          ]
        },
        {
          "title": "Neural Networks and Gradient-Based Learning in OCR",
          "year": 1997,
          "citations": 4,
          "abstract": null,
          "venue": "Neural Networks for Signal Processing VII. Proceedings of the 1997 IEEE Signal Processing Society Workshop",
          "doi": "10.1109/NNSP.1997.622405",
          "url": "https://www.semanticscholar.org/paper/6c3d93bc3e3555319443a1311b6aabbcf3ffd167",
          "authors": [
            "Yann LeCun"
          ]
        },
        {
          "title": "Transformation Invariance in Pattern Recognition-Tangent Distance and Tangent Propagation",
          "year": 1996,
          "citations": 578,
          "abstract": null,
          "venue": "Neural Networks",
          "doi": "10.1007/3-540-49430-8_13",
          "url": "https://www.semanticscholar.org/paper/153f64ab7c1c24b1b136d8da2f36c6333b8dbfdd",
          "authors": [
            "Patrice Y. Simard",
            "Yann LeCun",
            "J. Denker",
            "B. Victorri"
          ]
        },
        {
          "title": "Effiicient BackProp",
          "year": 1996,
          "citations": 214,
          "abstract": null,
          "venue": "Neural Networks",
          "doi": "10.1007/3-540-49430-8_2",
          "url": "https://www.semanticscholar.org/paper/deede4f010369a810eb1017fd9e757d9876a44c8",
          "authors": [
            "Yann LeCun",
            "L. Bottou",
            "Genevieve B. Orr",
            "K. Müller"
          ]
        },
        {
          "title": "LeRec: A NN/HMM Hybrid for On-Line Handwriting Recognition",
          "year": 1995,
          "citations": 166,
          "abstract": null,
          "venue": "Neural Computation",
          "doi": "10.1162/neco.1995.7.6.1289",
          "url": "https://www.semanticscholar.org/paper/4a4192fd6efb5661eca197cce24289776a4fbcc2",
          "authors": [
            "Yoshua Bengio",
            "Yann LeCun",
            "C. Nohl",
            "C. Burges"
          ]
        },
        {
          "title": "Learning algorithms for classification: A comparison on handwritten digit recognition",
          "year": 1995,
          "citations": 568,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/842dd6d0f4b72ce0e8f3ac8e6861637c1f4645ea",
          "authors": [
            "Yann LeCun",
            "L. Jackel",
            "L. Bottou",
            "Corinna Cortes",
            "J. Denker",
            "H. Drucker",
            "Isabelle M Guyon",
            "Urs Muller",
            "E. Sackinger",
            "Patrice Y. Simard",
            "V. Vapnik"
          ]
        },
        {
          "title": "Pattern Recognition and Neural Networks",
          "year": 1995,
          "citations": 4580,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/bf7e1b6997433dcb2121b07cce1de1c61471ff2d",
          "authors": [
            "Yann LeCun",
            "Yoshua Bengio"
          ]
        },
        {
          "title": "Comparison of learning algorithms for handwritten digit recognition",
          "year": 1995,
          "citations": 726,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/d50dce749321301f0104689f2dc582303a83be65",
          "authors": [
            "Yann LeCun",
            "L. Jackel",
            "L. Bottou",
            "A. Brunot",
            "Corinna Cortes",
            "J. Denker",
            "H. Drucker",
            "Isabelle M Guyon",
            "Urs Muller",
            "E. Sackinger",
            "Patrice Y. Simard",
            "V. Vapnik"
          ]
        },
        {
          "title": "Word normalization for on-line handwritten word recognition",
          "year": 1994,
          "citations": 38,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/4b336597d72bef3b5b6964a88040129edcaf8dcd",
          "authors": [
            "Yoshua Bengio",
            "Yann LeCun"
          ]
        },
        {
          "title": "Comparison of classifier methods: a case study in handwritten digit recognition",
          "year": 1994,
          "citations": 665,
          "abstract": "This paper compares the performance of several classifier algorithms on a standard database of handwritten digits. We consider not only raw accuracy, but also training time, recognition time, and memory requirements. When available, we report measurements of the fraction of patterns that must be rejected so that the remaining patterns have misclassification rates less than a given threshold.",
          "venue": "Signal Processing",
          "doi": "10.1109/ICPR.1994.576879",
          "url": "https://www.semanticscholar.org/paper/55f58ee028e8d86ddf80f68b7538bfb5d6005dc8",
          "authors": [
            "L. Bottou",
            "Corinna Cortes",
            "J. Denker",
            "H. Drucker",
            "Isabelle M Guyon",
            "L. Jackel",
            "Yann LeCun",
            "U. A. Müller",
            "Eduard Säckinger",
            "Patrice Y. Simard",
            "V. Vapnik"
          ]
        },
        {
          "title": "Boosting and Other Ensemble Methods",
          "year": 1994,
          "citations": 406,
          "abstract": "We compare the performance of three types of neural network-based ensemble techniques to that of a single neural network. The ensemble algorithms are two versions of boosting and committees of neural networks trained independently. For each of the four algorithms, we experimentally determine the test and training error curves in an optical character recognition (OCR) problem as both a function of training set size and computational cost using three architectures. We show that a single machine is best for small training set size while for large training set size some version of boosting is best. However, for a given computational cost, boosting is always best. Furthermore, we show a surprising result for the original boosting algorithm: namely, that as the training set size increases, the training error decreases until it asymptotes to the test error rate. This has potential implications in the search for better training algorithms.",
          "venue": "Neural Computation",
          "doi": "10.1162/neco.1994.6.6.1289",
          "url": "https://www.semanticscholar.org/paper/6db07f39446bdf74d0178a75f526baffee1a0369",
          "authors": [
            "H. Drucker",
            "Corinna Cortes",
            "L. Jackel",
            "Yann LeCun",
            "V. Vapnik"
          ]
        },
        {
          "title": "Measuring the VC-Dimension of a Learning Machine",
          "year": 1994,
          "citations": 434,
          "abstract": null,
          "venue": "Neural Computation",
          "doi": "10.1162/neco.1994.6.5.851",
          "url": "https://www.semanticscholar.org/paper/899defb6a100af509547b8d74bb626533ee87da4",
          "authors": [
            "V. Vapnik",
            "E. Levin",
            "Yann LeCun"
          ]
        },
        {
          "title": "Predicting transportpath degradation/failure based on recent performance history",
          "year": 1994,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/96fe89e4f006c85ea3fc743dc507113715128826",
          "authors": [
            "Wan-Ping Chiang",
            "Corinna Cortes",
            "L. Jackel",
            "Yann LeCun",
            "W. Lee",
            "E. Pednault",
            "V. Vapnik"
          ]
        },
        {
          "title": "Boosting and Other Machine Learning Algorithms",
          "year": 1994,
          "citations": 41,
          "abstract": null,
          "venue": "International Conference on Machine Learning",
          "doi": "10.1016/b978-1-55860-335-6.50015-5",
          "url": "https://www.semanticscholar.org/paper/b560bb5b24cd89a68ce20bd30d4c0f22ccae7d82",
          "authors": [
            "H. Drucker",
            "Corinna Cortes",
            "L. Jackel",
            "Yann LeCun",
            "V. Vapnik"
          ]
        },
        {
          "title": "Memory-based character recognition using a transformation invariant metric",
          "year": 1994,
          "citations": 28,
          "abstract": null,
          "venue": "Signal Processing",
          "doi": "10.1109/ICPR.1994.576916",
          "url": "https://www.semanticscholar.org/paper/be09fa4b8fbf399d1f2ce2263556d90f0661fe1f",
          "authors": [
            "Patrice Y. Simard",
            "Yann LeCun",
            "J. Denker"
          ]
        },
        {
          "title": "Word-level training of a handwritten word recognizer based on convolutional neural networks",
          "year": 1994,
          "citations": 77,
          "abstract": null,
          "venue": "Signal Processing",
          "doi": "10.1109/ICPR.1994.576881",
          "url": "https://www.semanticscholar.org/paper/ec8c344bb9d1e4b966f499a9b236c3e320d46362",
          "authors": [
            "Yann LeCun",
            "Yoshua Bengio"
          ]
        },
        {
          "title": "Word normalization for online handwritten word recognition",
          "year": 1994,
          "citations": 22,
          "abstract": "We introduce a new approach to normalizing words written with an electronic stylus that applies to all styles of handwriting (upper case, lower case, printed, cursive, or mixed). A geometrical model of the word spatial structure is fitted to the pen trajectory using the expectation-maximisation algorithm. The fitting process maximizes the likelihood of the trajectory given the model and a set a priors on its parameters. The method was evaluated and integrated to a recognition system that combines neural networks and hidden Markov models.",
          "venue": "Signal Processing",
          "doi": "10.1109/ICPR.1994.576966",
          "url": "https://www.semanticscholar.org/paper/f3c5f1e1edd0d63f2d1b30d308c2c88b06a829ef",
          "authors": [
            "Yoshua Bengio",
            "Yann LeCun"
          ]
        },
        {
          "title": "Neural Network Applications in Character Recognition and Document Analysis",
          "year": 1994,
          "citations": 11,
          "abstract": null,
          "venue": "",
          "doi": "10.1007/978-1-4615-2734-3_14",
          "url": "https://www.semanticscholar.org/paper/f633dc06f89ab060607202ad96daa85d268055c7",
          "authors": [
            "L. Jackel",
            "M. Y. Battista",
            "J. Ben",
            "J. Bromley",
            "C. Burges",
            "H. Baird",
            "E. Cosatto",
            "J. Denker",
            "H. Graf",
            "H. Katseff",
            "Yann LeCun",
            "C. Nohl",
            "E. Sackinger",
            "J. H. Shamilian",
            "T. Shoemaker",
            "C. E. Stenard",
            "B. I. Strom",
            "R. Ting",
            "T. Wood",
            "C. R. Zuraw"
          ]
        },
        {
          "title": "Off Line Recognition of Handwritten Postal Words Using Neural Networks",
          "year": 1993,
          "citations": 32,
          "abstract": null,
          "venue": "International journal of pattern recognition and artificial intelligence",
          "doi": "10.1142/S0218001493000340",
          "url": "https://www.semanticscholar.org/paper/065b0af1bc05ea4f1fbd2afc50a96b0ef1698c8d",
          "authors": [
            "C. Burges",
            "J. Ben",
            "J. Denker",
            "Yann LeCun",
            "C. Nohl"
          ]
        },
        {
          "title": "Device for recognizing mark",
          "year": 1993,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/25115955f80ea56236cf30704f2ef279287422d3",
          "authors": [
            "Yann LeCun",
            "Quen-Zong Wu",
            "ゾン ウ クエン",
            "ヤン アンドレレカン"
          ]
        },
        {
          "title": "Globally Trained Handwritten Word Recognizer Using Spatial Representation, Convolutional Neural Networks, and Hidden Markov Models",
          "year": 1993,
          "citations": 94,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/3461f06617b42dadd1ce240a93ffe420513b3399",
          "authors": [
            "Yoshua Bengio",
            "Yann LeCun",
            "D. Henderson"
          ]
        },
        {
          "title": "Device for recognizing mark and method for the same",
          "year": 1993,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/593701c4618ee7c8b89dcfd51639bfd9891dd0a9",
          "authors": [
            "Yann LeCun",
            "Quen-Zong Wu",
            "ゾン ウ クエン",
            "ヤン アンドレレカン"
          ]
        },
        {
          "title": "Globally trained handwritten word recognizer using spatial representation, space displacement neural networks and hidden Markov models",
          "year": 1993,
          "citations": 36,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/5fd7cbbecb090f32c198a1b2cc4e2582e06ea431",
          "authors": [
            "Yoshua Bengio",
            "Yann LeCun",
            "D. Henderson"
          ]
        },
        {
          "title": "Signature Verification Using A \"Siamese\" Time Delay Neural Network",
          "year": 1993,
          "citations": 3997,
          "abstract": null,
          "venue": "International journal of pattern recognition and artificial intelligence",
          "doi": "10.1142/S0218001493000339",
          "url": "https://www.semanticscholar.org/paper/997dc5d9a058753f034422afe7bd0cc0b8ad808b",
          "authors": [
            "J. Bromley",
            "James W. Bentz",
            "L. Bottou",
            "Isabelle M Guyon",
            "Yann LeCun",
            "Cliff Moore",
            "Eduard Säckinger",
            "Roopak Shah"
          ]
        },
        {
          "title": "On-line handwriting recognition with neural networks: Spatial representation versus temporal representation",
          "year": 1993,
          "citations": 4,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/c8a4f5358bde28333ab94076c935bc49c3ff26ea",
          "authors": [
            "Yann LeCun",
            "Yoshua Bengio",
            "D. Henderson",
            "A. Weisbuch",
            "H. Weissman",
            "L. Jackel"
          ]
        },
        {
          "title": "On-line recognition of limited-vocabulary Chinese character using multiple convolutional neural networks",
          "year": 1993,
          "citations": 13,
          "abstract": null,
          "venue": "1993 IEEE International Symposium on Circuits and Systems",
          "doi": "10.1109/ISCAS.1993.394256",
          "url": "https://www.semanticscholar.org/paper/cc74bcd1c131c3fd3edae602bc80b47cfebcd0fa",
          "authors": [
            "Quen-Zong Wu",
            "Yann LeCun",
            "L. Jackel",
            "Bor-Shenn Jeng"
          ]
        },
        {
          "title": "Natural Versus \"universal\" Probability, Complexity, And Entropy",
          "year": 1992,
          "citations": 12,
          "abstract": null,
          "venue": "Workshop on Physics and Computation",
          "doi": "10.1109/PHYCMP.1992.615508",
          "url": "https://www.semanticscholar.org/paper/4096248dca0986be1a6978945a58028e549403d8",
          "authors": [
            "J. Denker",
            "Yann LeCun"
          ]
        },
        {
          "title": "Reading handwritten digits: a ZIP code recognition system",
          "year": 1992,
          "citations": 54,
          "abstract": null,
          "venue": "Computer",
          "doi": "10.1109/2.144441",
          "url": "https://www.semanticscholar.org/paper/52a3dca70cc21b540ad5d7b7b6e23744c20095f7",
          "authors": [
            "O. Matan",
            "H. Baird",
            "J. Bromley",
            "C. Burges",
            "J. Denker",
            "L. Jackel",
            "Yann LeCun",
            "E. Pednault",
            "William Satterfield",
            "C. E. Stenard",
            "Timothy J. Thompson"
          ]
        },
        {
          "title": "Efficient Pattern Recognition Using a New Transformation Distance",
          "year": 1992,
          "citations": 578,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/8314dda1ec43ce57ff877f8f02ed89acb68ca035",
          "authors": [
            "Patrice Y. Simard",
            "Yann LeCun",
            "J. Denker"
          ]
        },
        {
          "title": "An efficient algorithm for learning invariance in adaptive classifiers",
          "year": 1992,
          "citations": 21,
          "abstract": null,
          "venue": "Proceedings., 11th IAPR International Conference on Pattern Recognition. Vol.II. Conference B: Pattern Recognition Methodology and Systems",
          "doi": "10.1109/ICPR.1992.201861",
          "url": "https://www.semanticscholar.org/paper/99c6d1a3e73e454184f81e77563a4cb5810dc430",
          "authors": [
            "Patrice Y. Simard",
            "Yann LeCun",
            "J. Denker",
            "B. Victorri"
          ]
        },
        {
          "title": "Automatic Learning Rate Maximization by On-Line Estimation of the Hessian's Eigenvectors",
          "year": 1992,
          "citations": 109,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/abc8a30694deda46c150d4da277aec291878cfeb",
          "authors": [
            "Yann LeCun",
            "Patrice Y. Simard",
            "Barak A. Pearlmutter"
          ]
        },
        {
          "title": "Application of the ANNA neural network chip to high-speed character recognition",
          "year": 1992,
          "citations": 144,
          "abstract": null,
          "venue": "IEEE Trans. Neural Networks",
          "doi": "10.1109/72.129422",
          "url": "https://www.semanticscholar.org/paper/b8bc656a1935f07e894833b608cc4671b9fa828f",
          "authors": [
            "Eduard Säckinger",
            "B. Boser",
            "J. Bromley",
            "Yann LeCun",
            "L. Jackel"
          ]
        },
        {
          "title": "Hardware requirements for neural network pattern classifiers: a case study and implementation",
          "year": 1992,
          "citations": 41,
          "abstract": null,
          "venue": "IEEE Micro",
          "doi": "10.1109/40.124378",
          "url": "https://www.semanticscholar.org/paper/bba485f09c82dd2a4261ca9648f2a4cfcd0d343f",
          "authors": [
            "B. Boser",
            "Eduard Säckinger",
            "J. Bromley",
            "Yann LeCun",
            "L. Jackel"
          ]
        },
        {
          "title": "Writer independent and writer adaptive neural network for on-line character recognition",
          "year": 1992,
          "citations": 28,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/de55322662f9538bfdc422498d6184bf2da4266c",
          "authors": [
            "Isabelle M Guyon",
            "D. Henderson",
            "P. Albrecht",
            "Yann LeCun",
            "J. Denker"
          ]
        },
        {
          "title": "Automatic Learning Rate Maximization in Large Adaptive Machines",
          "year": 1992,
          "citations": 15,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/f032d211e9db21d55b92c6349f0bb398142417a2",
          "authors": [
            "Yann LeCun",
            "Patrice Y. Simard",
            "Barak A. Pearlmutter"
          ]
        },
        {
          "title": "Improving generalization performance using double backpropagation",
          "year": 1992,
          "citations": 300,
          "abstract": null,
          "venue": "IEEE Trans. Neural Networks",
          "doi": "10.1109/72.165600",
          "url": "https://www.semanticscholar.org/paper/fbd86e19157ea0e4ffb05f14d7b94603a5667e0a",
          "authors": [
            "H. Drucker",
            "Yann LeCun"
          ]
        },
        {
          "title": "Reverse TDNN: An Architecture For Trajectory Generation",
          "year": 1991,
          "citations": 24,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/040800e88fbdff598fb85ea82c12f94c3939989f",
          "authors": [
            "Patrice Y. Simard",
            "Yann LeCun"
          ]
        },
        {
          "title": "A neural network approach to handprint character recognition",
          "year": 1991,
          "citations": 11,
          "abstract": null,
          "venue": "COMPCON Spring '91 Digest of Papers",
          "doi": "10.1109/CMPCON.1991.128851",
          "url": "https://www.semanticscholar.org/paper/2fdbed2b8fffa62c86de3e5500590a197ac3327a",
          "authors": [
            "L. Jackel",
            "C. E. Stenard",
            "H. Baird",
            "B. Boser",
            "J. Bromley",
            "C. Burges",
            "J. Denker",
            "H. Graf",
            "D. Henderson",
            "R. Howard",
            "W. Hubbard",
            "Yann LeCun",
            "O. Matan",
            "E. Pednault",
            "William Satterfield",
            "Eduard Säckinger",
            "Timothy J. Thompson"
          ]
        },
        {
          "title": "Multi-Digit Recognition Using a Space Displacement Neural Network",
          "year": 1991,
          "citations": 191,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/464e8d981df7f326c3af6e9d7bd627f83e438816",
          "authors": [
            "O. Matan",
            "C. Burges",
            "Yann LeCun",
            "J. Denker"
          ]
        },
        {
          "title": "Constrained neural networks for pattern recognition",
          "year": 1991,
          "citations": 7,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/68e9cab665e8555a5b55fb11f8bd930db32c1283",
          "authors": [
            "S. Solla",
            "Yann LeCun"
          ]
        },
        {
          "title": "An analog neural network processor with programmable topology",
          "year": 1991,
          "citations": 162,
          "abstract": null,
          "venue": "IEEE J. Solid State Circuits",
          "doi": "10.1109/4.104196",
          "url": "https://www.semanticscholar.org/paper/82795cf04f5631e82413b1952625a5a6f21b68ea",
          "authors": [
            "J. Bromley",
            "Yann LeCun",
            "L. Jackel"
          ]
        },
        {
          "title": "Design of a neural network character recognizer for a touch terminal",
          "year": 1991,
          "citations": 177,
          "abstract": null,
          "venue": "Pattern Recognition",
          "doi": "10.1016/0031-3203(91)90081-F",
          "url": "https://www.semanticscholar.org/paper/adf724f637afdb300426df8d2ff4c4342f1e7528",
          "authors": [
            "Isabelle M Guyon",
            "P. Albrecht",
            "Yann LeCun",
            "J. Denker",
            "W. Hubbard"
          ]
        },
        {
          "title": "Tangent Prop - A Formalism for Specifying Selected Invariances in an Adaptive Network",
          "year": 1991,
          "citations": 316,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/ff32cebbdb8a436ccd8ae797647428615ae32d74",
          "authors": [
            "Patrice Y. Simard",
            "B. Victorri",
            "Yann LeCun",
            "J. Denker"
          ]
        },
        {
          "title": "Second Order Properties of Error Surfaces: Learning Time and Generalization",
          "year": 1990,
          "citations": 107,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/0c43153a3627c7d98cc09f909c232f3899597204",
          "authors": [
            "Yann LeCun",
            "I. Kanter",
            "S. Solla"
          ]
        },
        {
          "title": "A time delay neural network character recognizer for a touch terminal",
          "year": 1990,
          "citations": 11,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/2c25cb7cb7c0be41510efeaef5cb96dea339823f",
          "authors": [
            "Isabelle M Guyon",
            "P. Albrecht",
            "Yann LeCun",
            "J. Denker",
            "W. Hubbard"
          ]
        },
        {
          "title": "Constrained neural network for unconstrained handwritten digit recognition",
          "year": 1990,
          "citations": 54,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/3016c38f8f5f1ad479eb25ef199a5b357c999193",
          "authors": [
            "Yann LeCun",
            "B. Boser",
            "J. Denker",
            "D. Henderson",
            "R. Howard",
            "W. Hubbard",
            "L. Jackel",
            "H. Baird"
          ]
        },
        {
          "title": "Handwritten character recognition using neural network architectures",
          "year": 1990,
          "citations": 50,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/8f2b909fa1aad7e9f13603d721ff953325a4f97d",
          "authors": [
            "O. Matan",
            "R. Kiang",
            "C. E. Stenard",
            "B. Boser",
            "J. Denker",
            "D. Henderson",
            "R. Howard",
            "W. Hubbard",
            "L. Jackel",
            "Yann LeCun"
          ]
        },
        {
          "title": "Handwritten zip code recognition with multilayer networks",
          "year": 1990,
          "citations": 233,
          "abstract": null,
          "venue": "[1990] Proceedings. 10th International Conference on Pattern Recognition",
          "doi": "10.1109/ICPR.1990.119325",
          "url": "https://www.semanticscholar.org/paper/a4bfe622ab32e6c645eb4be2079734355b22d304",
          "authors": [
            "Yann LeCun",
            "O. Matan",
            "B. Boser",
            "J. Denker",
            "D. Henderson",
            "R. Howard",
            "W. Hubbard",
            "L. D. Jacket",
            "H. Baird"
          ]
        },
        {
          "title": "Second Order Properties of Error Surfaces",
          "year": 1990,
          "citations": 13,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/d39adfe1d561f676b2075ac36c59405146533b0b",
          "authors": [
            "Yann LeCun",
            "I. Kanter",
            "S. Solla"
          ]
        },
        {
          "title": "Hardware requirements for neural-net optical character recognition",
          "year": 1990,
          "citations": 12,
          "abstract": null,
          "venue": "1990 IJCNN International Joint Conference on Neural Networks",
          "doi": "10.1109/IJCNN.1990.137801",
          "url": "https://www.semanticscholar.org/paper/dab9de4747d1286c456f36ec69415c5d668889aa",
          "authors": [
            "L. Jackel",
            "B. Boser",
            "J. Denker",
            "H. Graf",
            "Yann LeCun",
            "Isabelle M Guyon",
            "D. Henderson",
            "R. Howard",
            "W. Hubbard",
            "S. Solla"
          ]
        },
        {
          "title": "Transforming Neural-Net Output Levels to Probability Distributions",
          "year": 1990,
          "citations": 332,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/e4b370c1a04a8a6807bd73b6bbff5773e575fee7",
          "authors": [
            "J. Denker",
            "Yann LeCun"
          ]
        },
        {
          "title": "Generalization and network design strategies",
          "year": 1989,
          "citations": 1091,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/01b6affe3ea4eae1978aec54e87087feb76d9215",
          "authors": [
            "Yann LeCun"
          ]
        },
        {
          "title": "Handwritten digit recognition: applications of neural network chips and automatic learning",
          "year": 1989,
          "citations": 475,
          "abstract": null,
          "venue": "IEEE Communications Magazine",
          "doi": "10.1109/35.41400",
          "url": "https://www.semanticscholar.org/paper/3aa4c691289f56f9af6cf543633cfb3917274281",
          "authors": [
            "Yann LeCun",
            "L. Jackel",
            "B. Boser",
            "J. Denker",
            "H. Graf",
            "Isabelle M Guyon",
            "D. Henderson",
            "R. Howard",
            "W. Hubbard"
          ]
        },
        {
          "title": "Improving the convergence of back-propagation learning with second-order methods",
          "year": 1989,
          "citations": 444,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/589d377b23e2bdae7ad161b36a5d6613bcfccdde",
          "authors": [
            "S. Becker",
            "Yann LeCun"
          ]
        },
        {
          "title": "Handwritten Digit Recognition with a Back-Propagation Network",
          "year": 1989,
          "citations": 4237,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/86ab4cae682fbd49c5a5bedb630e5a40fa7529f6",
          "authors": [
            "Yann LeCun",
            "B. Boser",
            "J. Denker",
            "D. Henderson",
            "R. Howard",
            "W. Hubbard",
            "L. Jackel"
          ]
        },
        {
          "title": "Backpropagation Applied to Handwritten Zip Code Recognition",
          "year": 1989,
          "citations": 11654,
          "abstract": null,
          "venue": "Neural Computation",
          "doi": "10.1162/neco.1989.1.4.541",
          "url": "https://www.semanticscholar.org/paper/a8e8f3c8d4418c8d62e306538c9c1292635e9d27",
          "authors": [
            "Yann LeCun",
            "B. Boser",
            "J. Denker",
            "D. Henderson",
            "R. Howard",
            "W. Hubbard",
            "L. Jackel"
          ]
        },
        {
          "title": "Handwritten Digit Recognition: Applications of Neural Net Chips and Automatic Learning",
          "year": 1989,
          "citations": 30,
          "abstract": null,
          "venue": "NATO Neurocomputing",
          "doi": "10.1007/978-3-642-76153-9_35",
          "url": "https://www.semanticscholar.org/paper/cdefacc5f4e4292936ea9bd542e0a46c6c49905c",
          "authors": [
            "Yann LeCun",
            "L. Jackel",
            "B. Boser",
            "J. Denker",
            "H. Graf",
            "Isabelle M Guyon",
            "D. Henderson",
            "R. E. Howard",
            "W. Hubbard"
          ]
        },
        {
          "title": "Optimal Brain Damage",
          "year": 1989,
          "citations": 5047,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/e7297db245c3feb1897720b173a59fe7e36babb7",
          "authors": [
            "Yann LeCun",
            "J. Denker",
            "S. Solla"
          ]
        },
        {
          "title": "GEMINI: Gradient Estimation Through Matrix Inversion After Noise Injection",
          "year": 1988,
          "citations": 32,
          "abstract": null,
          "venue": "Neural Information Processing Systems",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/19ec5c7be1fe5e7088f3a042d3160ede757f5902",
          "authors": [
            "Yann LeCun",
            "C. Galland",
            "Geoffrey E. Hinton"
          ]
        },
        {
          "title": "Sn: A simulator for connectionist models",
          "year": 1988,
          "citations": 17,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/5b5461d8ba70ecd7358b6edd8f39bda711f73a69",
          "authors": [
            "L. Bottou",
            "Yann LeCun"
          ]
        },
        {
          "title": "User manual: SN: A simulator for connectionist models",
          "year": 1988,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/b2819d429bb7e76323ef3e836cbb608b7f700ab8",
          "authors": [
            "Yann LeCun",
            "L. Bottou"
          ]
        },
        {
          "title": "Using curvature information to improve back-propagation",
          "year": 1988,
          "citations": 2,
          "abstract": null,
          "venue": "Neural Networks",
          "doi": "10.1016/0893-6080(88)90205-5",
          "url": "https://www.semanticscholar.org/paper/e149ea080a0c8ed23319a0ae33260f4821696675",
          "authors": [
            "Yann LeCun"
          ]
        },
        {
          "title": "Learning on automata networks",
          "year": 1987,
          "citations": 1,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/3768e0e1c2c74b5049d79bfccad04db0e31954e8",
          "authors": [
            "F. F. Soulié",
            "P. Gallinari",
            "Yann LeCun",
            "S. Thiria"
          ]
        },
        {
          "title": "Generalization using back-propagation",
          "year": 1987,
          "citations": 2,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/745a9bf17a4db5b91e1bef2e083a9ad5c08ec282",
          "authors": [
            "F. F. Soulié",
            "P. Gallinari",
            "Yann LeCun",
            "S. Thiria"
          ]
        },
        {
          "title": "Memoires associatives distribuees: Une comparaison (Distributed associative memories: A comparison)",
          "year": 1987,
          "citations": 22,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/b667bca895b762611fe65929421e66181c7f23bc",
          "authors": [
            "P. Gallinari",
            "Yann LeCun",
            "S. Thiria",
            "F. F. Soulié"
          ]
        },
        {
          "title": "Learning processes in an asymmetric threshold network",
          "year": 1986,
          "citations": 125,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/56b771c4c3a54910dc3e7ff838940de89ed282db",
          "authors": [
            "Yann LeCun"
          ]
        },
        {
          "title": "Une procedure d'apprentissage pour reseau a seuil asymmetrique (A learning scheme for asymmetric threshold networks)",
          "year": 1985,
          "citations": 223,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/d007ed936c51a700d8c65d1bbfae7acc83783c31",
          "authors": [
            "Yann LeCun"
          ]
        },
        {
          "title": "Learning by teaching.",
          "year": 1977,
          "citations": 613,
          "abstract": null,
          "venue": "The Australian nurses' journal. Royal Australian Nursing Federation",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/d889ec784423556c29f33060e44506ebdd80b8a0",
          "authors": [
            "Cecilia Ka Yuk Chan",
            "Z. Zorina",
            "Jesse R. Sparks",
            "S. López Ornat",
            "C. Tsang",
            "E. Grigorenko",
            "R. Lubow",
            "J. Malone",
            "M. Domjan",
            "Charles Yang",
            "Michelyn C. Butler",
            "M. Gettinger",
            "T. Minor",
            "Traci N. Plumb",
            "H. Drachsler",
            "P. Kirschner",
            "M. Nakayama",
            "Rowena Santiago",
            "Ali Şimşek",
            "Fang‐Ying Yang",
            "Yi-Chun Chen",
            "G. Brooke",
            "Heidi L. Andrade",
            "Richard P. Cooper",
            "A. Podolskiy",
            "David W. Versailles",
            "Valérie Mérindol",
            "E. Guerci",
            "Nobuyuki Hanaki",
            "D. Grollman",
            "A. Billard",
            "L. C. Lamb",
            "Artur d’Avila Garcez",
            "D. Németh",
            "K. Janacsek",
            "John A. Nunnery",
            "L. Byrd-Poller",
            "M. Haan",
            "Rodrigo Harrison",
            "Mauricio G. Villena",
            "L. Izquierdo",
            "Segismundo S. Izquierdo",
            "F. Vega-Redondo",
            "Tracy Packiam Alloway",
            "U. Halsband",
            "N. Seel",
            "G. Bedny",
            "Hansjörg von Brevern",
            "K. Synytsya",
            "G. Kern-Isberner",
            "J. Breuker",
            "S. Cerri",
            "T. Zittoun",
            "S. Brinkmann",
            "Negin Dahya",
            "S. B. Fountain",
            "Karen E. Doyle",
            "K. Sarfo",
            "Bertram C. Bruce",
            "N. Bloch",
            "CM Olsson",
            "L. Nyberg",
            "R. Freivalds",
            "L. Hall",
            "M. Hall",
            "Ulrike Hanke",
            "L. Norton",
            "Aytac Gogus",
            "K. Illeris",
            "M. Macy",
            "A. Flache",
            "A. Robins",
            "L. Thorogood",
            "M. Udell",
            "C. Wynne",
            "P. Burnett",
            "M. Cannon",
            "A. Edmondson",
            "P. Hartono",
            "A. Callender",
            "Rachel Barr",
            "N. Brito",
            "Noorizah Mohd. Noor",
            "Tg. Nor Rizan Tg. Mohd. Maasum",
            "K. Cennamo",
            "Marc'Aurelio Ranzato",
            "Y-Lan Boureau",
            "K. Kavukcuoglu",
            "Karol Gregor",
            "Yann LeCun",
            "M. Alias",
            "Caifeng Shan",
            "Alice Y. Kolb",
            "D. Kolb",
            "R. Reilly",
            "K. Nielsen",
            "P. Couvillon",
            "H. King",
            "J. Dillon",
            "D. Neuman",
            "J. E. Purdy",
            "Linda Kragelund",
            "F. Gobet",
            "P. C. Lane",
            "S. Naidu",
            "Danny R. Bedgood",
            "Dirk Ifenthaler",
            "Ida Moadab",
            "D. Tucker",
            "P. Hager",
            "J. Fejes",
            "Danielle C. Colas-Zelin",
            "L. Matzel",
            "P. Perruchet",
            "B. Poulin-Charronnat",
            "S. Pacton",
            "C. Linnman",
            "Mohamed A Zeidan",
            "M. Milad",
            "I. Holloway",
            "D. Ansari",
            "K. Lionello-DeNolf",
            "J. Burgoyne",
            "Judy Huang",
            "Roger K. Thomas",
            "S. Pietropaolo",
            "Wim E. Crusio",
            "Sabine Richter",
            "J. Elen",
            "G. Clarebout",
            "E. Bliss-Moreau",
            "Jonte Bernhard",
            "Marcia L. Conner",
            "Lanita Jacobs",
            "Mariel Miller",
            "A. Hadwin",
            "M. Coen",
            "Carlo P. Magno",
            "Eli Hinkel",
            "S. Szedmák",
            "F. Balagué",
            "M. Milrad",
            "H. Hoppe",
            "Krisztina Molnár",
            "Erica de Vries",
            "E. Blanchard",
            "C. Frasson",
            "Susanne P. Lajoie",
            "T. Cazenave",
            "T. Jong",
            "J. Meij",
            "J. Gavelek",
            "Ailing Kong",
            "A. Daffertshofer",
            "J. Alonso-Tapia",
            "S. Billett",
            "D. Rumbaugh",
            "M. Beran",
            "Imran Ho-Abdullah",
            "Norsimah Mat Awal",
            "D. Seo",
            "M. Monfils",
            "A. Wright",
            "D. Deshler",
            "Frances M. Ihle",
            "Carrie Mark",
            "Daniel T. Pollitt",
            "M. Kennedy",
            "Michael C. Jackson",
            "Terezinha Nunes",
            "B. Jackling",
            "R. Howard",
            "William G. Kennedy",
            "L. C. Drickamer"
          ]
        },
        {
          "title": "General Information Registration & Reception",
          "year": null,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/2c3e28967d25ef2811e3675cf9d3ab244901e63b",
          "authors": [
            "B. Dosher",
            "Yann LeCun",
            "W. Estes",
            "J. Kujala",
            "A. Z. Scholten"
          ]
        },
        {
          "title": "Energy-based Models in Document Recognition and Computer Vision. 1. Two Challenges in Machine Learning",
          "year": null,
          "citations": 0,
          "abstract": null,
          "venue": "",
          "doi": null,
          "url": "https://www.semanticscholar.org/paper/9adb3a467cdc39637aca2a88a988d543cf45c72d",
          "authors": [
            "Yann LeCun",
            "S. Chopra",
            "Aurelio Marc",
            "Fu-Jie Ranzato",
            "Huang"
          ]
        }
      ],
      "top_coauthors": [
        {
          "name": "L. Bottou",
          "collaborations": 34
        },
        {
          "name": "J. Denker",
          "collaborations": 29
        },
        {
          "name": "K. Kavukcuoglu",
          "collaborations": 26
        },
        {
          "name": "L. Jackel",
          "collaborations": 25
        },
        {
          "name": "Marc'Aurelio Ranzato",
          "collaborations": 24
        },
        {
          "name": "Yoshua Bengio",
          "collaborations": 22
        },
        {
          "name": "P. Sermanet",
          "collaborations": 19
        },
        {
          "name": "Urs Muller",
          "collaborations": 18
        },
        {
          "name": "R. Howard",
          "collaborations": 17
        },
        {
          "name": "R. Hadsell",
          "collaborations": 17
        }
      ]
    },
    "combined": {
      "name": "Yann LeCun",
      "affiliation": "Facebook",
      "orcid": null,
      "homepage": null,
      "interests": [],
      "metrics": {
        "citations": 259193,
        "h_index": 137,
        "i10_index": 0,
        "publication_count": 405
      },
      "sources_found": [
        "arxiv",
        "semantic_scholar"
      ],
      "total_publications_all_sources": 588
    }
  }
}